{"id":"CP-08v","title":"Add MQTT support","description":"Add MQTT protocol support to commonplace. Spec will be supplied (TBD).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:45.192898672Z","created_by":"jes","updated_at":"2025-12-29T00:39:05.428000759Z","closed_at":"2025-12-29T00:39:05.428000759Z","close_reason":"MQTT support implemented with client, edits/sync/commands handlers, and topic routing. Merged in PR #12."}
{"id":"CP-0fy","title":"Sync tool should checkout directory JSON definition as .json file","description":"The sync tool (commonplace-sync) should write the JSON definition of a directory as a file named `.json` in that directory. This would allow users to see and potentially edit the directory's metadata/structure definition alongside the directory contents.","design":"Needs design discussion: What content should be in the .json file? Just metadata, or full fs-root schema? How does editing .json interact with sync? Need specification before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T14:57:56.428338-08:00","updated_at":"2025-12-29T22:37:26.417918062Z","closed_at":"2025-12-29T22:37:26.417918062Z","close_reason":"Sync client now writes fs-root schema to .commonplace.json in synced directories. Updates on server changes via SSE. Merged in PR #26."}
{"id":"CP-0j4","title":"Fix P1: Respect explicit node_id from server schema (PR #4)","description":"From PR #4 Codex review: When the server's FsSchema uses DocEntry.node_id for stable IDs, this should be respected instead of deriving IDs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:23.072384-08:00","updated_at":"2025-12-26T23:43:14.374964-08:00","closed_at":"2025-12-26T23:43:14.374964-08:00","close_reason":"Already fixed and merged to main. The handle_schema_change function now uses collect_paths_from_entry which extracts explicit node_id from DocEntry and uses it instead of deriving from path. See sync.rs lines 1249-1265 and 1358-1379."}
{"id":"CP-1ba","title":"Fix P1: Use text fs-root or send JSON-compatible updates (PR #4)","description":"From PR #4 Codex review: The fs-root node is created with content_type application/json but the updates being sent may not be JSON-compatible.","design":"Resolved by CP-qmk (PR #9). The push_schema_to_server function now uses create_yjs_map_diff_update which generates Y.Map updates instead of Y.Text updates. This makes the updates JSON-compatible as required by the fs-root node's application/json content type.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:23.464711-08:00","updated_at":"2025-12-27T00:14:06.868523-08:00","closed_at":"2025-12-27T00:14:06.868523-08:00","close_reason":"Resolved by CP-qmk fix - client now applies server CRDT state before making changes, ensuring proper tombstone creation for deletions. Merged in PR #9.","dependencies":[{"issue_id":"CP-1ba","depends_on_id":"CP-qmk","type":"blocks","created_at":"2025-12-26T23:41:34.266588-08:00","created_by":"daemon"}]}
{"id":"CP-1s6","title":"Orchestrator needs lock file to prevent multiple instances","description":"Running multiple orchestrator instances causes conflicts (e.g., Telegram bot conflict). Need a lock file or similar mechanism to prevent duplicate instances.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-01T19:41:29.49526294Z","created_by":"jes","updated_at":"2026-01-01T19:41:29.49526294Z"}
{"id":"CP-2pr","title":"Break sync.rs into smaller modules","description":"src/bin/sync.rs is 2734 lines and too large for a single module. It should be refactored into smaller, focused modules for better maintainability and readability.\n\nSuggested breakdown:\n- Core sync state machine\n- File system operations  \n- MQTT message handling\n- Conflict resolution logic\n- Document path resolution","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-31T07:03:46.71615207Z","created_by":"jes","updated_at":"2025-12-31T07:03:46.71615207Z","labels":["refactor","tech-debt"]}
{"id":"CP-2u5","title":"Replace endpoint doesn't work for JSON documents","description":"The /docs/{id}/replace endpoint uses character-level diffing via Y.Text, but JSON documents use Y.Map internally. When calling replace on a JSON document (like fs-root), the content is not updated. Workaround: Use the /edit endpoint with create_yjs_json_update instead.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-01T00:27:16.371497913Z","created_by":"jes","updated_at":"2026-01-01T02:05:49.98180474Z","closed_at":"2026-01-01T02:05:49.98180474Z","close_reason":"Fixed by modifying replace_content to use create_yjs_json_update for JSON documents"}
{"id":"CP-320","title":"Sync push loses node_ids when updating fs-root schema on server","description":"The sync correctly preserves node_ids when scanning locally (CP-8ou), but when it pushes the schema to the server, the node_ids become null.\n\nLocal .commonplace.json has correct shared UUIDs:\n- bartleby/prompts.txt: 0b250a22-3163-49df-8634-534585865cdd\n- telegram/content.txt: 0b250a22-3163-49df-8634-534585865cdd\n\nBut server's fs-root document has null for both.\n\nThis breaks file linking because the reconciler sees null and generates new random UUIDs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T00:11:19.958347431Z","created_by":"jes","updated_at":"2026-01-01T02:06:52.691341058Z","closed_at":"2026-01-01T02:06:52.691341058Z","close_reason":"Symptom of CP-g0c schema corruption - node_id preservation tests pass once schema is not corrupted"}
{"id":"CP-365","title":"commonplace-sync --node should accept path relative to fs-root","description":"According to SANDBOX_LINKING.md and bartleby-integration.md, --node should accept path-style names like 'bartleby-workspace' or 'workspace/bartleby' relative to the server's fs-root.\n\n**Expected:**\n```bash\ncommonplace-sync --node workspace/bartleby --server http://localhost:3000\n```\n\n**Actual:**\nMust use UUIDs:\n```bash\ncommonplace-sync --node 2750f8b7-7296-41f9-854d-7b130a707930 --server http://localhost:3000\n```\n\n**Requirements:**\n1. Accept path strings relative to server's --fs-root\n2. Resolve path → UUID by querying the server's fs-root schema\n3. Work with --sandbox mode for dynamic process management\n\n**Workaround:** Use UUIDs directly (look them up from server's .commonplace.json or API)","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T16:56:49.691337582Z","created_by":"jes","updated_at":"2026-01-01T19:02:28.161177467Z","closed_at":"2026-01-01T19:02:28.161177467Z","close_reason":"Implemented sandbox-exec config, path resolution (--path flag), recursive discovery (--recursive flag), and source_path tracking to prevent multi-config interference. All merged in PR #78.","comments":[{"id":15,"issue_id":"CP-365","author":"jes","text":"**Updated understanding:** The original design was even simpler - no --node flag needed at all.\n\nThe sync process should discover its server path automatically:\n1. Look at where processes.json is located on the filesystem\n2. Use the process name from that config\n3. Derive the server path: `{processes.json parent}/{process_name}`\n\nExample: If processes.json is at `/home/jes/commonplace/workspace/processes.json` and contains a 'bartleby' process, the sandbox should automatically sync to the server path `workspace/bartleby` (relative to fs-root).\n\nThis eliminates the need for explicit --node or --path arguments entirely.","created_at":"2026-01-01T16:58:55Z"}]}
{"id":"CP-3ky","title":"Implement Router Documents (docs/ROUTER.md)","description":"Implement the router document feature as specified in docs/ROUTER.md:\n\n- Add `--router \u003cnode-id\u003e` CLI flag (repeatable)\n- Router documents are JSON with `version`, `nodes`, and `edges` \n- Server subscribes to router document blue port for changes\n- Apply/diff wiring based on router document content\n- Emit `router.error` events on red port for errors\n- Handle node creation hints from `nodes` section\n- Track router-created wires separately from other wires","design":"Implementation approach:\n\n1. New module: src/router/ with:\n   - mod.rs: Module exports\n   - error.rs: RouterError enum for parse/validation/cycle errors\n   - schema.rs: RouterSchema, Edge, NodeSpec, PortType structs with serde\n   - manager.rs: RouterManager that subscribes to router document's blue port\n\n2. CLI: Added --router \u003cnode-id\u003e flag (repeatable) in cli.rs\n\n3. RouterConfig: Added routers: Vec\u003cString\u003e field\n\n4. Initialization: In lib.rs, for each router ID:\n   - Get or create JSON document node\n   - Create RouterManager with registry reference\n   - Start background watcher task\n   - Perform initial wiring\n\n5. Wire management:\n   - RouterManager tracks wires it created (WireKey -\u003e SubscriptionId)\n   - On each reconcile, diffs desired vs current wires\n   - Removes wires no longer declared, adds new ones\n   - Cycle detection handled by registry, emits router.error on failure\n\n6. Error handling:\n   - Parse errors, unsupported version, missing nodes, cycles → router.error event on red port","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-26T18:29:01.089173-08:00","updated_at":"2025-12-26T23:22:36.003263-08:00","closed_at":"2025-12-26T23:22:36.003263-08:00","close_reason":"Router documents feature implemented. Added --router CLI flag, RouterManager, schema validation, wiring management, and error events. Addressed 4 P2 review suggestions. Merged in PR #8."}
{"id":"CP-3ve","title":"Identify and refactor large files into smaller modules","description":"Audit the codebase for files that have grown too large and could benefit from being split into smaller, more focused modules. Look for files with multiple distinct responsibilities that could be separated.","design":"Test coverage now in place (40 tests). Ready for refactoring.\n\nTarget module structure for src/bin/sync.rs split:\n\n1. src/sync/mod.rs - Module root, re-exports\n2. src/sync/urls.rs - URL building functions (encode_node_id, encode_path, normalize_path, build_*_url)\n3. src/sync/yjs.rs - Yjs update creation (create_yjs_text_update, create_yjs_json_update, json_value_to_any)\n4. src/sync/types.rs - Data structures (HeadResponse, EditResponse, ForkResponse, FileEvent, SyncState, etc.)\n5. src/sync/client.rs - HTTP client operations (SyncClient trait + impl)\n6. src/sync/file_sync.rs - File mode sync (run_file_mode, file_watcher_task, upload_task)\n7. src/sync/dir_sync.rs - Directory mode sync (run_directory_mode, directory_watcher_task, handle_schema_change)\n8. src/sync/sse.rs - SSE handling (sse_task, directory_sse_task, handle_server_edit, refresh_from_head)\n\nsrc/bin/sync.rs becomes thin wrapper: just main() + Args parsing, delegates to sync module.\n\nTests move with their functions to respective modules.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-29T13:47:42.244104-08:00","updated_at":"2025-12-30T03:24:24.008280981Z","closed_at":"2025-12-30T03:24:24.008280981Z","close_reason":"Refactored sync.rs into modular structure. Created src/sync/ with urls.rs, yjs.rs, types.rs (implemented) and client.rs, dir_sync.rs, file_sync.rs, sse.rs (placeholders for Phase 2). Added 44 tests. PR #33 merged."}
{"id":"CP-4a0","title":"Refactor discovery.rs: Extract process state machine","description":"orchestrator/discovery.rs is 542 lines. Extract `ManagedDiscoveredProcess` state machine and lifecycle handling into separate module, keeping only config parsing and discovery logic in discovery.rs.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-30T00:34:51.339252-08:00","updated_at":"2025-12-30T16:55:35.033866881Z","closed_at":"2025-12-30T16:55:35.033866881Z","close_reason":"Extracted process state machine to discovered_manager.rs - PR #44 merged"}
{"id":"CP-4br","title":"Investigate excessive SSE connections during sync","description":"Summary: Logs show repeated \"SSE connection opened\" lines during sync; investigate why the sync client is opening many SSE connections for the same targets instead of maintaining one per file (plus fs-root), and fix the spawn/reconnect logic to avoid duplicates.\\n\\nFiles to modify: src/bin/sync.rs, src/sync/file_sync.rs, src/sync/sse.rs, src/sync/dir_sync.rs.\\n\\nImplementation steps:\\n1. Reproduce by running sync with logs enabled and count connection opens per file and for fs-root.\\n2. Trace where SSE tasks are spawned (per-file and fs-root) and ensure each target gets exactly one EventSource per lifecycle.\\n3. Identify whether reconnection loops or restart logic cause duplicate tasks; add guards or reuse existing connections.\\n4. Add/adjust logging or tests to assert single SSE connection per target (per file + fs-root).\\n\\nExample: For a sync of 3 files, expect 4 SSE connections total (3 files + fs-root); logs currently show repeated opens for the same file on each sync cycle.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T05:58:35.263828365Z","created_by":"jes","updated_at":"2026-01-01T11:20:25.079063026Z","closed_at":"2026-01-01T11:20:25.079063026Z","close_reason":"Investigated and found no bug. SSE connection architecture is correct: one connection per file plus fs-root, with automatic reconnection on disconnect. The 'excessive' connection logs are expected behavior from reconnection after server restarts or network issues.","comments":[{"id":11,"issue_id":"CP-4br","author":"jes","text":"Investigation notes:\n\n1. SSE task architecture looks correct:\n   - One SSE task per file (spawned via spawn_file_sync_tasks)\n   - One SSE task for fs-root directory (directory_sse_task)\n   - handle_schema_change has guard: if !known_paths.contains(path) before spawning\n\n2. Reconnection behavior is intentional:\n   - Both sse_task and directory_sse_task have reconnect loops with 5s delay\n   - 'SSE connection opened' is logged on each (re)connection\n\n3. Possible causes of 'excessive' logs:\n   - Server restarts causing all clients to reconnect\n   - Network issues causing disconnects\n   - Server SSE timeout dropping idle connections\n\n4. To verify if this is a real bug:\n   - Need to reproduce with a stable server\n   - Count unique SSE URLs being connected (should match file count + 1)\n   - Check if same URL is connected multiple times concurrently\n\nWill check server-side SSE connection handling next.","created_at":"2026-01-01T11:19:35Z"},{"id":12,"issue_id":"CP-4br","author":"jes","text":"Server-side SSE analysis:\n\n1. Server uses 30-second keep-alive interval (sse.rs:396)\n2. SSE connections stay open as long as:\n   - Client maintains connection\n   - Document exists\n   - No broadcast channel errors\n\n3. Connection drops would happen on:\n   - Server restart\n   - Document deletion\n   - Network issues\n   - Broadcast channel closure\n\nConclusion: The code appears correct. SSE connections are intentionally reconnecting (with 5s delay) when closed. The 'excessive' logs may be:\n1. Normal reconnection after server restarts during testing\n2. Expected behavior for initial connection setup\n3. Debug-level info logs appearing frequently\n\nRecommendation: Either close as not-a-bug, or demote the 'SSE connection opened' log from info! to debug! to reduce noise.\n\nI'll close this as the architecture appears correct and the behavior is expected.","created_at":"2026-01-01T11:20:17Z"}]}
{"id":"CP-4e9","title":"Sync protocol infinite loop: commit:null parsed as request","design":"When store has no HEAD commit, it responds with {type:head, req:..., commit:null}. The Rust code distinguishes requests (commit:None) from responses (commit:Some). But null deserializes to None, so the store receives its own response and re-handles it as a request, creating an infinite loop. Fix: use distinct message types like head_request vs head_response, or add a direction field.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-30T00:30:17.030876486Z","created_by":"jes","updated_at":"2025-12-30T01:17:06.619813304Z","closed_at":"2025-12-30T01:17:06.619813304Z","close_reason":"Fixed by splitting Head message into Head (request) and HeadResponse (response). Committed in ded73c4."}
{"id":"CP-4f7","title":"Deprecate derived IDs - all files and directories should have UUIDs","description":"Derived IDs (like fs-root:path) are fragile - they break on rename. Every file and directory entry should have an explicit UUID node_id instead.\n\nThis affects:\n- Reconciler: should generate UUIDs for entries without node_id\n- Sync tool: should ensure all entries have UUIDs when scanning\n- Link tool: already does this for source files\n- Schema migration: existing derived IDs should be converted to UUIDs\n\nBenefits:\n- Stable references across renames\n- Links don't break when source is renamed\n- Simpler path resolution (just lookup by UUID)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T22:48:39.651047828Z","created_by":"jes","updated_at":"2025-12-30T23:12:28.538534864Z","closed_at":"2025-12-30T23:12:28.538534864Z","close_reason":"Migration now generates UUIDs for all entries. Removed derive_doc_id method. PR #53 merged."}
{"id":"CP-4xd","title":"Directory-attached process management for orchestrator","description":"Similar to the existing file-attached process mechanism, add support for declaring that a process is running 'in a directory' that the orchestrator manages. This will be the primary paradigm for the sync-sandbox tool.\n\nUnlike file-attached processes which are tied to a specific document, directory-attached processes operate on a directory scope and can interact with multiple files within that directory tree.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T06:47:45.584747427Z","created_by":"jes","updated_at":"2025-12-31T16:27:44.602430837Z","closed_at":"2025-12-31T16:27:44.602430837Z","close_reason":"Merged in PR #55","comments":[{"id":6,"issue_id":"CP-4xd","author":"jes","text":"Implementation complete. Changes:\n- Made owns field optional in DiscoveredProcess (absent = directory-attached)\n- Added COMMONPLACE_SERVER env var to spawned processes\n- Added resolve_server_url() to OrchestratorConfig with fallback chain\n- Added COMMONPLACE_PATH env var support in sync.rs as alias for --node\n- Updated examples/.processes.json with directory-attached example\n\nCommits: 4d7963a, 0c5f293, 06b2975, 2e7d89b, 81574fa, 43367f8, 866e4b4, d7f1549","created_at":"2025-12-31T08:32:26Z"}]}
{"id":"CP-51t","title":"Verify diff module returns correct summary struct for replace endpoint","design":"The /nodes/:id/replace endpoint needs diff_to_yjs_update to return (update_bytes, DiffSummary) where DiffSummary has inserted, deleted, operations fields. Need to verify this interface exists or add it.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T08:03:48.888669529Z","created_by":"jes","updated_at":"2025-12-29T09:01:47.131481523Z","closed_at":"2025-12-29T09:01:47.131481523Z","close_reason":"Verified: diff module returns DiffResult with update_bytes, update_b64, operation_count, and summary (DiffSummary with chars_inserted, chars_deleted). replace_node endpoint correctly uses all fields."}
{"id":"CP-56w","title":"Refactor api.rs: Separate path-based vs ID-based routing","description":"api.rs has mixed concerns for /docs/{id} and /files/{path} routing. Extract path-based API (`/files/*`) into separate module to clarify the two API styles.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-30T00:34:51.228276-08:00","updated_at":"2025-12-30T16:31:46.635504385Z","closed_at":"2025-12-30T16:31:46.635504385Z","close_reason":"Closed","dependencies":[{"issue_id":"CP-56w","depends_on_id":"CP-ejh","type":"blocks","created_at":"2025-12-30T00:36:37.094635-08:00","created_by":"daemon"}]}
{"id":"CP-5af","title":"Telegram messages ↔ file integration","description":"Bidirectional sync between Telegram messages and commonplace documents:\n- Receive Telegram messages as document updates or events\n- Send document content/edits to Telegram chats\n- Subscribe to specific chats/channels\n- Bot or user account authentication\n\nEnables messaging-as-document patterns and chat automation.","design":"OPEN QUESTIONS for implementation:\n1. Bot token or user session auth?\n2. What's the document schema for messages?\n3. Handle message history or just new messages?\n4. Support for media (photos, files) or text only?\n5. Rate limiting and Telegram API compliance?\n6. How to map chats to document paths?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.825068-08:00","updated_at":"2025-12-30T01:45:22.840556932Z","dependencies":[{"issue_id":"CP-5af","depends_on_id":"CP-nno","type":"blocks","created_at":"2025-12-28T23:53:18.82599-08:00","created_by":"daemon"}]}
{"id":"CP-5i1","title":"HTML + WebSocket server process","description":"Server process that serves static HTML viewer and provides WebSocket connections for live document streaming. Powers the live HTML viewer (CP-6oj).","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T18:00:20.018424314Z","created_by":"jes","updated_at":"2025-12-30T18:00:20.018424314Z"}
{"id":"CP-5p5","title":"Investigate B-\u003eA sync not working: file watcher or echo detection issue","design":"Root cause found: Atomic writes break file watcher.\n\nWhen handle_server_edit writes to file, it uses atomic write (temp + rename). On Linux with inotify, this can cause the watcher to lose track of the file because:\n1. Watcher watches original inode\n2. Rename replaces file with new inode\n3. Watcher still watching old (deleted) inode\n4. Subsequent edits to new file not detected\n\nPotential fixes:\n1. Watch parent directory instead of file\n2. Re-register file watcher after each write\n3. Don't use atomic writes (risk: partial writes on crash)\n4. Use inotify IN_MOVED_TO event to re-watch\n\nNeeds implementation to test which approach works best.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-29T08:18:50.200861401Z","created_by":"jes","updated_at":"2025-12-29T16:02:38.701416395Z","closed_at":"2025-12-29T16:02:38.701416395Z","close_reason":"Fixed inotify file watcher issue by using direct writes instead of atomic (temp+rename). Testing revealed a separate race condition where upload_task can send stale content before server edits are written - needs follow-up fix. PR #21 merged."}
{"id":"CP-5qb","title":"Sandbox file linking not working - sync creates forks instead of using linked UUIDs","description":"When setting up linked files between sandbox processes (per SANDBOX_LINKING.md), the sync is creating new forks instead of using the shared UUIDs.\n\n**Expected behavior:**\n- text-to-telegram/content.txt and bartleby/prompts.txt share the same UUID\n- Changes to one file sync to the other\n\n**Actual behavior:**\n- Sync detects 'new file has identical content' and FORKS a new UUID\n- Each sandbox ends up with different UUIDs for the linked files\n- No sync happens between them\n\n**Root cause:**\n- Node-backed directories (entries: null, node_id: X) store schemas separately\n- Local schema edits aren't pushed to the server's subdirectory nodes\n- When sandbox syncs pull schemas, they get wrong/missing UUIDs\n\n**To fix:**\n1. Need to push linked schemas directly to subdirectory node documents\n2. Or change sync to preserve UUIDs from local schema when pushing\n3. Update SANDBOX_LINKING.md with correct procedure for node-backed directories","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:29:39.76376046Z","created_by":"jes","updated_at":"2026-01-01T19:37:40.407375761Z","closed_at":"2026-01-01T19:37:40.407375761Z","close_reason":"Fixed by adding path option to processes.json. Each sandbox now syncs from its own subdirectory rather than root, allowing linked UUIDs to work correctly."}
{"id":"CP-5qy","title":"Orchestrator should restart sandbox-exec processes that die","description":"When a sandbox-exec process exits (crashes or otherwise dies), the orchestrator should restart it automatically.\n\nCurrently the orchestrator has check_and_restart() logic but it may not be working correctly for sandbox-exec processes. The sync wrapper process may be running but the actual child process (e.g., bartleby, text-to-telegram) may have died.\n\nNeed to ensure the entire process tree is monitored and restarted on failure.","status":"open","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:21:34.651720793Z","created_by":"jes","updated_at":"2026-01-01T19:21:34.651720793Z"}
{"id":"CP-5we","title":"Beads integration with bidirectional sync","description":"Sync beads JSONL into commonplace as documents. Edits made via commonplace should publish back to beads, enabling bidirectional issue tracking integration.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:56:53.320326707Z","created_by":"jes","updated_at":"2025-12-30T17:56:53.320326707Z","dependencies":[{"issue_id":"CP-5we","depends_on_id":"CP-oi3","type":"blocks","created_at":"2025-12-30T18:43:29.742508518Z","created_by":"daemon"}]}
{"id":"CP-6oj","title":"Live HTML viewer with websocket updates","description":"Browser-based viewer that connects via websocket to display commonplace documents in real-time. XHTML documents render as HTML, JSON and XML documents display formatted source. Updates stream live as documents change.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:59:51.301579711Z","created_by":"jes","updated_at":"2025-12-30T17:59:51.301579711Z","dependencies":[{"issue_id":"CP-6oj","depends_on_id":"CP-5i1","type":"blocks","created_at":"2025-12-30T18:00:25.637694596Z","created_by":"daemon"}]}
{"id":"CP-6pd","title":"Use cwd to run processes in sandbox directory instead of symlinks/env vars","description":"When conductor/orchestrator spawns processes for directory-attached work, set the working directory (cwd) to the sandbox/workspace directory instead of relying on symlinks or environment variables like BARTLEBY_WORKING_DIR. This allows programs that use relative paths to naturally see the sandbox contents without any special configuration. Simpler and more transparent than the symlink approach.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T17:04:16.788917689Z","created_by":"jes","updated_at":"2025-12-31T19:55:32.624440087Z","closed_at":"2025-12-31T19:55:32.624440087Z","close_reason":"Implemented in PR #58. Bartleby now uses Path.cwd() instead of BARTLEBY_WORKING_DIR env var, and orchestrator sets cwd to workspace directory."}
{"id":"CP-7gx","title":"Sync --use-paths should work without --node when server has fs-root","description":"Currently sync client with --use-paths still requires --node. When using path-based endpoints (/files/*path), the sync should be able to work without specifying a node ID since paths are resolved on the server.\n\nWorkaround: Query /fs-root endpoint (CP-81o) to get the node ID.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T23:59:59.108226549Z","created_by":"jes","updated_at":"2026-01-01T11:33:34.815949Z","closed_at":"2026-01-01T11:33:34.815949Z","close_reason":"Fixed in PR #75. Sync with --use-paths can now auto-discover fs-root from server.","comments":[{"id":13,"issue_id":"CP-7gx","author":"jes","text":"Dependency: This requires CP-81o (GET /fs-root endpoint) to be implemented first. The sync client needs to be able to discover the fs-root document ID from the server before it can work without --node.\n\nWill implement CP-81o first, then come back to this.","created_at":"2026-01-01T11:21:19Z"}]}
{"id":"CP-7m0","title":"Flat directory JSON with subdirectory documents","description":"Directory JSON should only contain one level of files. Subdirectories need to be their own separate JSON documents. This enables partial checkouts of large directory trees.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:47:47.262049538Z","created_by":"jes","updated_at":"2025-12-30T21:56:23.60592734Z","closed_at":"2025-12-30T21:56:23.60592734Z","close_reason":"Closed"}
{"id":"CP-7n2","title":"Refactor sync.rs: Extract file watcher logic","description":"Extract file watcher setup and event handling from sync.rs into dedicated module `src/sync/watcher.rs`. This handles notify events, debouncing, and change detection.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-30T00:34:50.932224-08:00","updated_at":"2025-12-30T15:26:25.522185703Z","closed_at":"2025-12-30T15:26:25.522185703Z","close_reason":"Merged in PR #39","dependencies":[{"issue_id":"CP-7n2","depends_on_id":"CP-jwf","type":"blocks","created_at":"2025-12-30T00:36:37.008385-08:00","created_by":"daemon"}]}
{"id":"CP-80u","title":"Fix P2: Skip wiring when an identical edge already exists (PR #8)","description":"From PR #8 Codex review: The router creates wires based on managed_wires, but if a wiring already exists from an external source (e.g., /nodes/:from/wire/:to), this code will still call wire_* and create a second subscription. Consider checking existing registry wirings before adding.","design":"Added `find_existing_wiring(from, to, port)` method to NodeRegistry. Router manager now checks for existing wires before creating new ones and adopts them into managed_wires if found. Known limitation: Adopted wires skip the router's cycle error emission, but this is safe because external wire creation already performs cycle detection at the registry level.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T23:24:33.186937-08:00","updated_at":"2025-12-27T00:35:45.522329-08:00","closed_at":"2025-12-27T00:35:45.522329-08:00","close_reason":"Skip duplicate wirings implemented. Added find_existing_wiring() to NodeRegistry. Router now checks for existing wires before creating new ones and skips duplicates without claiming ownership (prevents router interference). Merged in PR #10."}
{"id":"CP-81o","title":"Server should expose fs-root document ID at /fs-root endpoint","description":"When server is started with --fs-root, there's no way for clients to discover the fs-root document ID. Add GET /fs-root endpoint that returns the document ID.\n\nThis would simplify the sync workflow - clients could auto-discover the fs-root instead of needing to pass --node.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T23:59:51.564657714Z","created_by":"jes","updated_at":"2026-01-01T11:27:19.342457135Z","closed_at":"2026-01-01T11:27:19.342457135Z","close_reason":"Fixed in PR #74. Added GET /fs-root endpoint that returns the fs-root document ID."}
{"id":"CP-8cd","title":"Make --recursive the default for orchestrator","description":"When running the orchestrator with a server that has --fs-root configured, --recursive mode should be the default behavior.\n\nCurrently requires explicit --recursive flag to discover all processes.json files in the filesystem tree. This should be the default since it's the most common use case.\n\nThe non-recursive mode (--watch-processes) can still be available for watching a specific document.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-01T19:21:01.334042203Z","created_by":"jes","updated_at":"2026-01-01T19:21:01.334042203Z"}
{"id":"CP-8ci","title":"Sync sandbox mode with temp directory isolation","description":"Upgrade sync subprocess mode to sync sandbox: uses a temp directory, checks out a synced directory or subdirectory, runs the child process in there, and cleans up after itself when the child exits.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:50:05.321115052Z","created_by":"jes","updated_at":"2026-01-01T02:37:02.757303296Z","closed_at":"2026-01-01T02:37:02.757303296Z","close_reason":"Sandbox mode verified working: creates temp dir, syncs with server, runs command in sandbox, cleans up on exit","dependencies":[{"issue_id":"CP-8ci","depends_on_id":"CP-cxj","type":"blocks","created_at":"2025-12-30T18:02:57.400462144Z","created_by":"daemon"},{"issue_id":"CP-8ci","depends_on_id":"CP-w2v","type":"blocks","created_at":"2025-12-30T18:02:57.424433327Z","created_by":"daemon"}],"comments":[{"id":4,"issue_id":"CP-8ci","author":"jes","text":"Accidentally closed without implementation","created_at":"2025-12-30T21:02:26Z"},{"id":8,"issue_id":"CP-8ci","author":"jes","text":"PR #49 was stale - reviewing if sandbox mode actually works correctly","created_at":"2026-01-01T02:36:44Z"}]}
{"id":"CP-8fz","title":"Fix server replay to use node's content type for JSON documents","description":"P1 from PR #6 review: The server's /nodes/:id/head and replace endpoints replay with ContentType::Text, but Y.Map commits need ContentType::Json. When replaying Y.Map commits with Text type, replay.rs returns \"Text root not found\" causing 500 errors.\n\nFix: Update src/api.rs (around lines 460-464) to use the node's actual content type when replaying commits.","design":"Fixed in 3 places:\n\n1. api.rs get_node_head: Now gets content type from the node via DocumentNode downcast instead of hardcoding Text. This allows proper replay of JSON (Y.Map) commits.\n\n2. api.rs replace_content: Now validates content type and returns 415 error for non-text nodes. Replace endpoint only supports text because it uses text-based diffing.\n\n3. sync.rs push_schema_to_server: Simplified to always use edit endpoint with Y.Map updates. This avoids the replace endpoint's text-only limitation.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T18:13:33.205983-08:00","updated_at":"2025-12-26T18:22:55.113026-08:00","closed_at":"2025-12-26T18:22:55.113026-08:00","close_reason":"Fixed server replay to use node's actual content type. GET /nodes/:id/head now works for JSON (Y.Map) documents. Replace endpoint properly rejects non-text content with 415. Merged in PR #7.","labels":["P1","api","bug","yjs"]}
{"id":"CP-8ou","title":"Directory sync doesn't preserve node_ids from existing .commonplace.json","description":"When running commonplace-sync in directory mode, scan_directory() always generates fresh Entry structs with node_id: None. It doesn't read the existing .commonplace.json to preserve manually-set node_ids.\n\nThis blocks the ability to link files across directories by manually editing node_ids in the schema - the sync overwrites them on every scan.\n\nExpected behavior: scan_directory should merge with existing .commonplace.json, preserving node_ids for files that still exist.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-31T23:35:43.380888682Z","created_by":"jes","updated_at":"2025-12-31T23:50:25.998188768Z","closed_at":"2025-12-31T23:50:25.998188768Z","close_reason":"Merged in PR #62. scan_directory now preserves node_ids from existing .commonplace.json."}
{"id":"CP-8t3","title":"Move HTTP interface to separate binary with MQTT connection","description":"Extract the HTTP interface into a new binary that connects to the document store over MQTT instead of direct access.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:46.493852588Z","created_by":"jes","updated_at":"2025-12-29T08:45:22.041612098Z","closed_at":"2025-12-29T01:52:01.289555636Z","close_reason":"HTTP/Store split implemented. Two new binaries: commonplace-store (MQTT+persistence) and commonplace-http (stateless HTTP gateway). Fixed P1 issues from codex reviews. Merged in PR #14.","dependencies":[{"issue_id":"CP-8t3","depends_on_id":"CP-08v","type":"blocks","created_at":"2025-12-28T21:57:24.845534402Z","created_by":"daemon"}]}
{"id":"CP-8vr","title":"Sync race condition when multiple files share same UUID","description":"When using commonplace-link to make two files share the same UUID, edits to one file don't reliably sync.\n\nROOT CAUSE (from codex review):\nRace between SSE writes and upload_task's initial file read. When processing a change, upload_task reads the file on disk BEFORE it checks state.pending_write. If another SSE handler for the same document is writing server content (because a second local file shares the UUID), the upload task captures the just-written server version instead of the user's edit. It then posts that stale content and logs a successful upload even though the user's change was overwritten on disk and never reaches the server.\n\nFIX: Check pending_write barrier BEFORE reading the file content in upload_task.\n\nLocation: src/sync/file_sync.rs:17-60\n\nRepro:\n1. Create two files with commonplace-link sharing a UUID\n2. Edit file A\n3. Sync reports 'Uploaded: X chars inserted'\n4. But server content remains unchanged\n\nImpact: Sandbox linking architecture (docs/SANDBOX_LINKING.md) doesn't work reliably.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T05:11:38.809310083Z","created_by":"jes","updated_at":"2026-01-01T05:29:49.087146613Z","closed_at":"2026-01-01T05:29:49.087146613Z","close_reason":"Fixed by capturing file content at watcher notification time instead of in upload_task. The watcher now reads the file immediately when detecting a change and passes the content in FileEvent::Modified(Vec\u003cu8\u003e), preventing SSE from overwriting the file before upload_task processes it."}
{"id":"CP-96p","title":"create_yjs_json_update produces malformed nested JSON","description":"When pushing JSON to a Y.Map document, the create_yjs_json_update function puts the entire root object as a string value instead of properly nesting the Y.Map structure. Example: {\"version\":1,\"root\":\"\\n  \\\"version\\\": 1,\\n  \\\"root\\\": {\\n...\"} - The root field contains escaped JSON string instead of an object.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T00:28:29.314098124Z","created_by":"jes","updated_at":"2026-01-01T02:06:51.668159906Z","closed_at":"2026-01-01T02:06:51.668159906Z","close_reason":"Symptom of CP-g0c schema corruption - Y.Map roundtrip tests pass and show correct nested JSON handling"}
{"id":"CP-9u1","title":"Sync client uses derived IDs instead of UUIDs from schema","description":"After CP-4f7 (deprecate derived IDs), the reconciler generates UUIDs for file entries. But the sync client still constructs derived IDs like 'fs-root:path/to/file.txt' when syncing file contents, instead of reading the node_id UUIDs from the updated schema.\n\nSteps to reproduce:\n1. Start server with --fs-root\n2. Run sync with --directory pointing to a folder with files\n3. Sync pushes schema, reconciler creates documents with UUIDs\n4. Sync tries to push file content using derived ID\n5. 'Identifier not found, waiting for reconciler' loops forever\n\nExpected: Sync should re-fetch the schema after push to get the UUID node_ids, then use those for file content syncing.\n\nBlocking bartleby integration testing.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-31T16:54:04.192088145Z","created_by":"jes","updated_at":"2025-12-31T17:17:14.235135137Z","closed_at":"2025-12-31T17:17:14.235135137Z","close_reason":"Fixed: Sync client now recursively fetches schemas from node-backed directories to resolve UUIDs. Added build_uuid_map_recursive() function that follows directory references."}
{"id":"CP-a85","title":"Filetree to XHTML renderer","description":"Render a filetree (directory structure) as XHTML output.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:54:39.878136696Z","created_by":"jes","updated_at":"2025-12-30T17:54:39.878136696Z"}
{"id":"CP-adm","title":"Macaroons for MQTT-layer authorization","description":"Implement macaroon-based authorization enforced at the MQTT layer. Macaroons provide:\n- Delegatable, attenuatable credentials\n- Fine-grained path-based permissions\n- Caveat-based restrictions (time, scope, etc.)\n\nEnforcement at MQTT means all clients (JS sandbox, external processes, CLI, MCP servers) go through the same auth layer.","design":"OPEN QUESTIONS for implementation:\n1. Where is the macaroon root key stored and managed?\n2. What operations require macaroons vs are public?\n3. How are macaroons minted and distributed to clients?\n4. What caveats are needed (time, path prefix, read-only, etc)?\n5. Who enforces - the MQTT broker (plugin?) or commonplace-store?\n6. Do we need a 'mint macaroon' command or API?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.628965-08:00","updated_at":"2025-12-30T01:44:34.551124057Z"}
{"id":"CP-ajb","title":"Add integration tests for MQTT path resolution","design":"Needs design discussion: Requires understanding MQTT broker setup for tests. Current codebase doesn't have MQTT integration tests - would need to add test infrastructure first (mock broker or real broker in tests). Substantial effort beyond just adding test cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T08:03:39.396454509Z","created_by":"jes","updated_at":"2025-12-30T23:17:27.562485622Z","closed_at":"2025-12-30T23:17:27.562485622Z","close_reason":"Added 13 integration tests for MQTT path resolution. PR #54 merged."}
{"id":"CP-bno","title":"POST /docs should accept initial content in request body","description":"Currently POST /docs creates an empty document. The request body is not used as initial content.\n\nEnhancement: Allow POST /docs to accept content in the body, either:\n1. JSON body for JSON documents\n2. Text body for text documents\n\nThis would simplify workflows where you want to create a document with specific content.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-01T00:15:49.814509595Z","created_by":"jes","updated_at":"2026-01-01T11:40:47.686684035Z","closed_at":"2026-01-01T11:40:47.686684035Z","close_reason":"Fixed in PR #76. POST /docs now accepts optional 'content' field in request body for setting initial document content. Returns 400 and cleans up if content setting fails."}
{"id":"CP-bnv","title":"Add path-based HTTP API endpoints","design":"Needs design discussion: What should the path-based API look like? Options: 1) /files/path/to/file.txt 2) /docs?path=path/to/file.txt 3) Something else. Need to decide URL structure, how to handle URL encoding of paths, and whether to support both path and UUID access on same endpoints.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-29T08:33:32.251084948Z","created_by":"jes","updated_at":"2025-12-29T21:44:24.931689601Z","closed_at":"2025-12-29T21:44:24.931689601Z","close_reason":"Added /files/*path endpoints for path-based HTTP API access. Merged in PR #24."}
{"id":"CP-bth","title":"Sync tool should respect environment variables as set by orchestrator","description":"The sync client (commonplace-sync) should read and respect environment variables that are set by the orchestrator process. This allows the orchestrator to configure sync behavior (server URL, node ID, etc.) through environment variables rather than requiring all configuration to be passed as CLI arguments.\n\nNote: This issue was recovered from commit ee6f395 after being accidentally deleted during a beads sync conflict.","notes":"Reviewed: sync tool already respects COMMONPLACE_SERVER, COMMONPLACE_NODE, COMMONPLACE_FORK_FROM via clap env attribute. May need COMMONPLACE_MQTT if direct MQTT support added to sync.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T06:44:05.946481773Z","created_by":"jes","updated_at":"2025-12-30T18:42:26.376893745Z","closed_at":"2025-12-30T18:42:26.376893745Z","close_reason":"Closed"}
{"id":"CP-c1b","title":"Fix P1: Start sync tasks for newly created local files (PR #4)","description":"From PR #4 Codex review: In directory mode, create/modify events only trigger a schema update but don't start sync tasks for the new files.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:21.87906-08:00","updated_at":"2025-12-26T23:43:55.607923-08:00","closed_at":"2025-12-26T23:43:55.607923-08:00","close_reason":"Already fixed and merged to main. The DirEvent::Created handler in directory_watcher_task (sync.rs lines 805-828) now calls spawn_file_sync_tasks for newly created local files."}
{"id":"CP-c1j","title":"Cross-fs-root linking via commonplace-link","description":"Enable commonplace-link to assign shared UUIDs across different fs-roots. This allows files in separate sync sandboxes to share content through the server.\n\nUse case: text-to-telegram and bartleby run in separate sandboxes. We need text-to-telegram/content.txt to sync with workspace/telegram/content.txt by sharing the same UUID.\n\nApproach: \n1. Create a 'linking workspace' that can reference files from multiple fs-roots\n2. Use commonplace-link within the linking workspace to assign shared UUIDs\n3. Individual sandbox syncs respect UUIDs assigned externally\n\nSee docs/SANDBOX_LINKING.md for full architecture.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-01T04:54:08.973778925Z","created_by":"jes","updated_at":"2026-01-01T04:59:07.233301299Z","closed_at":"2026-01-01T04:59:07.233301299Z","close_reason":"Not needed - single workspace tree with subdirectories solves the problem. See docs/SANDBOX_LINKING.md"}
{"id":"CP-c7h","title":"Podman for untrusted sandbox","description":"Use Podman containers for sandboxed execution of untrusted code. Provides stronger isolation than temp directory sandbox for running arbitrary user-provided commands.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T19:39:21.869408178Z","created_by":"jes","updated_at":"2025-12-30T19:39:21.869408178Z"}
{"id":"CP-ce1","title":"Implement .processes.json discovery for conductor","description":"Conductor discovers .processes.json files in the document tree and automatically launches/manages declared processes. Enables user-defined processes to attach to file paths without central configuration.\n\nSee: docs/plans/2025-12-30-processes-json-design.md\n\nTasks:\n- Parse .processes.json format (command, owns, cwd)\n- Watch document tree for .processes.json changes\n- Launch processes with COMMONPLACE_PATH and COMMONPLACE_MQTT env vars\n- Restart with exponential backoff on failure\n- Handle conflicts (warn if two processes claim same path)\n- Update counter example to use this convention","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T04:17:59.60264365Z","created_by":"jes","updated_at":"2025-12-30T04:56:47.832163772Z","closed_at":"2025-12-30T04:56:47.832163772Z","close_reason":"Implemented .processes.json discovery for conductor. Created discovery.rs with config parsing and process manager. Updated counter example to use env vars. PR #35 merged."}
{"id":"CP-ceq","title":"Test that new files created in sandbox get synced as new documents","description":"When a sandboxed process creates a new file that doesn't exist in the schema, the sync should:\n1. Detect the new file\n2. Create a new document on the server with a new UUID\n3. Add the file to the local schema\n4. Push the updated schema to the server\n\nNeed integration tests to verify this works correctly in sandbox mode.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-01T19:25:43.482719737Z","created_by":"jes","updated_at":"2026-01-01T19:25:43.482719737Z"}
{"id":"CP-cgi","title":"Fix P1: Use JSON replay when pushing Y.Map schema updates (PR #6)","description":"From PR #6 Codex review: The change switches the initial fs-root schema write to a Y.Map update but needs to use JSON replay instead for proper handling.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:21.54461-08:00","updated_at":"2025-12-26T23:39:41.921295-08:00","closed_at":"2025-12-26T23:39:41.921295-08:00","close_reason":"Already fixed in PR #7 (CP-8fz: Fix server replay to use node's content type). The replay.rs now handles ContentType::Json by initializing a map root and serializing via map.to_json(). Merged to main."}
{"id":"CP-ckq","title":"CRDT merge fails for concurrent edits from linked files","description":"When two files are linked to the same server document (via shared node_id), concurrent edits from both syncs produce incorrect merges.\n\n**Reproduction:**\n1. Set up file linking: content.txt ↔ prompts.txt (same node_id)\n2. Write 'test message' to content.txt\n3. Wait for sync to propagate to prompts.txt\n4. Clear BOTH files simultaneously\n5. Observe: server HEAD still has content, files get content restored\n\n**Expected:** Server HEAD should be empty, files should stay empty\n\n**Actual:** Server HEAD shows 15 bytes after both syncs uploaded 'delete 15 chars'\n\n**Log evidence:**\n- Uploaded: 0 chars inserted, 15 deleted (cid: bb01f73e)\n- Uploaded: 0 chars inserted, 15 deleted (cid: 502649a6)  \n- Wrote server content: 15 bytes at 502649a6\n\n**Root cause analysis:**\nThe sync protocol wasn't designed for multiple sync clients connected to the same document. Each sync maintains its own last_written_cid and parent tracking. When both upload with the same parent:\n1. First upload creates commit A (parent P)\n2. Second upload creates commit B (parent P, but HEAD is now A)\n3. Server enters merge path for B\n4. Merge computation produces wrong result\n\nThis is likely related to CP-f20 (race condition fix) but is a deeper issue with how CRDT updates are computed and applied in the merge path.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T09:36:52.554169483Z","created_by":"jes","updated_at":"2026-01-01T10:12:15.57286668Z","closed_at":"2026-01-01T10:12:15.57286668Z","close_reason":"Fixed in PR #72. Text diffs now use server's actual Yjs state via get_yjs_state() + compute_diff_update_with_base().","comments":[{"id":9,"issue_id":"CP-ckq","author":"jes","text":"## Root Cause Identified (Debug Session 2026-01-01)\n\nThrough debug logging, identified the actual root cause:\n\n### The Bug\nIn src/diff.rs, compute_diff_update creates a **fresh YDoc** with hardcoded client IDs:\n- base_doc = Doc::with_client_id(1)\n- target_doc = Doc::with_client_id(2)\n\n### Why This Fails\n1. Text diffs for the fast path use compute_diff_update(\u0026doc.content, new_content)\n2. This creates updates referencing character positions using client IDs 1 and 2\n3. The server's actual YDoc has characters inserted by **different** client IDs\n4. Yjs uses (client_id, clock) pairs to identify characters\n5. When the update tries to delete, it can't find matching characters\n6. **Result:** Delete operations become no-ops\n\n### Evidence from Logs\nAPPLY: doc content BEFORE update = 'test message' (13 bytes)\nAPPLY: doc content AFTER update = 'test message' (13 bytes)\nThe delete was applied but content didn't change!\n\n### The Fix\nText types need to use the server's actual Yjs state, like JSON types already do.\n\nChange in src/services/document.rs lines 635 and 651:\nFROM: diff::compute_diff_update(\u0026doc.content, new_content)\nTO: Use get_yjs_state(id) + compute_diff_update_with_base()","created_at":"2026-01-01T09:59:53Z"}]}
{"id":"CP-ckt","title":"Fix P1: URL-encode derived node IDs for nested files (PR #4)","description":"From PR #4 Codex review: When syncing directories, file.relative_path will include / characters which need to be URL-encoded for node IDs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:22.662002-08:00","updated_at":"2025-12-26T23:42:34.654703-08:00","closed_at":"2025-12-26T23:42:34.654703-08:00","close_reason":"Already fixed in PR #4 (043d0c2). The encode_node_id function was added to URL-encode node IDs containing slashes. All node ID usages in sync.rs now use this function. Merged to main."}
{"id":"CP-cv9","title":"Validate at_commit CID belongs to requested document (P2 from codex review)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T06:23:26.603794724Z","created_by":"jes","updated_at":"2025-12-30T23:01:36.990246638Z","closed_at":"2025-12-30T23:01:36.990246638Z","close_reason":"Validated at_commit CID in get_head, fork_document, and replace_content. PR #52 merged.","labels":["api","security"],"comments":[{"id":2,"issue_id":"CP-cv9","author":"jes","text":"From codex review on PR #36 (src/api.rs:410):\n\nThe ?at_commit path replays commits solely by CID without verifying that the CID is part of the requested document's history. CommitReplayer::get_content_and_state_at_commit ignores the provided doc id, so a caller who knows a CID from another document can fetch that other document's state through /docs/:id/head?at_commit=... (or get misinterpreted content if content types differ).\n\nFix: Check that target_cid is reachable from the document head before replaying.","created_at":"2025-12-30T06:23:35Z"}]}
{"id":"CP-cxj","title":"Sync tool skips files with unknown extensions","description":"Ensure sync tool skips files with extensions it doesn't understand rather than failing or corrupting them.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T17:54:27.688193893Z","created_by":"jes","updated_at":"2025-12-30T18:09:02.091283573Z","closed_at":"2025-12-30T18:09:02.091283573Z","close_reason":"Already implemented - is_allowed_extension() function filters files by ALLOWED_EXTENSIONS constant, used in directory scanning and file event handlers"}
{"id":"CP-dgu","title":"Sync tool: persist state locally for offline change detection","description":"The sync tool currently has no local state persistence. On restart, it fetches HEAD from the server and may overwrite local changes made while sync was stopped.\n\n## Current Behavior\n- SyncState is purely in-memory (last_written_cid, last_written_content)\n- On startup, fetches server HEAD and writes to local file\n- --initial-sync flag offers limited control (skip/local/server) but no conflict detection\n- Local changes made while offline could be silently lost\n\n## Proposed Solution\nPersist sync state to a local file (e.g., .commonplace-sync.json or alongside each synced file):\n- Last synced CID\n- Last synced content hash\n- Timestamp of last sync\n\nOn restart:\n1. Load persisted state\n2. Compare local file hash to persisted hash → detect local modifications\n3. Fetch server HEAD → detect server modifications  \n4. If both modified: conflict (prompt user or use strategy flag)\n5. If only local modified: push to server\n6. If only server modified: pull to local\n7. If neither modified: resume normal sync\n\n## Files to modify\n- src/bin/sync.rs - Add state persistence and conflict detection\n- Possibly src/sync/ modules for shared types","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T05:08:27.003489287Z","created_by":"jes","updated_at":"2025-12-30T06:26:58.408628459Z","closed_at":"2025-12-30T06:26:58.408628459Z","close_reason":"Implemented sync state persistence. PR #36 merged. State file tracks last_synced_cid and file hashes. Detects offline changes on restart. CRDT merge logic deferred to follow-up.","comments":[{"id":1,"issue_id":"CP-dgu","author":"jes","text":"Design complete: docs/plans/2025-01-02-sync-state-persistence-design.md\n\nKey design decisions:\n- State file: .{basename}.commonplace-sync.json beside synced target (not inside)\n- Uses CRDT merge instead of manual conflict resolution\n- Stores last_synced_cid + file hashes, not content\n\nBLOCKING: Need to add ?at_commit query param to /head endpoint first (infrastructure exists via CommitReplayer, just not exposed)","created_at":"2025-12-30T05:45:25Z"}]}
{"id":"CP-dnc","title":"Make sync robust when a process uses atomic-writes to edit a file","description":"The file watcher in src/sync/watcher.rs uses is_modify() to detect file changes. While this should catch rename events (since Modify(Name(To)) is a Modify variant), there are potential edge cases:\n\n1. Directory watcher (lines 179-209) explicitly handles rename modes - robust\n2. File watcher (lines 70-86) only checks is_modify() - less explicit\n\nInvestigate:\n- What happens if editor does delete+create instead of atomic rename?\n- Platform-specific inotify behavior (path vs inode watching)\n- Does watcher need to re-attach after file replacement?\n\nConsider:\n- Add explicit rename handling to file_watcher_task\n- Add integration tests with atomic write patterns\n- Test with vim, emacs, VSCode atomic saves","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T22:52:32.17908978Z","created_by":"jes","updated_at":"2025-12-31T23:04:38.726997837Z","closed_at":"2025-12-31T23:04:38.726997837Z","close_reason":"Watches parent directory for atomic writes, explicit rename handling, 4 integration tests"}
{"id":"CP-egb","title":"Sandboxed JS evaluator with document subscriptions and output","description":"Run a JS file in a sandbox with the ability to:\n- Declare dependencies on other commonplace documents\n- Subscribe to commits on those dependencies\n- Create a read-only output document\n- Listen for commands on the output document's path\n- Emit events as that document\n\nThe JS file acts as a reactive transform: inputs → computation → output document.","design":"OPEN QUESTIONS for implementation:\n1. What JS runtime to use (Deno, quickjs, deno_core)?\n2. What APIs are exposed to JS (document, subscribe, emit)?\n3. How to declare dependencies - in JS code or metadata file?\n4. How to limit resource usage (memory, CPU, network)?\n5. Where does the JS file live - in commonplace doc or filesystem?\n6. How to handle errors and crashes - restart policy?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.433243-08:00","updated_at":"2025-12-30T01:45:22.787863201Z","dependencies":[{"issue_id":"CP-egb","depends_on_id":"CP-nno","type":"blocks","created_at":"2025-12-28T22:50:33.552787-08:00","created_by":"daemon"}]}
{"id":"CP-ejh","title":"Refactor api.rs: Extract document handlers to service layer","description":"api.rs is 918 lines. Extract document CRUD operations into a service layer module (`src/services/document.rs`), separating business logic from HTTP handler concerns.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-30T00:34:51.124071-08:00","updated_at":"2025-12-30T16:17:43.597788755Z","closed_at":"2025-12-30T16:17:43.597788755Z","close_reason":"Closed"}
{"id":"CP-eoy","title":"commonplace-link: support linking anywhere within a checked out file tree","description":"Currently commonplace-link only works for files in the same directory. For use cases like linking bartleby's workspace files to text-to-telegram files, we need cross-directory linking within a synced tree.\n\nProposed behavior:\n- commonplace-link source target (where both are in the same synced workspace tree)\n- Updates both files' schemas to share the same UUID\n- When either file is edited, both sync to the same document\n\nUse case: bartleby/prompts.txt linked to telegram/content.txt so telegram messages become bartleby prompts, and bartleby/output.txt linked to telegram/input.txt so bartleby responses go to telegram.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T23:23:03.804284034Z","created_by":"jes","updated_at":"2026-01-01T01:58:24.737984163Z","closed_at":"2026-01-01T01:58:24.737984163Z","close_reason":"Implemented cross-directory linking support. Commit 2c99666."}
{"id":"CP-eyi","title":"Cron-style recurring scheduled events","description":"Fire events on a recurring schedule (like crontab). Use cases:\n- Periodic document refresh triggers\n- Scheduled backup/export jobs\n- Regular polling of external sources\n- Time-based workflow triggers\n\nCould be defined as a special node type or as a configuration on documents.","design":"OPEN QUESTIONS for implementation:\n1. Where are schedules stored - in a special document, node metadata, or separate config?\n2. What format for cron expressions (standard cron or extended)?\n3. What event type is fired on schedule trigger?\n4. How to handle timezone - UTC only or configurable?\n5. Should missed events (server was down) be replayed or skipped?\n6. Is this a separate service or integrated into commonplace-store?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.565001-08:00","updated_at":"2025-12-30T01:44:47.450426047Z"}
{"id":"CP-f20","title":"Bidirectional CRDT sync fails for producer-consumer file patterns","description":"When two files are linked with shared UUIDs for bidirectional sync, deletions on one side get restored instead of propagating.\n\nExample: bartleby appends responses to output.txt, which syncs to text-to-telegram/input.txt. text-to-telegram pops (removes) lines after sending to Telegram. The sync should propagate this deletion back to output.txt, but instead the deleted lines get restored from output.txt.\n\nExpected behavior: Deletion in input.txt → Yjs delete operation → syncs to server → propagates to output.txt (line removed from both)\n\nActual behavior: Deletion in input.txt gets overwritten by sync restoring content from output.txt\n\nPossible causes:\n1. File watcher not detecting text-to-telegram's atomic write (_atomic_write via tempfile rename)\n2. Diff algorithm not generating proper delete operations\n3. Race condition: output.txt re-syncs before input.txt deletion propagates\n4. Sync direction priority issue - maybe 'initial-sync local' affects ongoing sync behavior\n\nImpact: Causes spam loops when using file linking for message passing between applications.","notes":"Theory: SSE server edits are skipped when local content differs from last_written_content, but the sync client only refreshes HEAD when an echo is detected. In producer-consumer, consumer deletes lines → SSE to producer; producer has local pending changes (append or atomic write) so handle_server_edit sets needs_head_refresh and returns. upload_task clears needs_head_refresh when processing the local change but only calls refresh_from_head on echo; on a real local upload it never refreshes. That means the producer uploads its stale content (with deleted lines) and overwrites the deletion. See src/sync/sse.rs:229-292 (skip server edit on local changes sets needs_head_refresh) and src/sync/file_sync.rs:120-210 (needs_head_refresh cleared but only used on echo path). Fix likely: after any successful upload where needs_head_refresh was set, refresh from HEAD (or merge) so server edits aren't lost.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T07:47:10.941526886Z","created_by":"jes","updated_at":"2026-01-01T08:15:49.177770661Z","closed_at":"2026-01-01T08:15:49.177770661Z","close_reason":"Fixed in PR #71. Re-check needs_head_refresh after upload to catch SSE events that arrived during upload."}
{"id":"CP-g0c","title":"Sync corrupts .commonplace.json schema - overwrites to {} or {version:1}","description":"When running commonplace-sync with --directory and --node, the local .commonplace.json schema gets corrupted. It starts with a proper schema (version, root, entries with files) but gets repeatedly overwritten to just {} or {\"version\":1}. The fs-root document on the server ends up with content: {} instead of the full schema. This breaks directory sync completely.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T01:49:36.833268107Z","created_by":"jes","updated_at":"2026-01-01T01:54:58.343768111Z","closed_at":"2026-01-01T01:54:58.343768111Z","close_reason":"Fixed by validating schema before writing to local file. Commit 759ddfb."}
{"id":"CP-hm9","title":"MCP server: Keep MQTT event loop alive until publish is delivered","design":"From Codex review on PR #31: The event loop is capped at 2 seconds, so if broker connection takes longer, the publish() call only enqueues the packet and the loop stops before it can be sent/acked. fire_command returns success even if command was not delivered. Consider keeping a persistent MQTT client or waiting for ConnAck/PubAck before reporting success. File: src/bin/mcp.rs:73","status":"open","priority":3,"issue_type":"bug","created_at":"2025-12-30T02:22:36.905947547Z","created_by":"jes","updated_at":"2025-12-30T02:22:43.66815698Z"}
{"id":"CP-i0v","title":"File link UUIDs get overwritten when orchestrator restarts","description":"When the orchestrator restarts with a fresh database, the server's fs reconciler generates new UUIDs for entries instead of using the UUIDs from the local .commonplace.json schema.\n\n**Expected:** The linked UUIDs (e.g., aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa) should be preserved from the local schema.\n\n**Actual:** Reconciler creates new UUIDs, destroying file links.\n\n**Log evidence:**\n- Reconciler created document: bartleby/prompts.txt -\u003e afd6bda9-2d8c-479b-a64d-0d4a03b90def\n- Should have used: aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa (from local schema)\n\n**Root cause hypothesis:**\nThe server's fs reconciler runs before sync can push the local schema. With --initial-sync local, the sync should push first, but there's a race condition or ordering issue.\n\n**Workaround:** None currently - manual schema restoration required after each restart.","notes":"Theory: On restart with fresh DB, sync scans the directory and only preserves UUIDs if it can parse local .commonplace.json. If that file is missing/unreadable at startup (or path mismatch), scan_directory generates schema without node_id fields. That schema is pushed first (initial-sync local), so the server reconciler assigns fresh UUIDs. Immediately after, sync builds uuid_map from the server schema and uses those IDs for file sync, effectively overwriting the intended link UUIDs. Root cause is startup ordering/availability of .commonplace.json (or parse failure) rather than reconciler ignoring node_id.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T10:33:03.4426906Z","created_by":"jes","updated_at":"2026-01-01T11:18:07.089985344Z","closed_at":"2026-01-01T11:18:07.089985344Z","close_reason":"Fixed in PR #73. Nested schemas for node-backed directories are now persisted locally and restored on startup with --initial-sync local.","comments":[{"id":10,"issue_id":"CP-i0v","author":"jes","text":"Root cause found: The reconciler's migrate_inline_subdirectories() generates new UUIDs for inline subdirectories (line 521 in reconciler.rs) when migrating them to node-backed format. \n\nThe fix: The reconciler should NOT migrate inline directories to node-backed format. The inline format with explicit node_ids is the correct representation for file linking. Migration should only generate UUIDs for entries that don't have them, not restructure the schema.\n\nAlternatively, we could make migration opt-in or disable it entirely when the schema has inline entries with node_ids.","created_at":"2026-01-01T10:53:03Z"}]}
{"id":"CP-ia7","title":"CRDT merge corrupts JSON version field","description":"When pushing schema updates to an fs-root document that already has content, the CRDT merge can corrupt the JSON. Specifically, the 'version' field which should be integer 1 becomes string 've'. This appears to be a character-level diff/merge issue where {\"version\": 1} gets partially merged and produces garbage.\n\nThe corruption causes reconciler to fail with 'JSON parse error: invalid type: string \"ve\", expected u32'.\n\nWorkaround: only push to empty fs-root documents.\n\nReproduction:\n1. Start server with --fs-root and --database\n2. Run sync with --initial-sync local (pushes schema)\n3. Modify local .commonplace.json\n4. Run sync again with --initial-sync local\n5. Server schema now has corrupted version field","notes":"Diagnosis: DocumentStore::set_content uses diff::compute_diff_update (Y.Text char diff) regardless of content type. This is called by fs reconciler when migrating inline subdirectories and when updating fs-root schema. For JSON docs (ContentType::Json/JsonArray/Jsonl), applying a text-based Yjs update corrupts the underlying Y.Map/Y.Array state. That corrupted Yjs state then merges with later schema edits and can turn numeric fields into junk strings (e.g. version=\"ve\").\\n\\nLikely fix: make set_content content-type aware. For JSON/JSONL/JsonArray, generate a Yjs update with create_yjs_json_update/create_yjs_jsonl_update (using current ydoc state as base) instead of text diff; keep text diff only for Text/Xml. Alternatively route reconciliation updates through DocumentService::replace_content so JSON merge logic is used.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T06:13:37.424739978Z","created_by":"jes","updated_at":"2026-01-01T06:56:57.43341078Z","closed_at":"2026-01-01T06:56:57.43341078Z","close_reason":"Fixed in PR #70. set_content now uses content-type aware Yjs updates."}
{"id":"CP-jnf","title":"Support JSON files as Yjs map/array types in directory sync","description":"Summary: Allow synced JSON files to be stored as Yjs map/array types (not plain text) so JSON structure is preserved in CRDT.\n\nFiles to modify:\n- src/document.rs (content type handling / default doc type)\n- src/diff.rs (JSON diff generation if needed)\n- src/bin/sync.rs (JSON file handling, initial sync)\n- src/sync/content_type.rs (content type mapping, potentially new metadata)\n- docs/FILESYSTEM.md (clarify JSON type behavior)\n- docs/WIRING_DIAGRAM_FILES.md (if wiring files need special handling)\n\nImplementation steps:\n1. Identify how JSON documents are represented in yrs (map/array) vs text and how current commits are applied.\n2. Decide on encoding for JSON files in sync (map vs array based on top-level JSON).\n3. Update sync upload/replace logic to send JSON updates rather than text edits for JSON files.\n4. Ensure server-side content retrieval returns serialized JSON for map/array docs.\n5. Add tests/fixtures for JSON map/array round-trips through sync.\n\nExample:\n- Before: file data.json stored as plain text in Yjs text.\n- After: data.json stored as Yjs map or array (based on top-level JSON), serialized to JSON text on read/write.\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T13:28:50.035996-08:00","updated_at":"2025-12-28T14:00:59.660408-08:00","closed_at":"2025-12-28T14:00:59.660408-08:00","close_reason":"Implemented JSON map/array sync support"}
{"id":"CP-jpx","title":"Sync client fails when files have pre-set node_ids but reconciler not running","description":"When .commonplace.json has pre-set node_ids (for file linking), sync correctly reads them but then waits forever for a reconciler to create the documents. The sync should either:\n1. Create documents directly via POST /docs if they don't exist\n2. Or clearly require --fs-root on the server\n\nCurrently blocks bartleby-telegram file linking use case.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-31T23:55:18.052642482Z","created_by":"jes","updated_at":"2026-01-01T00:04:03.65171956Z","closed_at":"2026-01-01T00:04:03.65171956Z","close_reason":"Not a bug - works when server has --fs-root enabled. Documented correct workflow in docs/FILESYSTEM.md."}
{"id":"CP-jrc","title":"Sync overwrites local schema with server content, losing commonplace-link changes","description":"When sync starts and server already has content, it fetches the server schema and overwrites the local .commonplace.json file. This destroys any changes made by commonplace-link.\n\nRoot cause: dir_sync.rs:783-791 unconditionally writes server schema to local file when strategy=skip (server has content).\n\nRepro:\n1. Run sync to establish initial schema\n2. Run commonplace-link to create shared UUIDs  \n3. Run sync again\n4. Local schema is overwritten with server's old schema, losing the link\n\nExpected: Sync should either push local schema changes to server, or merge local+server schemas.\n\nLocation: src/sync/dir_sync.rs:783-791","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T05:46:00.069867795Z","created_by":"jes","updated_at":"2026-01-01T05:52:29.616008208Z","closed_at":"2026-01-01T05:52:29.616008208Z","close_reason":"Fixed by preserving local schema when it exists. Merged in PR #68."}
{"id":"CP-jwf","title":"Refactor sync.rs: Extract SyncState into separate module","description":"sync.rs is 2,407 lines - the largest file in the codebase. Extract `SyncState` struct and its associated methods (echo detection, write tracking, hash tracking) into `src/sync/state.rs`.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-30T00:34:50.838547-08:00","updated_at":"2025-12-30T08:54:16.77161781Z","closed_at":"2025-12-30T08:54:16.77161781Z","close_reason":"Extracted SyncState and PendingWrite to src/sync/state.rs. Added documentation for echo detection and write barrier. Merged in PR #38."}
{"id":"CP-ksf","title":"CLI tool for firing commands to commonplace paths","description":"A command-line tool that sends commands to a specified commonplace document path. Allows scripting and manual interaction with commonplace documents via their red port (events/commands).","design":"Needs design discussion: High-level feature request without implementation details. Requires specification of API design, data model, and integration points before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.268771-08:00","updated_at":"2025-12-29T23:50:06.348786945Z","closed_at":"2025-12-29T23:50:06.348786945Z","close_reason":"commonplace-cmd CLI implemented. Merged in PR #28."}
{"id":"CP-l5b","title":"Orchestrator leaves orphaned processes when killed","description":"When orchestrator or commonplace-sync is killed (SIGTERM/SIGKILL), spawned child processes (e.g., bartleby.py, text_to_telegram) are left orphaned. Need proper process cleanup - either kill children on exit or use process groups.","status":"open","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:42:53.377806426Z","created_by":"jes","updated_at":"2026-01-01T19:42:53.377806426Z"}
{"id":"CP-lav","title":"Python client: y_py YDoc not thread-safe with paho-mqtt callbacks","design":"The y_py (Yjs Python bindings) YDoc panics when accessed from a different thread than where it was created. paho-mqtt runs message callbacks in a background thread. When command handlers try to publish_edit(), they access YDoc from the MQTT thread, causing panic. Fix options: 1) Use queue to dispatch updates from MQTT thread to main thread, 2) Create YDoc in MQTT thread, 3) Use asyncio-based MQTT client with single-threaded event loop.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-30T00:30:34.203735202Z","created_by":"jes","updated_at":"2025-12-30T01:17:06.747552054Z","closed_at":"2025-12-30T01:17:06.747552054Z","close_reason":"Fixed by implementing queue-based pattern for YDoc operations. MQTT callbacks queue work, main loop processes. Committed in ded73c4."}
{"id":"CP-li3","title":"Deprecate wiring diagram concept","description":"The wiring diagram concept should be deprecated and removed from the codebase.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:44.059396274Z","created_by":"jes","updated_at":"2025-12-29T08:56:46.462777465Z","closed_at":"2025-12-29T00:50:28.541758-08:00","close_reason":"PR #18 merged. Deprecated nodes abstraction, restored /nodes HTTP endpoints for sync, renamed /sse/nodes to /sse/docs, fixed fs-root ContentType. Follow-up issues filed: CP-bnv (path-based API), CP-pta (nodes→docs rename), CP-m2g (sync path-based)."}
{"id":"CP-lr9","title":"Sync race condition causes output file overwrites","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-31T20:09:30.137946956Z","created_by":"jes","updated_at":"2025-12-31T21:51:40.994526815Z","closed_at":"2025-12-31T21:51:40.994526815Z","close_reason":"Fixed in PR #59. refresh_from_head now checks for pending local changes before overwriting.","comments":[{"id":7,"issue_id":"CP-lr9","author":"jes","text":"Root cause identified: sync client processes its own SSE edit events. Simple fix found - check edit.commit.author == sync-client in handle_server_edit. See CP-lr9-investigation.md for full analysis.","created_at":"2025-12-31T20:21:16Z"}]}
{"id":"CP-lzb","title":"Fix P1: Start sync tasks for files created from server schema (PR #4)","description":"From PR #4 Codex review: When a new path appears in the server schema, the handler doesn't start sync tasks for the new files.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:22.281537-08:00","updated_at":"2025-12-26T23:43:55.692683-08:00","closed_at":"2025-12-26T23:43:55.692683-08:00","close_reason":"Already fixed and merged to main. The handle_schema_change function now takes a spawn_tasks parameter, and runtime SSE events (line 1186) pass spawn_tasks=true to spawn sync tasks for new server-created files."}
{"id":"CP-lzy","title":"Sync sandbox exposes commonplace CLI tools to child","description":"Sync sandbox should ensure commonplace command line tools are available to the child process (in PATH or similar).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:50:47.47569485Z","created_by":"jes","updated_at":"2025-12-30T22:09:01.350202303Z","closed_at":"2025-12-30T22:09:01.350202303Z","close_reason":"Closed","dependencies":[{"issue_id":"CP-lzy","depends_on_id":"CP-8ci","type":"blocks","created_at":"2025-12-30T17:50:58.721422649Z","created_by":"daemon"},{"issue_id":"CP-lzy","depends_on_id":"CP-q3m","type":"blocks","created_at":"2025-12-30T18:02:57.44355175Z","created_by":"daemon"}],"comments":[{"id":5,"issue_id":"CP-lzy","author":"jes","text":"Accidentally closed - depends on CP-8ci","created_at":"2025-12-30T21:02:26Z"}]}
{"id":"CP-m2g","title":"Convert sync client to use path-based API","design":"Once path-based HTTP APIs exist (CP-bnv), update commonplace-sync to use paths like /files/notes/todo.txt instead of requiring UUIDs. This would simplify the sync client - no need to create nodes or track UUIDs, just sync files by their natural paths.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-29T08:35:40.683147536Z","created_by":"jes","updated_at":"2025-12-29T22:21:03.49437558Z","closed_at":"2025-12-29T22:21:03.49437558Z","close_reason":"Added --use-paths flag to sync client for path-based API. URL builders select between /files/*path and /docs/:id routes with proper path encoding. Merged in PR #25.","dependencies":[{"issue_id":"CP-m2g","depends_on_id":"CP-bnv","type":"blocks","created_at":"2025-12-29T08:35:57.462826032Z","created_by":"daemon"},{"issue_id":"CP-m2g","depends_on_id":"CP-pta","type":"blocks","created_at":"2025-12-29T08:37:30.460677237Z","created_by":"daemon"}]}
{"id":"CP-nno","title":"External process MQTT client as first-class citizen","description":"Allow a separate Unix process to connect to MQTT and perform all the same actions as the JS sandbox evaluator:\n- Subscribe to document commits\n- Create/own output documents\n- Receive commands on owned document paths\n- Emit events as owned documents\n\nThis makes external processes (any language) first-class participants in the commonplace reactive graph, using MQTT as the protocol.","design":"Needs design discussion: High-level feature request without implementation details. Requires specification of API design, data model, and integration points before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.52436-08:00","updated_at":"2025-12-30T01:26:42.019335953Z","closed_at":"2025-12-30T01:26:42.019335953Z","close_reason":"Python client example complete with FileProcess base class and CounterExample. Bug fixes for sync protocol and thread safety merged in 00fa478."}
{"id":"CP-o1h","title":"Fix: Merge commits should include both parent_cid and current HEAD as parents","description":"When parent_cid differs from HEAD in replace endpoint, the new commit only includes parent_cid as its parent. This drops the current HEAD from the commit graph. On history replay, the concurrent edits from HEAD are lost.\n\nFix: When parent_differs is true, the commit should have BOTH parent_cid AND current_head as parents.\n\nFound by local codex review on PR #37.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-30T08:14:26.210722759Z","created_by":"jes","updated_at":"2025-12-30T08:24:36.109315944Z","closed_at":"2025-12-30T08:24:36.109315944Z","close_reason":"Fixed merge commits to include both parent_cid AND current HEAD when they differ. This preserves concurrent edits in commit DAG for proper history replay. Committed in 7ebc4bd."}
{"id":"CP-o2h","title":"Evaluate whether NodeRegistry is still needed after HTTP/store split","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T00:52:45.145726221Z","created_by":"jes","updated_at":"2025-12-29T04:12:26.221158382Z","closed_at":"2025-12-29T04:12:26.221158382Z","close_reason":"Evaluated: NodeRegistry is NOT duplicated after HTTP/store split. Store owns it (document state, wiring, fs reconciliation). HTTP is stateless (MQTT gateway only). Architecture is already optimal - no changes needed.","dependencies":[{"issue_id":"CP-o2h","depends_on_id":"CP-8t3","type":"blocks","created_at":"2025-12-29T00:52:52.493729194Z","created_by":"daemon"}]}
{"id":"CP-og0","title":"Fork detection: binary file hash mismatch","description":"In CP-rs3 implementation, fork detection for binary files won't work correctly because:\n- Initial sync stores hash of base64-encoded content (via scan_directory_with_contents)\n- New file detection hashes raw bytes before encoding\n\nThis means identical binary files won't be detected as copies. Text files work correctly.\n\nFix: Hash raw file bytes in both cases, before any base64 encoding.","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-12-30T20:07:20.775344004Z","created_by":"jes","updated_at":"2025-12-31T23:04:39.527009741Z","closed_at":"2025-12-31T23:04:39.527009741Z","close_reason":"Fixed hash consistency - both paths now hash raw bytes before base64"}
{"id":"CP-oi3","title":"JSONL file support","description":"Internally stored as a Yjs array of maps, but sync tool should check it out as JSONL format (one JSON object per line).","notes":"Needs design: How should JSONL ↔ Yjs array/map conversion work? Need to define CRDT structure for array of maps and bidirectional conversion logic.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:46:27.750869028Z","created_by":"jes","updated_at":"2025-12-30T20:49:43.561621338Z","closed_at":"2025-12-30T20:49:43.561621338Z","close_reason":"Merged PR #48 - JSONL file support"}
{"id":"CP-oji","title":"Handle rename events so new paths get sync tasks","description":"notify reports renames as `Modify(Name)` events; the current mapping treats all `is_modify()` as `DirEvent::Modified`. The modified handler only re-pushes schema and never starts new per-file sync tasks or removes old ones, so a rename leaves the new file untracked and the old path's tasks running until restart.\n\nConsider handling rename explicitly (or treating `Modify(Name)` as delete+create).","design":"Implemented by detecting `Modify(Name)` events separately from other modifications in the directory watcher. Rename events are now classified as delete+create based on RenameMode: From→Deleted, To→Created, Both/Any/Other→check path.exists() to determine direction. This ensures sync tasks are properly stopped for old paths and started for new paths.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T17:03:59.632881-08:00","updated_at":"2025-12-26T17:49:57.531409-08:00","closed_at":"2025-12-26T17:49:57.531409-08:00","close_reason":"Rename events now handled properly - Modify(Name) events are classified as delete+create based on RenameMode. Merged in PR #5.","labels":["enhancement","sync"]}
{"id":"CP-okn","title":"New orchestrator binary for process management","description":"Create a new orchestrator binary which invokes the document store and (once they exist) other processes like HTTP interface and sandboxed evaluator.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:47.418639497Z","created_by":"jes","updated_at":"2025-12-29T08:45:22.029787664Z","closed_at":"2025-12-29T03:12:03.336139764Z","close_reason":"Orchestrator binary implemented with process supervision, dependency ordering, restart policies with exponential backoff, and graceful shutdown. Merged in PR #16.","dependencies":[{"issue_id":"CP-okn","depends_on_id":"CP-8t3","type":"blocks","created_at":"2025-12-28T21:57:25.7353176Z","created_by":"daemon"}]}
{"id":"CP-pgx","title":"MCP server for firing commands to commonplace paths","description":"An MCP server that exposes commonplace document paths as callable tools. MCP clients can invoke commands on commonplace documents, bridging LLM tool-use with the commonplace reactive document system.","design":"Needs design discussion: High-level feature request without implementation details. Requires specification of API design, data model, and integration points before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.349217-08:00","updated_at":"2025-12-30T01:43:40.761417202Z","closed_at":"2025-12-30T01:43:40.761417202Z","close_reason":"Implemented commonplace-mcp server. PR #31 created - pending merge.","dependencies":[{"issue_id":"CP-pgx","depends_on_id":"CP-ksf","type":"related","created_at":"2025-12-28T22:50:33.586139-08:00","created_by":"daemon"}]}
{"id":"CP-pta","title":"Rename /nodes API to /docs throughout codebase","design":"Completed implementation. PR #20 created. Waiting for merge.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T08:37:04.362222409Z","created_by":"jes","updated_at":"2025-12-29T09:40:55.11574492Z","closed_at":"2025-12-29T09:40:55.11574492Z","close_reason":"Renamed /nodes API to /docs throughout codebase. Merged all node endpoints into document API. PR #20 merged."}
{"id":"CP-q3m","title":"CLI tool with relative path support in synced directories","description":"The command-line command-issuing tool should work inside a synced directory such that you can use relative paths to send commands to the relevant document.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:48:46.353930244Z","created_by":"jes","updated_at":"2025-12-30T18:24:55.356003983Z","closed_at":"2025-12-30T18:24:55.356003983Z","close_reason":"Added relative path support to commonplace-cmd - PR #45 merged"}
{"id":"CP-qmk","title":"Fix P1: Preserve schema deletions when pushing updates (PR #7)","description":"From PR #7 Codex review: When pushing schema updates, deletions are not being preserved. The code always posts an edit built by create_yjs_map_update but this may not handle entry deletions properly. Need to investigate and fix.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:21.270524-08:00","updated_at":"2025-12-27T00:14:06.786038-08:00","closed_at":"2025-12-27T00:14:06.786038-08:00","close_reason":"Preserve schema deletions implemented. Added state field to HEAD response, client now applies server CRDT state before making changes so deletions create proper tombstones. Merged in PR #9."}
{"id":"CP-qyj","title":"TypeScript support for sandboxed evaluator","description":"Extend the JS sandbox evaluator to support TypeScript. This could mean:\n- Transpiling TS → JS before evaluation\n- Supporting .ts file extensions in sandbox\n- Type definitions for the sandbox API (dependencies, output documents, events)\n\nThis makes the sandbox more ergonomic for larger/complex reactive transforms.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.488271-08:00","updated_at":"2025-12-28T23:53:18.488271-08:00","dependencies":[{"issue_id":"CP-qyj","depends_on_id":"CP-egb","type":"blocks","created_at":"2025-12-28T23:53:18.489746-08:00","created_by":"daemon"}]}
{"id":"CP-r2a","title":"Fix sync race condition: upload_task sends stale content during B-\u003eA sync","description":"When a server edit arrives via SSE, the handle_server_edit function fetches HEAD and writes to the local file. However, the file watcher can trigger upload_task with stale file content before the write completes, causing the old content to be synced back to the server.\n\nRoot cause: Echo detection relies on comparing file content to last_written_content, but there's a window between SSE notification and file write where upload_task can read stale content.\n\nPossible fixes:\n1. Add a flag to pause upload_task during server writes\n2. Use file modification timestamp comparison\n3. Add sequence numbers to track edit origin","design":"## Extended Barrier Pattern - REVISED AFTER CODEX REVIEW\n\n### Codex-Identified Issues:\n\n**CRITICAL: Partial writes can still trigger uploads**\nIf watcher fires during our write, content differs from pending, we upload partial/corrupted content. FIX: Don't immediately upload on mismatch - retry/re-read until content stabilizes or matches pending.\n\n**HIGH: Multiple server edits clobber pending fields**\nIf handle_server_edit runs while barrier is up, it overwrites pending_write_*, causing misclassification when first write's watcher event arrives. FIX: Use generation token (monotonic write_id) so barrier maps to exact write.\n\n**HIGH: Upload with stale parent_cid may fail**\nServer's replace endpoint may reject if parent doesn't match HEAD. FIX: Refresh HEAD before upload, or use CRDT edit endpoint for merges.\n\n**MEDIUM: Window between re-check and barrier set**\nLocal edit can slip in between re-check and write_in_progress=true. FIX: Do both atomically under write lock.\n\n**MEDIUM: Read→drop→write lock pattern is risky**\nState can change between drop(read) and acquire(write). FIX: Re-check under write lock, or use single write lock.\n\n**LOW: Watcher never fires leaves barrier stuck**\nlast_written_cid never updates, next upload uses stale parent. FIX: Timeout/fallback to finalize barrier.\n\n---\n\n### Improved Design: Token-Based Barrier\n\n```rust\nstruct SyncState {\n    last_written_cid: Option\u003cString\u003e,\n    last_written_content: String,\n    // Token-based barrier:\n    current_write_id: u64,  // Monotonic counter\n    pending_write: Option\u003cPendingWrite\u003e,\n}\n\nstruct PendingWrite {\n    write_id: u64,\n    content: String,\n    cid: String,\n    started_at: Instant,\n}\n```\n\n**handle_server_edit:**\n1. Acquire write lock\n2. If pending_write exists and not timed out, queue/skip this edit\n3. Increment current_write_id\n4. Set pending_write = Some(PendingWrite { write_id, content, cid, started_at })\n5. Release lock\n6. Write file\n7. Do NOT clear barrier (upload_task does it)\n\n**upload_task:**\n1. Read file content\n2. Acquire write lock (not read!)\n3. If pending_write exists:\n   a. If content == pending.content AND file stable (re-read matches):\n      - Clear pending, update last_written_*, done (echo)\n   b. If content != pending.content:\n      - Re-read file after short delay (50ms)\n      - If still differs after N retries: user edited, clear pending, upload\n   c. If pending.started_at \u003e 30s ago: timeout, clear pending\n4. Normal echo detection if no pending\n\n**Key improvements:**\n- Retry on mismatch instead of immediate upload (avoids partial writes)\n- Token prevents clobbering from concurrent server edits\n- Single write lock avoids ABA bugs\n- Timeout prevents stuck barrier\n- Refresh HEAD before upload on conflict path","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-29T16:02:47.797530633Z","created_by":"jes","updated_at":"2025-12-29T20:50:11.443695514Z","closed_at":"2025-12-29T20:50:11.443695514Z","close_reason":"Token-based write barrier implemented to fix sync race condition. Prevents upload_task from sending stale content during server-to-local sync. 13+ codex review iterations, all P1 issues fixed. Merged in PR #23."}
{"id":"CP-rs3","title":"File copy in sync directory triggers document fork","description":"When a new file appears in a synced directory with content that exactly matches another file already synced by the same process, automatically fork the original document rather than creating an unrelated new document. Detection: pure content hash matching against all currently synced files.","notes":"PR #47 created. Codex review requested. P2 limitation filed as CP-og0 for binary files.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:58:58.555594612Z","created_by":"jes","updated_at":"2025-12-30T20:22:08.593492297Z","closed_at":"2025-12-30T20:22:08.593492297Z","close_reason":"Merged PR #47 - file copy triggers document fork via content hash matching"}
{"id":"CP-se0","title":"One-time scheduled events (at-style)","description":"Schedule events to fire at a specific point in the future. Unlike cron (recurring), these are one-shot:\n- Reminders\n- Delayed actions\n- Future-dated triggers\n- Timeout/deadline events\n\nCould share infrastructure with cron scheduling but with single-fire semantics.","design":"OPEN QUESTIONS for implementation:\n1. How to persist scheduled events across restarts?\n2. What happens if target path doesn't exist when event fires?\n3. Should there be a 'list scheduled events' API?\n4. Can events be cancelled before they fire?\n5. What precision - seconds, milliseconds, or just minutes?\n6. Same storage and service questions as CP-eyi","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.644504-08:00","updated_at":"2025-12-30T01:44:47.476156216Z","dependencies":[{"issue_id":"CP-se0","depends_on_id":"CP-eyi","type":"related","created_at":"2025-12-28T23:53:29.351623-08:00","created_by":"daemon"}]}
{"id":"CP-sz8","title":"Refactor document.rs: Extract ContentType to dedicated module","description":"document.rs has ContentType enum with MIME conversion, default content generation, and detection logic. Extract to `src/content_type.rs` to be shared between document.rs and sync/ modules (which has partial duplication).","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-30T00:34:51.455397-08:00","updated_at":"2025-12-30T16:42:58.50460762Z","closed_at":"2025-12-30T16:42:58.50460762Z","close_reason":"Closed"}
{"id":"CP-tmo","title":"Orchestrator should watch for fs-root schema changes","description":"When the server's fs-root schema changes (e.g., via /replace), the orchestrator should detect this and update sandboxes accordingly. Currently requires restart.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-01T19:41:28.363627394Z","created_by":"jes","updated_at":"2026-01-01T19:41:28.363627394Z"}
{"id":"CP-uj2","title":"Represent directory trees as Yjs JSON (Y.Map) instead of text JSON","description":"Currently, the fs-root document uses TEXT content type with JSON stored as a text string. This was a workaround because the edit system (diff.rs, replay.rs) uses TEXT-based Yjs updates (Y.Text), but DocumentNode for JSON type uses Y.Map internally.\n\nThe proper solution would be to use native Yjs JSON structure (Y.Map) for directory schemas, which would enable:\n- Proper CRDT merging of concurrent schema changes\n- More efficient updates (only changed entries, not full document replacement)\n- Better conflict resolution for concurrent file additions/deletions","design":"Implemented Y.Map support:\n\n1. replay.rs: Extended get_content_and_state_at_commit to support JSON content type by initializing Y.Map root and using map.to_json() for extraction.\n\n2. sync.rs: Added create_yjs_map_update() and json_value_to_any() helper to convert JSON strings to Y.Map updates. Updated push_schema_to_server to use Y.Map updates for initial schema push.\n\nThis enables proper CRDT merging of concurrent schema changes and more efficient updates (only changed entries, not full document replacement).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T17:04:59.967959-08:00","updated_at":"2025-12-26T18:01:42.374357-08:00","closed_at":"2025-12-26T18:01:42.374357-08:00","close_reason":"Added Y.Map support for directory schemas: replay.rs now supports JSON content type, sync.rs uses Y.Map updates for initial schema push. Merged in PR #6.","labels":["architecture","sync","yjs"]}
{"id":"CP-w2v","title":"Directory JSON as hidden file inside checkout","description":"Synced directory JSON should be a hidden file inside the checked out directory, not outside it. Sync tool should handle this intelligently (avoid syncing the hidden file itself, proper conflict handling, etc.).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:54:00.14442659Z","created_by":"jes","updated_at":"2025-12-30T18:10:05.226276237Z","closed_at":"2025-12-30T18:10:05.226276237Z","close_reason":"Already implemented - schema stored as .commonplace.json inside checkout, ignored in scanning and watcher"}
{"id":"CP-xuw","title":"Make .processes.json dynamically add/remove processes in running conductor","description":"The conductor should watch for changes to .processes.json files and dynamically start/stop processes without requiring a restart.\n\nCurrently .processes.json is only read at startup. We need:\n1. Watch for .processes.json changes via document subscription\n2. Start new processes when added to .processes.json\n3. Stop processes when removed from .processes.json\n4. Handle graceful restarts when command/args change","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T10:51:20.920681904Z","created_by":"jes","updated_at":"2026-01-01T11:53:36.875939089Z","closed_at":"2026-01-01T11:53:36.875939089Z","close_reason":"Fixed in PR #77. Added --watch-processes flag to orchestrator for dynamic process management. Processes are started/stopped based on document changes with periodic health checks for automatic restart.","comments":[{"id":14,"issue_id":"CP-xuw","author":"jes","text":"Investigation notes:\n\n**Current Architecture:**\n1. ProcessManager (manager.rs) - Handles core processes from orchestrator config file\n2. DiscoveredProcessManager (discovered_manager.rs) - Has machinery for .processes.json but not wired up\n\n**DiscoveredProcessManager already has:**\n- add_process() / remove_process() methods\n- spawn_process() / check_and_restart()\n- Tracks processes in HashMap with ManagedDiscoveredProcess\n\n**What's needed for dynamic updates:**\n1. Add method to watch .processes.json document via SSE\n2. On document change, parse new ProcessesConfig\n3. Diff current vs new config:\n   - Stop processes that were removed\n   - Start processes that were added  \n   - Restart processes where command/args changed\n4. Wire this into the orchestrator or create dedicated mode\n\n**Implementation approach:**\nAdd watch_processes_document() method to DiscoveredProcessManager that:\n- Subscribes to document SSE stream\n- Parses edits as ProcessesConfig\n- Calls reconcile_processes() to diff and update\n","created_at":"2026-01-01T11:43:13Z"}]}
{"id":"CP-y9l","title":"tmux ↔ file integration","description":"Bidirectional sync between tmux pane content and commonplace documents:\n- Capture tmux pane content to a document (scrollback, current view)\n- Send content from a document to a tmux pane (sendkeys)\n- Subscribe to pane output as a stream\n- Control tmux sessions/windows/panes via document commands\n\nEnables terminal-as-document patterns and terminal automation.","design":"OPEN QUESTIONS for implementation:\n1. Use tmux command-line or libtmux/tmux control mode?\n2. What's the document schema for pane content?\n3. How often to capture pane content (poll vs events)?\n4. How to identify target pane (session:window.pane)?\n5. Handle scrollback or just visible content?\n6. Security - limit which sessions can be controlled?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.734354-08:00","updated_at":"2025-12-30T01:45:22.817292165Z","dependencies":[{"issue_id":"CP-y9l","depends_on_id":"CP-nno","type":"blocks","created_at":"2025-12-28T23:53:18.735182-08:00","created_by":"daemon"}]}
{"id":"CP-ylp","title":"Enforce mandatory file extensions in filesystem sync","description":"Update commonplace filesystem so that file extensions are mandatory. Only .json, .txt, .xml, .xhtml, and .bin files can be synced, and they must correspond to their Yjs implementations.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:43.205364505Z","created_by":"jes","updated_at":"2025-12-28T23:14:28.396705982Z","closed_at":"2025-12-28T23:14:28.396705982Z","close_reason":"Implemented mandatory file extension filtering for filesystem sync. Only .json, .txt, .xml, .xhtml, .bin, .md files are now synced. Added is_allowed_extension() function and filtering in scan_dir_recursive(), scan_files_recursive(), DirEvent::Created handler, and handle_schema_change(). Merged in PR #12."}
{"id":"CP-yq8","title":"Refactor sync.rs: Extract SSE subscription loop","description":"Extract SSE subscription handling from sync.rs into `src/sync/sse_client.rs`. This manages server event subscriptions, reconnection, and incoming edit processing.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-30T00:34:51.027152-08:00","updated_at":"2025-12-30T15:51:57.815913081Z","closed_at":"2025-12-30T15:51:57.815913081Z","close_reason":"Extracted SSE subscription loop to src/sync/sse.rs. Merged in PR #40.","dependencies":[{"issue_id":"CP-yq8","depends_on_id":"CP-jwf","type":"blocks","created_at":"2025-12-30T00:36:37.050903-08:00","created_by":"daemon"}]}
{"id":"CP-z7t","title":"MCP server using commonplace JSON file for tool/resource definitions","description":"An MCP server that reads a specified commonplace JSON document and exposes its contents as MCP tools, resources, and prompts. The JSON document defines the MCP schema, and the server dynamically serves those definitions to MCP clients.","design":"OPEN QUESTIONS for implementation:\n1. What JSON schema should define tools? MCP-native schema or custom format?\n2. Should this dynamically reload when the document changes?\n3. How to handle tool implementations - call external commands, evaluate JS, or just return content?\n4. Should it support resources and prompts in addition to tools?\n5. How does this relate to CP-pgx (already implemented) - replace or complement it?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.180475-08:00","updated_at":"2025-12-30T01:44:22.367660722Z"}
{"id":"CP-zif","title":"Commonplace link tool for shared document references","description":"A symlink/hardlink-like tool (possible names: synclink, commonlink) that works in a checked-out sync directory to create another file pointing to the same document UUID. Implementation likely involves editing the directory JSON to add another entry referencing the same document.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:52:42.458856392Z","created_by":"jes","updated_at":"2025-12-30T22:44:51.153396044Z","closed_at":"2025-12-30T22:44:51.153396044Z","close_reason":"Closed"}
{"id":"CP-zjl","title":"Sync tool wrapper mode: run executable in synced directory context","description":"Add a mode to invoke the sync tool that:\n\n1. Starts commonplace-sync to check out a directory tree to a local path\n2. Launches a specified executable in that synced directory context\n3. Keeps sync running while the executable is active\n4. When the child executable exits, the sync tool also exits and cleans up\n\nExample usage:\n```\ncommonplace-sync --exec \"vim .\" --server http://localhost:3000 --prefix notes --local ./workspace\n```\n\nThis enables workflows where a user wants to work on synced files with their preferred editor/tool, and have everything tear down cleanly when they're done.\n\n**Orchestrator compatibility:**\nThe sync tool should respect environment variable conventions of orchestrator-launched processes:\n- Pass through relevant env vars to the child process (e.g., `$EDITOR`, `$SHELL`, `$TERM`)\n- Respect standard orchestrator signals (SIGTERM, SIGINT) for graceful shutdown\n- Propagate child exit codes to the parent\n- Honor env-based configuration (e.g., `COMMONPLACE_SERVER`, `COMMONPLACE_PREFIX`)\n- Support `--` separator for passing args to the child executable","design":"Exec mode implementation approach: Add --exec flag to Args struct. When provided, after initial sync completes, spawn child process in synced directory using tokio::process::Command. Pass through env vars (EDITOR, SHELL, TERM, etc). Handle SIGTERM/SIGINT to gracefully shutdown both sync tasks and child. Propagate child exit code. Support -- separator via clap's trailing_var_arg.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T00:13:55.940464-08:00","updated_at":"2025-12-30T08:40:24.04936003Z","closed_at":"2025-12-30T08:40:24.04936003Z","close_reason":"Implemented exec mode for sync tool. Added --exec flag that syncs directory, launches command, keeps sync running during execution, and propagates exit code on completion. Handles signals gracefully. Pushed directly to main in 1e83d1b."}
{"id":"CP-zkk","title":"Implement CRDT merge for offline changes in sync tool","description":"Follow-up from CP-dgu. When the sync tool detects offline local changes on restart (via state file hash comparison), it should:\n\n1. Fetch historical Yjs state at last_synced_cid using ?at_commit endpoint\n2. Compute diff from historical state to current local content\n3. Create Yjs update from diff\n4. Push update to server (CRDT automatically merges with any server changes)\n5. Pull merged result and update local file\n\nThe infrastructure is ready:\n- State file tracks last_synced_cid and file hashes (CP-dgu, PR #36)\n- ?at_commit endpoint returns Yjs state at any historical commit\n- Offline change detection logs 'Detected offline local changes' on startup\n\nJust needs the merge logic implementation in run_file_mode after detecting changes.","notes":"Reviewed code: offline CRDT merge is already implemented in run_file_mode (lines 322-381). Detects offline changes, pushes via replace endpoint with last_synced_cid as parent for proper CRDT merge.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T06:27:49.553275883Z","created_by":"jes","updated_at":"2025-12-30T18:42:48.412284179Z","closed_at":"2025-12-30T18:42:48.412284179Z","close_reason":"Closed","labels":["feature"],"comments":[{"id":3,"issue_id":"CP-zkk","author":"jes","text":"Discovered from CP-dgu during implementation. Design doc: docs/plans/2025-01-02-sync-state-persistence-design.md","created_at":"2025-12-30T06:28:03Z"}]}
