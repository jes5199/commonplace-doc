{"id":"CP-08v","title":"Add MQTT support","description":"Add MQTT protocol support to commonplace. Spec will be supplied (TBD).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:45.192898672Z","created_by":"jes","updated_at":"2025-12-29T00:39:05.428000759Z","closed_at":"2025-12-29T00:39:05.428000759Z","close_reason":"MQTT support implemented with client, edits/sync/commands handlers, and topic routing. Merged in PR #12."}
{"id":"CP-0cd","title":"Blocks acceptance: File deletion not propagating to sandbox","description":"## Summary\nWhen a file is deleted from the workspace, the deletion does not propagate to the sandbox.\n\n## Repro\n1. Create `workspace/text-to-telegram/test-file.txt`\n2. Wait for sync to sandbox\n3. Delete `workspace/text-to-telegram/test-file.txt`\n4. Check sandbox\n\n## Expected\nFile should be deleted from sandbox\n\n## Actual\nFile still exists in sandbox\n\n## Blocks\nAcceptance criterion D2","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T02:21:00.600383948Z","created_by":"jes","updated_at":"2026-01-03T02:48:55.9217856Z","closed_at":"2026-01-03T02:48:55.9217856Z","close_reason":"Fixed file deletion propagation for node-backed subdirectories. Modified handle_file_deleted to use find_owning_document and push schema to correct subdirectory document."}
{"id":"CP-0f4m","title":"P2: Restart all processes sharing a script","description":"The script watch map stores a single process name per script UUID. If multiple evaluate processes use the same script, only one will restart when the script changes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-06T06:34:07.434565092Z","created_by":"jes","updated_at":"2026-01-07T01:12:38.990946447Z","closed_at":"2026-01-07T01:12:38.990946447Z","close_reason":"Changed ScriptWatchMap to Vec\u003cString\u003e - now restarts all processes sharing a script"}
{"id":"CP-0fy","title":"Sync tool should checkout directory JSON definition as .json file","description":"The sync tool (commonplace-sync) should write the JSON definition of a directory as a file named `.json` in that directory. This would allow users to see and potentially edit the directory's metadata/structure definition alongside the directory contents.","design":"Needs design discussion: What content should be in the .json file? Just metadata, or full fs-root schema? How does editing .json interact with sync? Need specification before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T14:57:56.428338-08:00","updated_at":"2025-12-29T22:37:26.417918062Z","closed_at":"2025-12-29T22:37:26.417918062Z","close_reason":"Sync client now writes fs-root schema to .commonplace.json in synced directories. Updates on server changes via SSE. Merged in PR #26."}
{"id":"CP-0j4","title":"Fix P1: Respect explicit node_id from server schema (PR #4)","description":"From PR #4 Codex review: When the server's FsSchema uses DocEntry.node_id for stable IDs, this should be respected instead of deriving IDs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:23.072384-08:00","updated_at":"2025-12-26T23:43:14.374964-08:00","closed_at":"2025-12-26T23:43:14.374964-08:00","close_reason":"Already fixed and merged to main. The handle_schema_change function now uses collect_paths_from_entry which extracts explicit node_id from DocEntry and uses it instead of deriving from path. See sync.rs lines 1249-1265 and 1358-1379."}
{"id":"CP-0kk7","title":"Show full timestamps in commonplace-log","description":"Dates in log output should show full timestamp (date + time), not just YYYY-MM-DD","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T21:27:15.366276684Z","created_by":"jes","updated_at":"2026-01-03T21:28:13.598758936Z","closed_at":"2026-01-03T21:28:13.598758936Z","close_reason":"Short format now shows YYYY-MM-DD HH:MM instead of just date"}
{"id":"CP-0vu5","title":"Handle missing head.state in delete_schema_entry","description":"## Summary\n\nFrom codex review on PR #104:\n\nThe delete path always calls `create_yjs_json_delete_key` with `base_state.as_deref()` from `/docs/:id/head`, but `state` is optional in the API. In environments where `state` isn't provided (e.g., servers without Yjs state), this call errors and `handle_file_deleted` just logs a warning, so deleted files never get removed from the schema.\n\n## Suggested Fix\n\nConsider detecting a missing `state` and falling back to a safe recovery path (e.g., rescan+merge or an explicit error that triggers retries) so deletions still propagate.\n\n## Current Behavior\n\nThe current implementation was designed to \"fail loud\" rather than silently produce a no-op update. This is intentional but may not be ideal for all environments.\n\n## Context\n\n- PR #104: Fix schema deletion propagation for targeted deletes\n- File: src/sync/client.rs:125","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-06T21:29:44.512626214Z","created_by":"jes","updated_at":"2026-01-06T21:51:04.1510163Z","closed_at":"2026-01-06T21:51:04.1510163Z","close_reason":"Won't fix - head.state is always present for schema documents in commonplace. The fail-loud behavior is correct and surfaces issues immediately if this assumption ever breaks."}
{"id":"CP-0x3","title":"Ensure synced JSON files end with a newline","description":"Summary: When syncing .json files, ensure the content written to disk ends with a trailing newline to match expected formatting.\n\nFiles to modify:\n- src/sync/file_sync.rs (text upload/download handling for JSON content)\n- src/services/document.rs (optional: JSON serialization path if server normalizes output)\n- docs/DEVELOPMENT.md or README.md (document newline behavior if needed)\n\nImplementation steps:\n1. Define a helper to normalize JSON content with a trailing newline when writing to disk.\n2. Apply the helper in sync download/refresh paths for JSON files.\n3. Ensure upload paths preserve the newline (avoid stripping).\n4. Add a test case for JSON sync roundtrip with trailing newline.\n\nExample:\nBefore: file ends with `}`\nAfter: file ends with `}` + `\\n`\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T05:42:36.419552735Z","created_by":"jes","updated_at":"2026-01-03T07:05:06.905703074Z","closed_at":"2026-01-03T07:05:06.905703074Z","close_reason":"Added ensure_trailing_newline() helper in file_sync.rs for text file writes"}
{"id":"CP-13l","title":"Server path resolution doesn't follow subdirectory documents","description":"When a subdirectory in the fs-root schema has entries: null and a node_id (meaning the subdirectory contents are in a separate document), the server's resolve_path function in files.rs fails to look up nested paths.\n\nExample: Path 'bartleby/output.txt' should:\n1. Look up 'bartleby' in fs-root (gets node_id 32eb1257-...)\n2. Fetch that document to get bartleby's schema\n3. Look up 'output.txt' in that schema\n\nBut currently resolve_path uses the synchronous resolve_path_to_uuid which only looks at the fs-root content passed to it and can't fetch intermediate documents.\n\nThe fix is to make resolve_path iterate through path segments, fetching intermediate directory documents when entries is null.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T00:25:32.097370344Z","created_by":"jes","updated_at":"2026-01-02T01:04:06.977544302Z","closed_at":"2026-01-02T01:04:06.977544302Z","close_reason":"Fixed by implementing iterative path resolution in files.rs and sse.rs that follows subdirectory node_id references. Merged in PR #82."}
{"id":"CP-1ba","title":"Fix P1: Use text fs-root or send JSON-compatible updates (PR #4)","description":"From PR #4 Codex review: The fs-root node is created with content_type application/json but the updates being sent may not be JSON-compatible.","design":"Resolved by CP-qmk (PR #9). The push_schema_to_server function now uses create_yjs_map_diff_update which generates Y.Map updates instead of Y.Text updates. This makes the updates JSON-compatible as required by the fs-root node's application/json content type.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:23.464711-08:00","updated_at":"2025-12-27T00:14:06.868523-08:00","closed_at":"2025-12-27T00:14:06.868523-08:00","close_reason":"Resolved by CP-qmk fix - client now applies server CRDT state before making changes, ensuring proper tombstone creation for deletions. Merged in PR #9.","dependencies":[{"issue_id":"CP-1ba","depends_on_id":"CP-qmk","type":"blocks","created_at":"2025-12-26T23:41:34.266588-08:00","created_by":"daemon"}]}
{"id":"CP-1evh","title":"cbd: preserve full beads JSONL schema and unknown fields","description":"Summary: Expand the cbd Issue schema to match beads JSONL fields and preserve unknown fields so updates don't drop data.\n\nFiles to modify:\n- src/cbd.rs\n- tests (new cbd schema/roundtrip tests)\n\nImplementation steps:\n1. Inventory fields used in .beads/issues.jsonl (assignee, parent, due/defer, estimate, acceptance, design, notes, external_ref, comments, etc.) and add them to the Issue struct with serde defaults.\n2. Add a #[serde(flatten)] extra map to preserve unknown fields that cbd doesn't explicitly model.\n3. When updating issues, ensure extra fields are retained when appending the new JSONL line.\n4. Ensure JSON output includes the full Issue struct (including optional fields) without losing unknown fields.\n5. Add tests that parse a JSONL line with extra fields, update status, and verify the extra fields are preserved in the appended issue.\n\nExample:\nBefore: An issue with a design field is updated via cbd update and the design field disappears in the new JSONL line.\nAfter: cbd update appends a new line that retains design and other unknown fields.\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T07:02:30.178176522Z","created_by":"jes","updated_at":"2026-01-05T07:51:23.634121945Z","closed_at":"2026-01-05T07:51:23.634121945Z","close_reason":"Added design, notes, comments fields and #[serde(flatten)] extra map for round-trip fidelity","dependencies":[{"issue_id":"CP-1evh","depends_on_id":"CP-1j5m","type":"discovered-from","created_at":"2026-01-05T07:02:30.186405686Z","created_by":"jes"}]}
{"id":"CP-1isz","title":"Add MQTT topic for getting document content","description":"HTTP has GET /docs/:id to retrieve raw document content but there's no MQTT equivalent.\n\nOptions:\n- Add to sync protocol: {type: 'content', req: '...'} request/response\n- Or use commands port with a 'get' verb\n\nThis allows MQTT clients to fetch current content without HTTP.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:05.184991524Z","created_by":"jes","updated_at":"2026-01-09T07:05:05.184991524Z"}
{"id":"CP-1j5m","title":"Add Commonplace Bug Database CLI backed by JSONL-in-commonplace","description":"Summary: Create the **Commonplace Bug Database** CLI (commonplace-bd) that mimics beads but uses JSONL stored in commonplace as the only source of truth.\n\nFiles to modify:\n- src/bin (new binary, e.g., src/bin/commonplace-bd.rs)\n- src/services/document.rs or src/sync (helpers to read/write JSONL docs in commonplace)\n- docs/DEVELOPMENT.md or README.md (document usage and limitations)\n\nImplementation steps:\n1. Define how the JSONL doc is located (fixed UUID/path or configurable).\n2. Implement core commands (ready/show/create/update/close/sync) against the JSONL doc.\n3. Ensure concurrency handling (append-only writes, optimistic retries).\n4. Add `--json` output parity with beads where practical.\n\nExample:\ncommonplace-bd ready --json\ncommonplace-bd create \"Issue title\" --type task --priority 2 --json\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T20:54:13.887626138Z","created_by":"jes","updated_at":"2026-01-05T06:44:18.080646168Z","closed_at":"2026-01-05T06:44:18.080646168Z","close_reason":"Implemented cbd CLI with list/ready/show/create/close/update commands. Output format matches bd. Added commonplace-bd alias."}
{"id":"CP-1juq","title":"Filetree-to-xml process fails with XML output merging issue","description":"The filetree-to-xml process starts but fails shortly after. The XML output shows incorrect content merging: default XML template gets mixed with process output. Likely a Yjs/SDK issue with how XML content type documents are handled.","notes":"Fixed underlying XmlFragment support (closed CP-dscp, CP-80z2, CP-az8d). XML documents now use proper XmlFragment internally with compute_xml_diff_update() handling diff/replace operations. Ready to test filetree-to-xml process.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T04:31:26.427100233Z","created_by":"jes","updated_at":"2026-01-07T20:35:23.270765799Z","closed_at":"2026-01-07T20:35:23.270765799Z","close_reason":"Fixed XML XmlFragment CRDT support with proper server state synchronization. Added compute_xml_diff_update_with_base() and fixed filetree-to-xml to use HTTP replace.","dependencies":[{"issue_id":"CP-1juq","depends_on_id":"CP-a85","type":"discovered-from","created_at":"2026-01-07T04:31:26.432732129Z","created_by":"jes"}]}
{"id":"CP-1s6","title":"Orchestrator needs lock file to prevent multiple instances","description":"Running multiple orchestrator instances causes conflicts (e.g., Telegram bot conflict). Need a lock file or similar mechanism to prevent duplicate instances.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T19:41:29.49526294Z","created_by":"jes","updated_at":"2026-01-03T07:09:28.043796045Z","closed_at":"2026-01-03T07:09:28.043796045Z","close_reason":"Already implemented - lock file at lines 60-87 in src/bin/orchestrator.rs using fs2::FileExt"}
{"id":"CP-2cql","title":"Add MQTT topic for fs-root discovery","description":"HTTP has GET /fs-root to discover the fs-root document ID. No MQTT equivalent.\n\nOptions:\n- Well-known topic: {workspace}/_system/fs-root\n- Or publish fs-root ID as retained message on a system topic\n\nThis is needed for clients to bootstrap without HTTP.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:23.401309702Z","created_by":"jes","updated_at":"2026-01-09T07:05:23.401309702Z"}
{"id":"CP-2ee8","title":"cbd: add list filters/sort and JSON output parity","description":"Summary: Extend cbd list output with bd-style filters/sorting and JSON parity fields.\n\nFiles to modify:\n- src/cbd.rs\n- tests (list filtering and JSON output)\n\nImplementation steps:\n1. Add list flags for --type, --priority, --label, --assignee, --parent, --search, and --sort (created/updated/priority).\n2. Keep existing --status behavior and allow multiple filters to combine.\n3. When --json is set, include dependency_count and dependent_count fields in the output objects.\n4. Preserve deterministic ordering for list output (priority, then created/updated, then id).\n5. Add tests covering filter combinations and count calculations.\n\nExample:\ncommonplace-bd list --status open --label future-work --sort updated --json\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T07:02:50.286670756Z","created_by":"jes","updated_at":"2026-01-05T08:00:40.734788236Z","closed_at":"2026-01-05T08:00:40.734788236Z","close_reason":"Added list filters: --issue-type, --priority, --label, --search, --sort","dependencies":[{"issue_id":"CP-2ee8","depends_on_id":"CP-1evh","type":"blocks","created_at":"2026-01-05T07:02:50.296258852Z","created_by":"jes"},{"issue_id":"CP-2ee8","depends_on_id":"CP-1j5m","type":"discovered-from","created_at":"2026-01-05T07:02:50.301282121Z","created_by":"jes"}]}
{"id":"CP-2gv7","title":"cbd: add dep add/remove and blocked/ready semantics","description":"Summary: Add dependency management commands and make ready/blocked respect blockers and defer dates.\n\nFiles to modify:\n- src/cbd.rs\n- tests (dependency and ready/blocked behavior)\n\nImplementation steps:\n1. Add a dep subcommand with add/remove that follows beads semantics (\"X needs Y\" means Y blocks X).\n2. Update ready to exclude issues that are blocked by dependencies and issues deferred into the future.\n3. Add a blocked command that lists open issues with blockers.\n4. Ensure JSON output includes dependency metadata for ready/blocked results.\n5. Add tests for dep add/remove, ready filtering with blockers, and defer date handling.\n\nExample:\nBefore: cbd ready lists issues even if they depend on other open issues.\nAfter: cbd ready excludes blocked issues; cbd blocked shows them.\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T07:02:44.818770932Z","created_by":"jes","updated_at":"2026-01-05T08:16:03.555495072Z","closed_at":"2026-01-05T08:16:03.555495072Z","close_reason":"Added dep add/remove/list commands, blocked command, and fixed ready to check open blockers only","dependencies":[{"issue_id":"CP-2gv7","depends_on_id":"CP-1evh","type":"blocks","created_at":"2026-01-05T07:02:44.826902316Z","created_by":"jes"},{"issue_id":"CP-2gv7","depends_on_id":"CP-1j5m","type":"discovered-from","created_at":"2026-01-05T07:02:44.830298599Z","created_by":"jes"}]}
{"id":"CP-2ie","title":"Store images as external blobs with versioned JSON references","description":"Summary: Store images as external blobs (outside redb), with versioned JSON documents in commonplace referencing the blobs. Sync should handle uploads/downloads transparently.\n\nFiles to modify:\n- src/services/document.rs (new content type or metadata for blob references)\n- src/sync/file_sync.rs (upload/download logic for image files)\n- src/sync/content_type.rs (detect image types and map to blob handling)\n- docs/ARCHITECTURE.md or README.md (document blob storage)\n\nImplementation steps:\n1. Define a blob storage location and format (e.g., content-addressed files on disk).\n2. Create a JSON schema for image documents that references blobs and preserves version history.\n3. Update sync to detect image files, store/update blobs, and sync JSON metadata instead of raw bytes.\n4. Ensure deletion and GC of unused blobs is safe (future work acceptable).\n\nExample:\n- Upload image.png → stores blob at /var/commonplace/blobs/sha256-... and document content becomes JSON referencing that blob.\n- Sync downloads JSON, then fetches blob to materialize image file locally.\n\nLabels:\n- future-work","status":"closed","priority":4,"issue_type":"feature","created_at":"2026-01-03T07:02:24.612595692Z","created_by":"jes","updated_at":"2026-01-05T08:45:42.006485547Z","closed_at":"2026-01-05T08:45:42.006485547Z","close_reason":"Won't implement: images stored as base64 inline instead of external blobs - simpler approach chosen","labels":["future-work"]}
{"id":"CP-2is8","title":"P2: Array merges in create_yjs_json_merge still delete items - additive_only flag not respected for arrays in yjs.rs:96-103","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T20:37:44.87543036Z","created_by":"jes","updated_at":"2026-01-07T00:57:17.604097142Z","closed_at":"2026-01-07T00:57:17.604097142Z","close_reason":"Fixed array handling to respect additive_only flag - now appends instead of clearing when merging"}
{"id":"CP-2mgl","title":"Sync clients should not push empty Yjs commits","description":"Summary: Prevent filesystem sync clients from uploading empty Yjs updates (e.g., base64 \"AAA=\") that create no-op commits and can confuse merge semantics.\n\nFiles to modify:\n- src/sync/file_sync.rs\n- src/sync/sse.rs\n- src/mqtt/edits.rs (if validation is done on ingest)\n\nImplementation steps:\n1. Identify the code path that uploads Yjs updates from local file changes; add a guard that rejects empty updates and logs a debug message.\n2. If the server accepts edits over MQTT, add a validation step that drops empty updates before persisting.\n3. Add tests for a local edit that produces an empty update to ensure no commit is created.\n\nExample:\nBefore: local change produces update \"AAA=\", sync pushes it and a commit is recorded.\nAfter: sync detects empty update and skips upload; no commit is created.\n","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-05T02:05:35.901054776Z","created_by":"jes","updated_at":"2026-01-05T02:24:22.73674133Z","closed_at":"2026-01-05T02:24:22.73674133Z","close_reason":"Server-side guard in replace_content() is sufficient - returns existing HEAD when no changes detected (1deb1d0)"}
{"id":"CP-2pr","title":"Break sync.rs into smaller modules","description":"src/bin/sync.rs is 2734 lines and too large for a single module. It should be refactored into smaller, focused modules for better maintainability and readability.\n\nSuggested breakdown:\n- Core sync state machine\n- File system operations  \n- MQTT message handling\n- Conflict resolution logic\n- Document path resolution","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T07:03:46.71615207Z","created_by":"jes","updated_at":"2026-01-03T07:48:47.031028968Z","closed_at":"2026-01-03T07:48:47.031028968Z","close_reason":"Already factored - sync is split into 13 modules under src/sync/. Main binary is 1296 lines.","labels":["refactor","tech-debt"]}
{"id":"CP-2u5","title":"Replace endpoint doesn't work for JSON documents","description":"The /docs/{id}/replace endpoint uses character-level diffing via Y.Text, but JSON documents use Y.Map internally. When calling replace on a JSON document (like fs-root), the content is not updated. Workaround: Use the /edit endpoint with create_yjs_json_update instead.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-01T00:27:16.371497913Z","created_by":"jes","updated_at":"2026-01-01T02:05:49.98180474Z","closed_at":"2026-01-01T02:05:49.98180474Z","close_reason":"Fixed by modifying replace_content to use create_yjs_json_update for JSON documents"}
{"id":"CP-320","title":"Sync push loses node_ids when updating fs-root schema on server","description":"The sync correctly preserves node_ids when scanning locally (CP-8ou), but when it pushes the schema to the server, the node_ids become null.\n\nLocal .commonplace.json has correct shared UUIDs:\n- bartleby/prompts.txt: 0b250a22-3163-49df-8634-534585865cdd\n- telegram/content.txt: 0b250a22-3163-49df-8634-534585865cdd\n\nBut server's fs-root document has null for both.\n\nThis breaks file linking because the reconciler sees null and generates new random UUIDs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T00:11:19.958347431Z","created_by":"jes","updated_at":"2026-01-01T02:06:52.691341058Z","closed_at":"2026-01-01T02:06:52.691341058Z","close_reason":"Symptom of CP-g0c schema corruption - node_id preservation tests pass once schema is not corrupted"}
{"id":"CP-365","title":"commonplace-sync --node should accept path relative to fs-root","description":"According to SANDBOX_LINKING.md and bartleby-integration.md, --node should accept path-style names like 'bartleby-workspace' or 'workspace/bartleby' relative to the server's fs-root.\n\n**Expected:**\n```bash\ncommonplace-sync --node workspace/bartleby --server http://localhost:3000\n```\n\n**Actual:**\nMust use UUIDs:\n```bash\ncommonplace-sync --node 2750f8b7-7296-41f9-854d-7b130a707930 --server http://localhost:3000\n```\n\n**Requirements:**\n1. Accept path strings relative to server's --fs-root\n2. Resolve path → UUID by querying the server's fs-root schema\n3. Work with --sandbox mode for dynamic process management\n\n**Workaround:** Use UUIDs directly (look them up from server's .commonplace.json or API)","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T16:56:49.691337582Z","created_by":"jes","updated_at":"2026-01-01T19:02:28.161177467Z","closed_at":"2026-01-01T19:02:28.161177467Z","close_reason":"Implemented sandbox-exec config, path resolution (--path flag), recursive discovery (--recursive flag), and source_path tracking to prevent multi-config interference. All merged in PR #78.","comments":[{"id":15,"issue_id":"CP-365","author":"jes","text":"**Updated understanding:** The original design was even simpler - no --node flag needed at all.\n\nThe sync process should discover its server path automatically:\n1. Look at where processes.json is located on the filesystem\n2. Use the process name from that config\n3. Derive the server path: `{processes.json parent}/{process_name}`\n\nExample: If processes.json is at `/home/jes/commonplace/workspace/processes.json` and contains a 'bartleby' process, the sandbox should automatically sync to the server path `workspace/bartleby` (relative to fs-root).\n\nThis eliminates the need for explicit --node or --path arguments entirely.","created_at":"2026-01-01T16:58:55Z"}]}
{"id":"CP-3ky","title":"Implement Router Documents (docs/ROUTER.md)","description":"Implement the router document feature as specified in docs/ROUTER.md:\n\n- Add `--router \u003cnode-id\u003e` CLI flag (repeatable)\n- Router documents are JSON with `version`, `nodes`, and `edges` \n- Server subscribes to router document blue port for changes\n- Apply/diff wiring based on router document content\n- Emit `router.error` events on red port for errors\n- Handle node creation hints from `nodes` section\n- Track router-created wires separately from other wires","design":"Implementation approach:\n\n1. New module: src/router/ with:\n   - mod.rs: Module exports\n   - error.rs: RouterError enum for parse/validation/cycle errors\n   - schema.rs: RouterSchema, Edge, NodeSpec, PortType structs with serde\n   - manager.rs: RouterManager that subscribes to router document's blue port\n\n2. CLI: Added --router \u003cnode-id\u003e flag (repeatable) in cli.rs\n\n3. RouterConfig: Added routers: Vec\u003cString\u003e field\n\n4. Initialization: In lib.rs, for each router ID:\n   - Get or create JSON document node\n   - Create RouterManager with registry reference\n   - Start background watcher task\n   - Perform initial wiring\n\n5. Wire management:\n   - RouterManager tracks wires it created (WireKey -\u003e SubscriptionId)\n   - On each reconcile, diffs desired vs current wires\n   - Removes wires no longer declared, adds new ones\n   - Cycle detection handled by registry, emits router.error on failure\n\n6. Error handling:\n   - Parse errors, unsupported version, missing nodes, cycles → router.error event on red port","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-26T18:29:01.089173-08:00","updated_at":"2025-12-26T23:22:36.003263-08:00","closed_at":"2025-12-26T23:22:36.003263-08:00","close_reason":"Router documents feature implemented. Added --router CLI flag, RouterManager, schema validation, wiring management, and error events. Addressed 4 P2 review suggestions. Merged in PR #8."}
{"id":"CP-3st","title":"Reconciler doesn't create documents for UUIDs in node-backed subdirectory schemas","description":"When a subdirectory has entries: null and a node_id (node-backed), the reconciler creates that subdirectory document but doesn't recursively reconcile the UUIDs defined within that subdirectory's schema.\n\nExample: sandbox-workspace/bartleby has entries: null, node_id: a8e1bff4-...\n1. Sync pushes bartleby/.commonplace.json to document a8e1bff4\n2. That schema defines output.txt -\u003e 06f938e2, prompts.txt -\u003e 6fe7bbef\n3. But these UUIDs never get created as documents\n4. Sync fails with 'Identifier not found' after 30 retries\n\nThe fix: When reconciling a node-backed directory, the server should fetch that directory's schema document and recursively reconcile any UUIDs defined within it.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T01:35:20.370037954Z","created_by":"jes","updated_at":"2026-01-02T02:09:46.171363236Z","closed_at":"2026-01-02T02:09:46.171363236Z","close_reason":"Closed"}
{"id":"CP-3tnk","title":"P2: path.rs rejects directories with inline schema entries","description":"In path.rs around lines 48-57, path resolution fails when a directory has an inline (non-file) .commonplace.json entry. The code assumes all entries point to files but inline entries are valid in the schema.\n\nLocation: src/path.rs:48-57\nFound by: codex review","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T09:10:02.56506803Z","created_by":"jes","updated_at":"2026-01-06T00:55:15.237327857Z","closed_at":"2026-01-06T00:55:15.237327857Z","close_reason":"Won't fix - inline subdirectories are deprecated and migration exists"}
{"id":"CP-3ve","title":"Identify and refactor large files into smaller modules","description":"Audit the codebase for files that have grown too large and could benefit from being split into smaller, more focused modules. Look for files with multiple distinct responsibilities that could be separated.","design":"Test coverage now in place (40 tests). Ready for refactoring.\n\nTarget module structure for src/bin/sync.rs split:\n\n1. src/sync/mod.rs - Module root, re-exports\n2. src/sync/urls.rs - URL building functions (encode_node_id, encode_path, normalize_path, build_*_url)\n3. src/sync/yjs.rs - Yjs update creation (create_yjs_text_update, create_yjs_json_update, json_value_to_any)\n4. src/sync/types.rs - Data structures (HeadResponse, EditResponse, ForkResponse, FileEvent, SyncState, etc.)\n5. src/sync/client.rs - HTTP client operations (SyncClient trait + impl)\n6. src/sync/file_sync.rs - File mode sync (run_file_mode, file_watcher_task, upload_task)\n7. src/sync/dir_sync.rs - Directory mode sync (run_directory_mode, directory_watcher_task, handle_schema_change)\n8. src/sync/sse.rs - SSE handling (sse_task, directory_sse_task, handle_server_edit, refresh_from_head)\n\nsrc/bin/sync.rs becomes thin wrapper: just main() + Args parsing, delegates to sync module.\n\nTests move with their functions to respective modules.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-29T13:47:42.244104-08:00","updated_at":"2025-12-30T03:24:24.008280981Z","closed_at":"2025-12-30T03:24:24.008280981Z","close_reason":"Refactored sync.rs into modular structure. Created src/sync/ with urls.rs, yjs.rs, types.rs (implemented) and client.rs, dir_sync.rs, file_sync.rs, sse.rs (placeholders for Phase 2). Added 44 tests. PR #33 merged."}
{"id":"CP-3xx","title":"commonplace-ps doesn't work with recursive mode orchestrator","description":"The recursive mode orchestrator (DiscoveredProcessManager) doesn't write to the status file, making commonplace-ps report 'Orchestrator is not running'.\n\nThe non-recursive mode (ProcessManager) works correctly after the fix in commit 8610987.\n\nNeed to verify write_status() is being called in DiscoveredProcessManager and that it's writing to the correct path.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T13:20:38.148247847Z","created_by":"jes","updated_at":"2026-01-03T19:05:59.824799775Z","closed_at":"2026-01-03T19:05:59.824799775Z","close_reason":"Already fixed. DiscoveredProcessManager correctly writes status file with process info."}
{"id":"CP-47e3","title":"Blackboard like functionality (\"black\")","description":"Future exploration: Add blackboard like functionality to commonplace, potentially called \"black\". Details TBD.","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-05T23:45:04.079809774Z","created_by":"jes","updated_at":"2026-01-05T23:45:04.079809774Z","labels":["future-work"]}
{"id":"CP-4a0","title":"Refactor discovery.rs: Extract process state machine","description":"orchestrator/discovery.rs is 542 lines. Extract `ManagedDiscoveredProcess` state machine and lifecycle handling into separate module, keeping only config parsing and discovery logic in discovery.rs.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-30T00:34:51.339252-08:00","updated_at":"2025-12-30T16:55:35.033866881Z","closed_at":"2025-12-30T16:55:35.033866881Z","close_reason":"Extracted process state machine to discovered_manager.rs - PR #44 merged"}
{"id":"CP-4br","title":"Investigate excessive SSE connections during sync","description":"Summary: Logs show repeated \"SSE connection opened\" lines during sync; investigate why the sync client is opening many SSE connections for the same targets instead of maintaining one per file (plus fs-root), and fix the spawn/reconnect logic to avoid duplicates.\\n\\nFiles to modify: src/bin/sync.rs, src/sync/file_sync.rs, src/sync/sse.rs, src/sync/dir_sync.rs.\\n\\nImplementation steps:\\n1. Reproduce by running sync with logs enabled and count connection opens per file and for fs-root.\\n2. Trace where SSE tasks are spawned (per-file and fs-root) and ensure each target gets exactly one EventSource per lifecycle.\\n3. Identify whether reconnection loops or restart logic cause duplicate tasks; add guards or reuse existing connections.\\n4. Add/adjust logging or tests to assert single SSE connection per target (per file + fs-root).\\n\\nExample: For a sync of 3 files, expect 4 SSE connections total (3 files + fs-root); logs currently show repeated opens for the same file on each sync cycle.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-01T05:58:35.263828365Z","created_by":"jes","updated_at":"2026-01-01T11:20:25.079063026Z","closed_at":"2026-01-01T11:20:25.079063026Z","close_reason":"Investigated and found no bug. SSE connection architecture is correct: one connection per file plus fs-root, with automatic reconnection on disconnect. The 'excessive' connection logs are expected behavior from reconnection after server restarts or network issues.","comments":[{"id":11,"issue_id":"CP-4br","author":"jes","text":"Investigation notes:\n\n1. SSE task architecture looks correct:\n   - One SSE task per file (spawned via spawn_file_sync_tasks)\n   - One SSE task for fs-root directory (directory_sse_task)\n   - handle_schema_change has guard: if !known_paths.contains(path) before spawning\n\n2. Reconnection behavior is intentional:\n   - Both sse_task and directory_sse_task have reconnect loops with 5s delay\n   - 'SSE connection opened' is logged on each (re)connection\n\n3. Possible causes of 'excessive' logs:\n   - Server restarts causing all clients to reconnect\n   - Network issues causing disconnects\n   - Server SSE timeout dropping idle connections\n\n4. To verify if this is a real bug:\n   - Need to reproduce with a stable server\n   - Count unique SSE URLs being connected (should match file count + 1)\n   - Check if same URL is connected multiple times concurrently\n\nWill check server-side SSE connection handling next.","created_at":"2026-01-01T11:19:35Z"},{"id":12,"issue_id":"CP-4br","author":"jes","text":"Server-side SSE analysis:\n\n1. Server uses 30-second keep-alive interval (sse.rs:396)\n2. SSE connections stay open as long as:\n   - Client maintains connection\n   - Document exists\n   - No broadcast channel errors\n\n3. Connection drops would happen on:\n   - Server restart\n   - Document deletion\n   - Network issues\n   - Broadcast channel closure\n\nConclusion: The code appears correct. SSE connections are intentionally reconnecting (with 5s delay) when closed. The 'excessive' logs may be:\n1. Normal reconnection after server restarts during testing\n2. Expected behavior for initial connection setup\n3. Debug-level info logs appearing frequently\n\nRecommendation: Either close as not-a-bug, or demote the 'SSE connection opened' log from info! to debug! to reduce noise.\n\nI'll close this as the architecture appears correct and the behavior is expected.","created_at":"2026-01-01T11:20:17Z"}]}
{"id":"CP-4e9","title":"Sync protocol infinite loop: commit:null parsed as request","design":"When store has no HEAD commit, it responds with {type:head, req:..., commit:null}. The Rust code distinguishes requests (commit:None) from responses (commit:Some). But null deserializes to None, so the store receives its own response and re-handles it as a request, creating an infinite loop. Fix: use distinct message types like head_request vs head_response, or add a direction field.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-30T00:30:17.030876486Z","created_by":"jes","updated_at":"2025-12-30T01:17:06.619813304Z","closed_at":"2025-12-30T01:17:06.619813304Z","close_reason":"Fixed by splitting Head message into Head (request) and HeadResponse (response). Committed in ded73c4."}
{"id":"CP-4f7","title":"Deprecate derived IDs - all files and directories should have UUIDs","description":"Derived IDs (like fs-root:path) are fragile - they break on rename. Every file and directory entry should have an explicit UUID node_id instead.\n\nThis affects:\n- Reconciler: should generate UUIDs for entries without node_id\n- Sync tool: should ensure all entries have UUIDs when scanning\n- Link tool: already does this for source files\n- Schema migration: existing derived IDs should be converted to UUIDs\n\nBenefits:\n- Stable references across renames\n- Links don't break when source is renamed\n- Simpler path resolution (just lookup by UUID)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T22:48:39.651047828Z","created_by":"jes","updated_at":"2025-12-30T23:12:28.538534864Z","closed_at":"2025-12-30T23:12:28.538534864Z","close_reason":"Migration now generates UUIDs for all entries. Removed derive_doc_id method. PR #53 merged."}
{"id":"CP-4k28","title":"Single-file sync should create file if it doesn't exist","description":"When using `commonplace-sync --file \u003cpath\u003e --path \u003cserver-path\u003e`, if the server path doesn't exist, sync fails with:\n\n```\nFailed to resolve path 'beads/commonplace-issues.jsonl': Path not found\n```\n\nExpected behavior: sync should create the document on the server if it doesn't exist, similar to how directory sync creates new files.\n\nWorkaround: manually copy the file to a synced directory first so main sync creates it, then beads-sync can take over.\n\nUse case: syncing a file from outside the main workspace tree (e.g., .beads/issues.jsonl) into the workspace.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T19:46:28.849935844Z","created_by":"jes","updated_at":"2026-01-04T00:02:41.755867441Z","closed_at":"2026-01-04T00:02:41.755867441Z","close_reason":"Implemented resolve_or_create_path function that creates documents on the server when using single-file sync with a non-existent path. Generates local UUID, updates parent schema, triggers reconciler. Commit: c1d6dbd"}
{"id":"CP-4qm","title":"commonplace-replay should work from outside sync directory","description":"commonplace-replay fails when run from outside the sync directory, even when given a valid path to a synced file.\n\nExample:\n```\njes@commonplace:~/commonplace$ ./target/release/commonplace-replay workspace/bartleby/prompts.txt\nError: \"Not in a commonplace sync directory: .commonplace.json not found\"\n\njes@commonplace:~/commonplace$ cd workspace/\njes@commonplace:~/commonplace/workspace$ ../target/release/commonplace-replay bartleby/prompts.txt\nCommit: 9eb1736331c96195d0b5102a88a9ea7b6f02170a6708493c345b1c241bc1ea12\n```\n\nExpected: Should find .commonplace.json by walking up from the file path, not from cwd.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T11:45:47.616212936Z","created_by":"jes","updated_at":"2026-01-03T18:49:04.229496192Z","closed_at":"2026-01-03T18:49:04.229496192Z","close_reason":"Fixed. Now searches for workspace root starting from file's directory, not cwd."}
{"id":"CP-4r4d","title":"Shadow inode GC never called - memory/disk leak","description":"InodeTracker::gc() is implemented (state.rs:258-283) but never invoked anywhere. Shadow hardlinks and inode state entries accumulate indefinitely during sync sessions.\n\nImpact: Long-running sync with frequent edits causes unbounded growth of:\n- InodeTracker.states HashMap (memory)\n- Shadow directory hardlinks (disk)\n\nFix: Add a periodic GC task (e.g., every 5 minutes) that:\n1. Calls tracker.gc()\n2. Removes returned shadow file paths from disk\n\nRelated: CP-txg0 review","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-05T08:57:10.943768718Z","created_by":"jes","updated_at":"2026-01-05T23:50:35.408929138Z","closed_at":"2026-01-05T23:50:35.408929138Z","close_reason":"Added shadow_gc_task that runs every 5 minutes and cleans up stale shadow hardlinks"}
{"id":"CP-4w00","title":"Spawn SSE tasks dynamically for newly discovered node-backed subdirs","description":"Currently subdir_sse_task is only spawned at startup for known node-backed subdirectories. When handle_schema_change discovers a new node-backed subdir via SSE event, it creates local directories and files but does NOT spawn a new SSE task to watch that subdir's schema.\n\nThis means changes to newly discovered subdirs won't propagate until the next sync restart.\n\nThe workaround is the retry loop in sync_schema() (dir_sync.rs:2089-2118) which polls 3 times with 3s delays at startup hoping other sync clients will have pushed their schemas.\n\nFix: In handle_schema_change (or handle_subdir_schema_change), when a new node-backed subdirectory is discovered, spawn a subdir_sse_task for it dynamically.\n\nRelated: CP-75fq (UUID coordination issue)","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-09T06:19:36.922242004Z","created_by":"jes","updated_at":"2026-01-09T06:49:14.934707069Z","closed_at":"2026-01-09T06:49:14.934707069Z","close_reason":"Fixed by spawning SSE tasks dynamically when new node-backed subdirs are discovered via SSE events"}
{"id":"CP-4xd","title":"Directory-attached process management for orchestrator","description":"Similar to the existing file-attached process mechanism, add support for declaring that a process is running 'in a directory' that the orchestrator manages. This will be the primary paradigm for the sync-sandbox tool.\n\nUnlike file-attached processes which are tied to a specific document, directory-attached processes operate on a directory scope and can interact with multiple files within that directory tree.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T06:47:45.584747427Z","created_by":"jes","updated_at":"2025-12-31T16:27:44.602430837Z","closed_at":"2025-12-31T16:27:44.602430837Z","close_reason":"Merged in PR #55","comments":[{"id":6,"issue_id":"CP-4xd","author":"jes","text":"Implementation complete. Changes:\n- Made owns field optional in DiscoveredProcess (absent = directory-attached)\n- Added COMMONPLACE_SERVER env var to spawned processes\n- Added resolve_server_url() to OrchestratorConfig with fallback chain\n- Added COMMONPLACE_PATH env var support in sync.rs as alias for --node\n- Updated examples/.processes.json with directory-attached example\n\nCommits: 4d7963a, 0c5f293, 06b2975, 2e7d89b, 81574fa, 43367f8, 866e4b4, d7f1549","created_at":"2025-12-31T08:32:26Z"}]}
{"id":"CP-51t","title":"Verify diff module returns correct summary struct for replace endpoint","design":"The /nodes/:id/replace endpoint needs diff_to_yjs_update to return (update_bytes, DiffSummary) where DiffSummary has inserted, deleted, operations fields. Need to verify this interface exists or add it.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T08:03:48.888669529Z","created_by":"jes","updated_at":"2025-12-29T09:01:47.131481523Z","closed_at":"2025-12-29T09:01:47.131481523Z","close_reason":"Verified: diff module returns DiffResult with update_bytes, update_b64, operation_count, and summary (DiffSummary with chars_inserted, chars_deleted). replace_node endpoint correctly uses all fields."}
{"id":"CP-55s","title":"Blocks acceptance: commonplace-link creates schema but file doesn't sync","description":"## Summary\ncommonplace-link creates the local schema entry for the target file, but:\n1. The file doesn't get materialized on disk from the source content\n2. The schema change doesn't push to server\n3. Edits to the manually-created target don't sync back\n\n## Related\nMay be same as CP-a31 'commonplace-link doesn't push schema changes to server'\n\n## Repro\n1. Create source file with content\n2. Run commonplace-link source target\n3. Wait for sync\n4. Check if target exists (it doesn't)\n5. Manually create target with content\n6. Check if source gets updated (it doesn't)\n\n## Expected\nTarget file should be created with source content, and edits should sync bidirectionally.\n\n## Blocks\nAcceptance criteria L4, L5, L6, L7","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T02:23:46.200448694Z","created_by":"jes","updated_at":"2026-01-03T03:12:26.196893938Z","closed_at":"2026-01-03T03:12:26.196893938Z","close_reason":"Fixed commonplace-link to push schema changes to server. Added server push capability with --server flag (defaults to localhost:3000). For root schemas, discovers fs-root ID from server. For subdirectory schemas, uses node_id from parent schema. P2 edge case remaining for repeated directory names."}
{"id":"CP-56w","title":"Refactor api.rs: Separate path-based vs ID-based routing","description":"api.rs has mixed concerns for /docs/{id} and /files/{path} routing. Extract path-based API (`/files/*`) into separate module to clarify the two API styles.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-30T00:34:51.228276-08:00","updated_at":"2025-12-30T16:31:46.635504385Z","closed_at":"2025-12-30T16:31:46.635504385Z","close_reason":"Closed","dependencies":[{"issue_id":"CP-56w","depends_on_id":"CP-ejh","type":"blocks","created_at":"2025-12-30T00:36:37.094635-08:00","created_by":"daemon"}]}
{"id":"CP-59h","title":"Define and implement websocket protocol for realtime sync","description":"Summary: WebSocket endpoint with subprotocol negotiation for y-websocket compatibility and commonplace-extended mode.\n\n## Endpoint\n\n```\nws://localhost:3000/ws/docs/{id}\n```\n\n## Subprotocol Negotiation\n\nClient sends `Sec-WebSocket-Protocol` header to select mode:\n\n| Subprotocol | Description |\n|-------------|-------------|\n| `y-websocket` | Pure Yjs compatibility for browser tools (Tiptap, Monaco, etc.) |\n| `commonplace` | Extended protocol with commit metadata and blue/red ports |\n\n## Message Types\n\n### y-websocket mode (types 0-1)\n- 0: Sync messages (sync step 1, sync step 2, update)\n- 1: Awareness messages (cursor positions, presence)\n\n### commonplace mode (types 0-5)\n- 0-1: Same as y-websocket\n- 3: Commit metadata (parent cid, timestamp)\n- 4: Blue port events (commit notifications)\n- 5: Red port events (ephemeral JSON)\n\n## Implementation Steps\n\n1. Add websocket endpoint using axum's WebSocket support\n2. Implement subprotocol negotiation via Sec-WebSocket-Protocol header\n3. Implement y-websocket mode first (milestone: browser Yjs tools work)\n4. Add commonplace mode extensions\n5. Add reconnection handling and backpressure\n6. Tests for both modes\n\n## Use Cases\n\n- Browser-based collaborative editing (Tiptap, ProseMirror)\n- Compatibility with existing Yjs ecosystem tools\n- Real-time sync without polling","notes":"Phase 1 (y-websocket core) committed: 4fdbd67. Endpoint /ws/docs/{id} with subprotocol negotiation, sync protocol, room coordination. Phase 2 (commonplace extensions) pending.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-03T19:19:07.492551245Z","created_by":"jes","updated_at":"2026-01-04T02:02:18.545827145Z","closed_at":"2026-01-04T02:02:18.545827145Z","close_reason":"Phase 1 (y-websocket core) complete. Follow-on work in CP-9abt, CP-ow96, CP-w5sw."}
{"id":"CP-5af","title":"Telegram messages ↔ file integration","description":"Bidirectional sync between Telegram messages and commonplace documents:\n- Receive Telegram messages as document updates or events\n- Send document content/edits to Telegram chats\n- Subscribe to specific chats/channels\n- Bot or user account authentication\n\nEnables messaging-as-document patterns and chat automation.","design":"OPEN QUESTIONS for implementation:\n1. Bot token or user session auth?\n2. What's the document schema for messages?\n3. Handle message history or just new messages?\n4. Support for media (photos, files) or text only?\n5. Rate limiting and Telegram API compliance?\n6. How to map chats to document paths?","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.825068-08:00","updated_at":"2026-01-04T01:03:22.052424894Z","closed_at":"2026-01-04T01:03:22.052424894Z","close_reason":"Done","labels":["future-work"],"dependencies":[{"issue_id":"CP-5af","depends_on_id":"CP-nno","type":"blocks","created_at":"2025-12-28T23:53:18.82599-08:00","created_by":"daemon"}]}
{"id":"CP-5et6","title":"Server replace_content should treat JSONL as text, not JSON","description":"Summary: The server's replace_content needs to parse incoming JSONL text into Y.Array\u003cY.Map\u003e format for proper Yjs diff.\n\nCurrent: JSONL documents use Y.Array\u003cY.Map\u003e, but replace receives raw JSONL text and fails to parse it.\n\nFix: In replace_content, when content_type is JSONL:\n1. Parse incoming text as newline-delimited JSON\n2. Convert each line to a Y.Map entry\n3. Diff against existing Y.Array\u003cY.Map\u003e state\n\nFiles to modify:\n- src/services/document.rs (replace_content)\n- src/sync/yjs.rs (may need create_yjs_jsonl_diff_update or similar)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-05T04:26:24.852577094Z","created_by":"jes","updated_at":"2026-01-05T05:52:44.409864068Z","closed_at":"2026-01-05T05:52:44.409864068Z","close_reason":"Fixed: compute_json_diff now uses create_yjs_jsonl_update for JSONL content type"}
{"id":"CP-5i1","title":"HTML + WebSocket server process","description":"Server process that serves static HTML viewer and provides WebSocket connections for live document streaming. Powers the live HTML viewer (CP-6oj).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T18:00:20.018424314Z","created_by":"jes","updated_at":"2026-01-04T05:25:41.914326057Z","closed_at":"2026-01-04T05:25:41.915427847Z","labels":["future-work"]}
{"id":"CP-5p5","title":"Investigate B-\u003eA sync not working: file watcher or echo detection issue","design":"Root cause found: Atomic writes break file watcher.\n\nWhen handle_server_edit writes to file, it uses atomic write (temp + rename). On Linux with inotify, this can cause the watcher to lose track of the file because:\n1. Watcher watches original inode\n2. Rename replaces file with new inode\n3. Watcher still watching old (deleted) inode\n4. Subsequent edits to new file not detected\n\nPotential fixes:\n1. Watch parent directory instead of file\n2. Re-register file watcher after each write\n3. Don't use atomic writes (risk: partial writes on crash)\n4. Use inotify IN_MOVED_TO event to re-watch\n\nNeeds implementation to test which approach works best.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-29T08:18:50.200861401Z","created_by":"jes","updated_at":"2025-12-29T16:02:38.701416395Z","closed_at":"2025-12-29T16:02:38.701416395Z","close_reason":"Fixed inotify file watcher issue by using direct writes instead of atomic (temp+rename). Testing revealed a separate race condition where upload_task can send stale content before server edits are written - needs follow-up fix. PR #21 merged."}
{"id":"CP-5qb","title":"Sandbox file linking not working - sync creates forks instead of using linked UUIDs","description":"When setting up linked files between sandbox processes (per SANDBOX_LINKING.md), the sync is creating new forks instead of using the shared UUIDs.\n\n**Expected behavior:**\n- text-to-telegram/content.txt and bartleby/prompts.txt share the same UUID\n- Changes to one file sync to the other\n\n**Actual behavior:**\n- Sync detects 'new file has identical content' and FORKS a new UUID\n- Each sandbox ends up with different UUIDs for the linked files\n- No sync happens between them\n\n**Root cause:**\n- Node-backed directories (entries: null, node_id: X) store schemas separately\n- Local schema edits aren't pushed to the server's subdirectory nodes\n- When sandbox syncs pull schemas, they get wrong/missing UUIDs\n\n**To fix:**\n1. Need to push linked schemas directly to subdirectory node documents\n2. Or change sync to preserve UUIDs from local schema when pushing\n3. Update SANDBOX_LINKING.md with correct procedure for node-backed directories","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:29:39.76376046Z","created_by":"jes","updated_at":"2026-01-01T19:37:40.407375761Z","closed_at":"2026-01-01T19:37:40.407375761Z","close_reason":"Fixed by adding path option to processes.json. Each sandbox now syncs from its own subdirectory rather than root, allowing linked UUIDs to work correctly."}
{"id":"CP-5qy","title":"Orchestrator should restart sandbox-exec processes that die","description":"When a sandbox-exec process exits (crashes or otherwise dies), the orchestrator should restart it automatically.\n\nCurrently the orchestrator has check_and_restart() logic but it may not be working correctly for sandbox-exec processes. The sync wrapper process may be running but the actual child process (e.g., bartleby, text-to-telegram) may have died.\n\nNeed to ensure the entire process tree is monitored and restarted on failure.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:21:34.651720793Z","created_by":"jes","updated_at":"2026-01-03T07:19:25.650620312Z","closed_at":"2026-01-03T07:19:25.650620312Z","close_reason":"Verified working - sandbox-exec processes restart automatically when killed (tested with bartleby multiple times)"}
{"id":"CP-5vk","title":"Blocks acceptance: New files in subdirectories appear at wrong path in sandbox","description":"## Summary\nFiles created in workspace subdirectories appear at the wrong path in sandboxes.\n\n## Repro\n1. Create `workspace/bartleby/test-note.txt` with content 'note'\n2. Check bartleby sandbox\n\n## Expected\nFile appears at `bartleby/test-note.txt` in sandbox\n\n## Actual\nFile appears at root `test-note.txt` in sandbox (wrong path)\n\nAdditionally, the file content is empty (0 bytes) instead of 'note'.\n\n## Log evidence\n```\n[bartleby] Server created new file: test-note.txt -\u003e /tmp/commonplace-sandbox-.../test-note.txt\n```\n\nThe path should be `bartleby/test-note.txt` not `test-note.txt`.\n\n## Blocks\nAcceptance criteria C5, C6","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T02:14:13.431123317Z","created_by":"jes","updated_at":"2026-01-03T02:17:02.39902252Z","closed_at":"2026-01-03T02:17:02.399030281Z"}
{"id":"CP-5we","title":"Beads integration with bidirectional sync","description":"Sync beads JSONL into commonplace as documents. Edits made via commonplace should publish back to beads, enabling bidirectional issue tracking integration.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:56:53.320326707Z","created_by":"jes","updated_at":"2026-01-05T08:44:43.083181209Z","closed_at":"2026-01-05T08:44:43.083181209Z","close_reason":"Working: beads JSONL syncs via commonplace-sync, cbd reads/writes through server, bidirectional flow complete","labels":["future-work"],"dependencies":[{"issue_id":"CP-5we","depends_on_id":"CP-oi3","type":"blocks","created_at":"2025-12-30T18:43:29.742508518Z","created_by":"daemon"}]}
{"id":"CP-5wwk","title":"tracker.shadow() return value ignored - silent failure","description":"In sse.rs:817, tracker.shadow(old_key) is called but its return value (Option\u003cPathBuf\u003e) is ignored.\n\nRace condition: If concurrent GC removes the inode state between the read lock (line 793) and write lock (line 817), shadow() returns None and the shadow hardlink is never tracked - but we just created the hardlink at line 809.\n\nResult: Orphaned shadow hardlink that won't be GC'd and won't have its writes forwarded.\n\nFix: Check return value of shadow() and either:\n1. Log warning if it returns None unexpectedly\n2. Delete the hardlink we just created if tracking failed\n\nRelated: CP-txg0 review","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-05T08:57:20.721396968Z","created_by":"jes","updated_at":"2026-01-05T23:50:36.65853067Z","closed_at":"2026-01-05T23:50:36.65853067Z","close_reason":"Fixed: now checks shadow() return value and removes orphaned hardlink if tracking failed"}
{"id":"CP-5y0","title":"Sync doesn't detect offline edits on restart","description":"When the sync client is stopped, files are edited, and sync is restarted, the offline edits are NOT synced to the server until a new modification is made.\n\nTest case (O5):\n1. Stop workspace sync\n2. Edit file while sync is down\n3. Restart workspace sync\n4. Server content is NOT updated\n\nExpected: Sync should detect file changes made while it was down and push them on startup.\nActual: File appears 'in sync' until a new modification is made.\n\nLikely cause: Sync client caches last known content/hash and only checks on file change events, not at startup.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T09:49:00.716518671Z","created_by":"jes","updated_at":"2026-01-02T10:57:10.858702165Z","closed_at":"2026-01-02T10:57:10.858702165Z","close_reason":"Closed"}
{"id":"CP-6ke7","title":"Add MQTT topic for document forking","description":"HTTP has POST /docs/:id/fork to create a new document forked from an existing one at HEAD or a specific commit. No MQTT equivalent.\n\nAdd to sync protocol or commands port.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:20.607105809Z","created_by":"jes","updated_at":"2026-01-09T07:05:20.607105809Z"}
{"id":"CP-6kk","title":"Remove non-recursive mode from orchestrator","description":"Summary: Remove the non-recursive orchestrator mode so it always scans recursively and watches all processes.json files.\n\nFiles to modify:\n- src/bin/orchestrator.rs (CLI flags and default behavior)\n- src/orchestrator (remove non-recursive code paths)\n- docs/DEVELOPMENT.md or README.md (update usage)\n\nImplementation steps:\n1. Remove the non-recursive flag(s) and associated code paths.\n2. Ensure recursive scanning is always enabled.\n3. Update docs/CLI help to reflect the simplified behavior.\n\nExample:\nBefore: orchestrator --watch-processes (non-recursive)\nAfter: orchestrator always uses recursive mode","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T18:11:15.095687874Z","created_by":"jes","updated_at":"2026-01-03T18:57:19.117322889Z","closed_at":"2026-01-03T18:57:19.117322889Z","close_reason":"Removed non-recursive mode. Orchestrator now always starts server+sync from commonplace.json, then recursively discovers processes. Removed --recursive, --watch-processes, and --use-paths flags."}
{"id":"CP-6kpq","title":"Add .cbd.json config file for repo-to-commonplace path mapping","description":"cbd should discover .cbd.json in repo root (or .beads/) that specifies the commonplace path to the synced issues.jsonl file. Enables cbd to work in any repo without hardcoded paths.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T06:43:34.197110755Z","created_by":"jes","updated_at":"2026-01-05T06:49:51.248409509Z","closed_at":"2026-01-05T06:49:51.248409509Z","close_reason":"Added .cbd.json discovery to cbd - walks up directories looking for .cbd.json or .beads/.cbd.json"}
{"id":"CP-6ngz","title":"P2: Config reload leaves stale process settings in manager","description":"In manager.rs around lines 486-533, reload_config() compares old vs new config but doesn't update internal state for processes that changed but weren't restarted. The ProcessInfo stored in self.processes may have stale configuration.\n\nLocation: src/orchestrator/manager.rs:486-533\nFound by: codex review","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T09:09:52.679464435Z","created_by":"jes","updated_at":"2026-01-06T01:19:41.791591756Z","closed_at":"2026-01-06T01:19:41.791591756Z","close_reason":"Update unchanged process configs in reload_config"}
{"id":"CP-6o2m","title":"Add MQTT path-based operations","description":"HTTP has /files/*path endpoints that resolve filesystem paths to document IDs. No MQTT equivalent.\n\nOptions:\n- Path resolution service on a system topic\n- Or extend topic format to support path-based addressing\n\nCurrently MQTT topics require knowing the document path with extension upfront.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:24.604689681Z","created_by":"jes","updated_at":"2026-01-09T07:05:24.604689681Z"}
{"id":"CP-6oj","title":"Live HTML viewer with websocket updates","description":"Browser-based viewer that connects via websocket to display commonplace documents in real-time. XHTML documents render as HTML, JSON and XML documents display formatted source. Updates stream live as documents change.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:59:51.301579711Z","created_by":"jes","updated_at":"2026-01-04T09:28:35.297677806Z","closed_at":"2026-01-04T09:28:35.297684906Z","labels":["future-work"],"dependencies":[{"issue_id":"CP-6oj","depends_on_id":"CP-5i1","type":"blocks","created_at":"2025-12-30T18:00:25.637694596Z","created_by":"daemon"}]}
{"id":"CP-6pd","title":"Use cwd to run processes in sandbox directory instead of symlinks/env vars","description":"When conductor/orchestrator spawns processes for directory-attached work, set the working directory (cwd) to the sandbox/workspace directory instead of relying on symlinks or environment variables like BARTLEBY_WORKING_DIR. This allows programs that use relative paths to naturally see the sandbox contents without any special configuration. Simpler and more transparent than the symlink approach.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-31T17:04:16.788917689Z","created_by":"jes","updated_at":"2025-12-31T19:55:32.624440087Z","closed_at":"2025-12-31T19:55:32.624440087Z","close_reason":"Implemented in PR #58. Bartleby now uses Path.cwd() instead of BARTLEBY_WORKING_DIR env var, and orchestrator sets cwd to workspace directory."}
{"id":"CP-6ux9","title":"Empty UUID map guard incorrectly skips deletion for legitimately empty subdirectories","design":"When a node-backed subdirectory becomes empty on the server (all files deleted), build_uuid_map_recursive returns an empty map. The current safety check in handle_subdir_schema_cleanup treats this as a fetch failure and skips deletions, so stale local files remain. Need to distinguish true fetch errors from legitimately empty schemas.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T22:42:32.229756487Z","created_by":"jes","updated_at":"2026-01-06T23:46:09.52226168Z","closed_at":"2026-01-06T23:46:09.52226168Z","close_reason":"Fixed empty UUID map guard to properly distinguish legitimate empty schemas from fetch failures. Added status tracking to build_uuid_map_recursive, guards for fetch failures, schema entries check, and node-backed directory support. Merged in PR #106."}
{"id":"CP-75fq","title":"UUID coordination between sync clients is broken","description":"When multiple sync clients (sandbox, workspace) create schemas independently, they generate different UUIDs for the same logical paths. After a database restart, UUIDs diverge completely:\n- Sandbox generates UUID A for content.txt\n- Workspace has stale UUID B for content.txt  \n- Server may have empty schemas or yet another UUID\n\nRoot cause: No single source of truth for UUIDs. Each sync client generates UUIDs locally when creating new schema entries.\n\nImpact: File content doesn't sync between sandboxes and workspace because they're syncing to different server documents.\n\nProposed fix: Server should be the source of truth. When a sync client creates a new entry, it should:\n1. Push schema to server with null node_id\n2. Server's reconciler generates the UUID\n3. Sync client pulls the UUID back and updates local schema\n\nThis ensures all clients see the same UUIDs.","status":"open","priority":1,"issue_type":"bug","created_at":"2026-01-09T05:46:42.591775384Z","created_by":"jes","updated_at":"2026-01-09T05:46:42.591775384Z"}
{"id":"CP-78a","title":"Blocks acceptance: CRDT merge corruption on file edit","description":"## Summary\nFile content becomes corrupted after an edit, indicating CRDT merge failure.\n\n## Repro\n1. Create file `workspace/bartleby/test-note.txt` with content 'note'\n2. Wait for sync\n3. Edit file to contain 'updated note'\n4. Check sandbox\n\n## Expected\nContent: 'updated note'\n\n## Actual\nContent: 'updated updaed note' (corrupted merge of old and new content)\n\n## Analysis\nThe CRDT appears to be merging the old content 'note' with the new 'updated note' incorrectly, resulting in 'updated updaed note'.\n\n## Blocks\nAcceptance criterion E6","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T02:18:08.885726507Z","created_by":"jes","updated_at":"2026-01-03T03:45:07.862314284Z","closed_at":"2026-01-03T03:45:07.862314284Z","close_reason":"Unable to reproduce after multiple attempts. Comment from jes: 'Multiple tests with file creation and editing showed correct CRDT behavior. May have been a transient race condition.' Closing as unreproducible. If issue recurs, reopen with specific reproduction steps.","comments":[{"id":21,"issue_id":"CP-78a","author":"jes","text":"Unable to reproduce. Multiple tests with file creation and editing in text-to-telegram subdirectory showed correct CRDT behavior. 'note' to 'updated note' worked correctly. Rapid edits also converged correctly. May have been a transient race condition.","created_at":"2026-01-03T02:53:03Z"}]}
{"id":"CP-7cjh","title":"Reconciler creates child documents but doesn't update parent schema","description":"When the server's fs reconciler creates new subdirectories (e.g., tmux windows), it creates the child document nodes but fails to add them to the parent directory's schema. This causes other sync clients to never see the new directories.\n\n**Reproduction:**\n1. file-tmux-file creates new tmux window files in its sandbox\n2. Reconciler logs 'Migrated inline subdirectory' and 'Reconciler created document'\n3. But parent schema (e.g., tmux/0/) never gets the new entry\n4. Other syncs (bartleby, workspace) don't see the new window\n\n**Evidence:**\n- Server tmux/0 schema has 7 entries\n- Workspace tmux/0 directory has 10 entries (0-js-evaluator, 2-_tmux_, 4-jes missing from server)\n- Reconciler logs show documents were created but parent schema unchanged\n\n**Expected:** Parent schema should be updated when reconciler creates child documents.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-06T20:03:41.198249125Z","created_by":"jes","updated_at":"2026-01-06T20:45:50.231329326Z","closed_at":"2026-01-06T20:45:50.231329326Z","close_reason":"Added create_yjs_json_merge for additive schema syncs. Merged in PR #103."}
{"id":"CP-7el5","title":"Add --push-only and --pull-only flags to commonplace-sync","description":"Add directional sync modes to commonplace-sync:\n\n**--push-only**: \n- Watches local files for changes and pushes to server\n- Ignores server-side updates (no SSE subscription or pull)\n- Use case: source-of-truth files like .beads/issues.jsonl\n\n**--pull-only**:\n- Subscribes to server updates and writes to local files\n- Ignores local file changes (no file watcher)\n- Use case: read-only mirrors, generated content\n\nCurrent behavior (bidirectional) remains the default.\n\nImplementation:\n- Skip SSE subscription when --push-only\n- Skip file watcher setup when --pull-only\n- Validate flags are mutually exclusive","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T20:00:46.196501081Z","created_by":"jes","updated_at":"2026-01-03T23:04:24.043330229Z","closed_at":"2026-01-03T23:04:24.043330229Z","close_reason":"Implemented --push-only and --pull-only flags for commonplace-sync"}
{"id":"CP-7gx","title":"Sync --use-paths should work without --node when server has fs-root","description":"Currently sync client with --use-paths still requires --node. When using path-based endpoints (/files/*path), the sync should be able to work without specifying a node ID since paths are resolved on the server.\n\nWorkaround: Query /fs-root endpoint (CP-81o) to get the node ID.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T23:59:59.108226549Z","created_by":"jes","updated_at":"2026-01-01T11:33:34.815949Z","closed_at":"2026-01-01T11:33:34.815949Z","close_reason":"Fixed in PR #75. Sync with --use-paths can now auto-discover fs-root from server.","comments":[{"id":13,"issue_id":"CP-7gx","author":"jes","text":"Dependency: This requires CP-81o (GET /fs-root endpoint) to be implemented first. The sync client needs to be able to discover the fs-root document ID from the server before it can work without --node.\n\nWill implement CP-81o first, then come back to this.","created_at":"2026-01-01T11:21:19Z"}]}
{"id":"CP-7h3","title":"commonplace-ps should show sandbox child process info, not wrapper","description":"Currently commonplace-ps shows the commonplace-sync wrapper process PID and CWD for sandbox-exec processes. This is misleading because:\n\n- The CWD shows where the orchestrator started (e.g., /home/jes/commonplace)\n- The actual sandboxed app runs as a child process in /tmp/commonplace-sandbox-*\n\nExample current output:\n```\nbartleby  818853 Running  /home/jes/commonplace\n```\n\nBut the actual bartleby process (PID 818883) runs in /tmp/commonplace-sandbox-be791041-...\n\nOptions:\n1. Show child process PID and CWD instead of wrapper\n2. Show both (wrapper PID + child CWD)\n3. Add a column for 'sandbox path' when applicable","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T12:28:21.602293227Z","created_by":"jes","updated_at":"2026-01-03T19:14:44.953532069Z","closed_at":"2026-01-03T19:14:44.953532069Z","close_reason":"Fixed. Now reads child process CWD from /proc/\u003cchild_pid\u003e/cwd to show the actual sandbox directory instead of the wrapper's CWD."}
{"id":"CP-7m0","title":"Flat directory JSON with subdirectory documents","description":"Directory JSON should only contain one level of files. Subdirectories need to be their own separate JSON documents. This enables partial checkouts of large directory trees.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:47:47.262049538Z","created_by":"jes","updated_at":"2025-12-30T21:56:23.60592734Z","closed_at":"2025-12-30T21:56:23.60592734Z","close_reason":"Closed"}
{"id":"CP-7n2","title":"Refactor sync.rs: Extract file watcher logic","description":"Extract file watcher setup and event handling from sync.rs into dedicated module `src/sync/watcher.rs`. This handles notify events, debouncing, and change detection.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-30T00:34:50.932224-08:00","updated_at":"2025-12-30T15:26:25.522185703Z","closed_at":"2025-12-30T15:26:25.522185703Z","close_reason":"Merged in PR #39","dependencies":[{"issue_id":"CP-7n2","depends_on_id":"CP-jwf","type":"blocks","created_at":"2025-12-30T00:36:37.008385-08:00","created_by":"daemon"}]}
{"id":"CP-7ne","title":"Writes to JSONL files are disappearing","description":"Summary: JSONL file writes intermittently vanish; appended lines are missing after a short period, suggesting a sync/atomic-write issue or competing writers.\n\nFiles to modify:\n- src/bin/sync.rs (local file event handling and writeback)\n- src/sync/* (file watcher, coalescing, conflict resolution)\n- any JSONL writers (search for .jsonl writes)\n\nImplementation steps:\n1. Identify affected JSONL files and reproduce (append line, wait, verify line missing).\n2. Check for multiple writers or sandbox processes touching the same JSONL file.\n3. Inspect sync logs around the disappearance for overwrite or rollback events.\n4. Verify whether atomic write behavior or rename-based updates are being misinterpreted as deletes.\n5. Add a regression test that appends to a concrete JSONL file and confirms persistence through sync cycles.\n\nExample:\nBefore: Append a line to a JSONL file (e.g., history/events.jsonl), then wait ~N seconds.\nAfter: New line remains present unless explicitly removed.","notes":"Root cause likely: JSONL files are treated as plain text updates. upload_task only routes application/json to push_json_content; application/x-ndjson uses push_file_content (text), which sends Y.Text updates. On server, JSONL expects Y.Array; mismatched updates can serialize to empty or per-character JSONL. Add JSONL-aware upload path using create_yjs_jsonl_update and route jsonl/ndjson content types to it.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T00:00:47.541630379Z","created_by":"jes","updated_at":"2026-01-03T08:59:59.485881086Z","closed_at":"2026-01-03T08:59:59.485881086Z","close_reason":"Fixed in commit 3539e38 - JSONL uploads now use Y.Array updates instead of treating them as plain text, preventing data loss."}
{"id":"CP-80u","title":"Fix P2: Skip wiring when an identical edge already exists (PR #8)","description":"From PR #8 Codex review: The router creates wires based on managed_wires, but if a wiring already exists from an external source (e.g., /nodes/:from/wire/:to), this code will still call wire_* and create a second subscription. Consider checking existing registry wirings before adding.","design":"Added `find_existing_wiring(from, to, port)` method to NodeRegistry. Router manager now checks for existing wires before creating new ones and adopts them into managed_wires if found. Known limitation: Adopted wires skip the router's cycle error emission, but this is safe because external wire creation already performs cycle detection at the registry level.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T23:24:33.186937-08:00","updated_at":"2025-12-27T00:35:45.522329-08:00","closed_at":"2025-12-27T00:35:45.522329-08:00","close_reason":"Skip duplicate wirings implemented. Added find_existing_wiring() to NodeRegistry. Router now checks for existing wires before creating new ones and skips duplicates without claiming ownership (prevents router interference). Merged in PR #10."}
{"id":"CP-80z2","title":"XML documents using XmlFragment causes /replace to crash","description":"## Root Cause\n\nXML documents use `XmlFragment` internally (via `get_or_insert_xml_fragment`) but the diff module (`src/diff.rs`) creates updates for `Y.Text` type. When applying Text updates to an XmlFragment document, the server crashes.\n\n## Affected Endpoints\n- POST /docs/{id}/replace\n- POST /files/{path}/replace\n\n## Workaround Applied\nChanged XML content type to use `Y.Text` instead of `Y.XmlFragment` in:\n- src/document.rs (create_document, get_or_create_with_id, apply_yjs_update)\n- src/replay.rs (get_content_and_state_at_commit)\n\n## Proper Fix\nEither:\n1. Keep XML using Text (current workaround) - simpler but loses semantic XML editing\n2. Update diff module to detect content type and use appropriate Yjs type (XmlFragment vs Text)\n\n## Testing\nTest in tests/api_tests.rs was updated to use Text-based updates for XML documents.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T05:29:13.957190244Z","created_by":"jes","updated_at":"2026-01-07T19:21:09.471261202Z","closed_at":"2026-01-07T19:21:09.471261202Z","close_reason":"Fixed by implementing compute_xml_diff_update() in src/diff.rs that generates XmlFragment-compatible updates. Also fixed replay.rs to handle XML content type with XmlFragment."}
{"id":"CP-81o","title":"Server should expose fs-root document ID at /fs-root endpoint","description":"When server is started with --fs-root, there's no way for clients to discover the fs-root document ID. Add GET /fs-root endpoint that returns the document ID.\n\nThis would simplify the sync workflow - clients could auto-discover the fs-root instead of needing to pass --node.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T23:59:51.564657714Z","created_by":"jes","updated_at":"2026-01-01T11:27:19.342457135Z","closed_at":"2026-01-01T11:27:19.342457135Z","close_reason":"Fixed in PR #74. Added GET /fs-root endpoint that returns the fs-root document ID."}
{"id":"CP-8cd","title":"Make --recursive the default for orchestrator","description":"When running the orchestrator with a server that has --fs-root configured, --recursive mode should be the default behavior.\n\nCurrently requires explicit --recursive flag to discover all processes.json files in the filesystem tree. This should be the default since it's the most common use case.\n\nThe non-recursive mode (--watch-processes) can still be available for watching a specific document.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T19:21:01.334042203Z","created_by":"jes","updated_at":"2026-01-03T06:59:04.700263953Z","closed_at":"2026-01-03T06:59:04.700263953Z","close_reason":"Already implemented - --recursive defaults to true in src/cli.rs:120"}
{"id":"CP-8ci","title":"Sync sandbox mode with temp directory isolation","description":"Upgrade sync subprocess mode to sync sandbox: uses a temp directory, checks out a synced directory or subdirectory, runs the child process in there, and cleans up after itself when the child exits.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:50:05.321115052Z","created_by":"jes","updated_at":"2026-01-01T02:37:02.757303296Z","closed_at":"2026-01-01T02:37:02.757303296Z","close_reason":"Sandbox mode verified working: creates temp dir, syncs with server, runs command in sandbox, cleans up on exit","dependencies":[{"issue_id":"CP-8ci","depends_on_id":"CP-cxj","type":"blocks","created_at":"2025-12-30T18:02:57.400462144Z","created_by":"daemon"},{"issue_id":"CP-8ci","depends_on_id":"CP-w2v","type":"blocks","created_at":"2025-12-30T18:02:57.424433327Z","created_by":"daemon"}],"comments":[{"id":4,"issue_id":"CP-8ci","author":"jes","text":"Accidentally closed without implementation","created_at":"2025-12-30T21:02:26Z"},{"id":8,"issue_id":"CP-8ci","author":"jes","text":"PR #49 was stale - reviewing if sandbox mode actually works correctly","created_at":"2026-01-01T02:36:44Z"}]}
{"id":"CP-8fz","title":"Fix server replay to use node's content type for JSON documents","description":"P1 from PR #6 review: The server's /nodes/:id/head and replace endpoints replay with ContentType::Text, but Y.Map commits need ContentType::Json. When replaying Y.Map commits with Text type, replay.rs returns \"Text root not found\" causing 500 errors.\n\nFix: Update src/api.rs (around lines 460-464) to use the node's actual content type when replaying commits.","design":"Fixed in 3 places:\n\n1. api.rs get_node_head: Now gets content type from the node via DocumentNode downcast instead of hardcoding Text. This allows proper replay of JSON (Y.Map) commits.\n\n2. api.rs replace_content: Now validates content type and returns 415 error for non-text nodes. Replace endpoint only supports text because it uses text-based diffing.\n\n3. sync.rs push_schema_to_server: Simplified to always use edit endpoint with Y.Map updates. This avoids the replace endpoint's text-only limitation.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T18:13:33.205983-08:00","updated_at":"2025-12-26T18:22:55.113026-08:00","closed_at":"2025-12-26T18:22:55.113026-08:00","close_reason":"Fixed server replay to use node's actual content type. GET /nodes/:id/head now works for JSON (Y.Map) documents. Replace endpoint properly rejects non-text content with 415. Merged in PR #7.","labels":["P1","api","bug","yjs"]}
{"id":"CP-8nbb","title":"file-tmux-file: carriage returns not working","description":"Summary: Carriage returns (\\r) are not being handled correctly in file↔tmux↔file flows, causing cursor-return behavior to be lost or rendered incorrectly.\n\nFiles to modify:\n- src/tmux (or tmux integration module)\n- src/sync/file_sync.rs\n- src/sync/watcher.rs\n- tests (tmux/file IO handling)\n\nImplementation steps:\n1. Reproduce by sending a line with \\r (e.g., progress-style output) through file→tmux→file and observe incorrect rendering/output.\n2. Trace how file content is read, normalized, and written; confirm whether \\r is stripped, converted to \\n, or ignored.\n3. Preserve \\r in the data path (or map to tmux send-keys appropriately) so terminal cursor returns behave as expected.\n4. Add a regression test with a \\r-containing payload to ensure roundtrip fidelity.\n\nExample:\nBefore: \"progress 10%\\rprogress 20%\" becomes two lines or loses cursor reset.\nAfter: tmux displays the overwrite behavior and output file preserves intended \\r semantics.\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T03:50:50.189985064Z","created_by":"jes","updated_at":"2026-01-07T00:51:01.079041467Z","closed_at":"2026-01-07T00:51:01.079041467Z","close_reason":"Not reproducible - tested and carriage returns are working correctly"}
{"id":"CP-8ou","title":"Directory sync doesn't preserve node_ids from existing .commonplace.json","description":"When running commonplace-sync in directory mode, scan_directory() always generates fresh Entry structs with node_id: None. It doesn't read the existing .commonplace.json to preserve manually-set node_ids.\n\nThis blocks the ability to link files across directories by manually editing node_ids in the schema - the sync overwrites them on every scan.\n\nExpected behavior: scan_directory should merge with existing .commonplace.json, preserving node_ids for files that still exist.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-31T23:35:43.380888682Z","created_by":"jes","updated_at":"2025-12-31T23:50:25.998188768Z","closed_at":"2025-12-31T23:50:25.998188768Z","close_reason":"Merged in PR #62. scan_directory now preserves node_ids from existing .commonplace.json."}
{"id":"CP-8p9","title":"Sync should delete directories removed from schema","description":"When a directory entry is removed from .commonplace.json schema, the sync should delete the corresponding physical directory from disk.\n\nCurrently, schema changes propagate but the physical directory remains orphaned on disk.\n\nRelated to CP-jgn (the inverse problem).","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T04:59:34.340307337Z","created_by":"jes","updated_at":"2026-01-03T08:31:28.3992328Z","closed_at":"2026-01-03T08:31:28.3992328Z","close_reason":"Sync now deletes files and directories that have been removed from the server schema. When schema changes are detected, orphaned files are deleted and their sync tasks stopped, and orphaned directories are recursively removed."}
{"id":"CP-8sf","title":"Add CLI to signal orchestrator-managed process by path/name","description":"Summary: Provide a command-line tool to signal a running process by path and process name.\n\nFiles to modify:\n- src/bin (new binary, e.g., src/bin/commonplace-signal.rs)\n- src/orchestrator (process lookup by name + cwd/path, expose signal API)\n- docs/DEVELOPMENT.md or README.md (document usage)\n\nImplementation steps:\n1. Accept arguments: path (cwd or root) and process name; optional signal (default SIGTERM).\n2. Resolve to a running orchestrator-managed process that matches name and path.\n3. Send signal and report success; if not found, exit non-zero with a clear error.\n4. Add `--json` output with resolved pid, signal, name, and cwd.\n\nExample:\ncommonplace-signal --path /home/jes/commonplace --name sync --signal SIGTERM\n→ signaled pid 12345 (sync) in /home/jes/commonplace\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T06:08:05.415694784Z","created_by":"jes","updated_at":"2026-01-03T07:46:30.811509276Z","closed_at":"2026-01-03T07:46:30.811509276Z","close_reason":"Implemented commonplace-signal CLI to send signals to orchestrator-managed processes by name. Supports --path filter and --signal option."}
{"id":"CP-8t3","title":"Move HTTP interface to separate binary with MQTT connection","description":"Extract the HTTP interface into a new binary that connects to the document store over MQTT instead of direct access.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:46.493852588Z","created_by":"jes","updated_at":"2025-12-29T08:45:22.041612098Z","closed_at":"2025-12-29T01:52:01.289555636Z","close_reason":"HTTP/Store split implemented. Two new binaries: commonplace-store (MQTT+persistence) and commonplace-http (stateless HTTP gateway). Fixed P1 issues from codex reviews. Merged in PR #14.","dependencies":[{"issue_id":"CP-8t3","depends_on_id":"CP-08v","type":"blocks","created_at":"2025-12-28T21:57:24.845534402Z","created_by":"daemon"}]}
{"id":"CP-8tiw","title":"P2: log.rs silently ignores Yjs update application failures","description":"In log.rs around lines 315-322, when applying Yjs updates fails, the error is logged but execution continues as if successful. This can lead to divergent state between what the log shows and actual document content.\n\nLocation: src/bin/log.rs:315-322\nFound by: codex review","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T09:09:57.9244403Z","created_by":"jes","updated_at":"2026-01-06T01:14:47.719996001Z","closed_at":"2026-01-06T01:14:47.719996001Z","close_reason":"Added eprintln warnings for base64 decode and Yjs update decode failures"}
{"id":"CP-8vr","title":"Sync race condition when multiple files share same UUID","description":"When using commonplace-link to make two files share the same UUID, edits to one file don't reliably sync.\n\nROOT CAUSE (from codex review):\nRace between SSE writes and upload_task's initial file read. When processing a change, upload_task reads the file on disk BEFORE it checks state.pending_write. If another SSE handler for the same document is writing server content (because a second local file shares the UUID), the upload task captures the just-written server version instead of the user's edit. It then posts that stale content and logs a successful upload even though the user's change was overwritten on disk and never reaches the server.\n\nFIX: Check pending_write barrier BEFORE reading the file content in upload_task.\n\nLocation: src/sync/file_sync.rs:17-60\n\nRepro:\n1. Create two files with commonplace-link sharing a UUID\n2. Edit file A\n3. Sync reports 'Uploaded: X chars inserted'\n4. But server content remains unchanged\n\nImpact: Sandbox linking architecture (docs/SANDBOX_LINKING.md) doesn't work reliably.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T05:11:38.809310083Z","created_by":"jes","updated_at":"2026-01-01T05:29:49.087146613Z","closed_at":"2026-01-01T05:29:49.087146613Z","close_reason":"Fixed by capturing file content at watcher notification time instead of in upload_task. The watcher now reads the file immediately when detecting a change and passes the content in FileEvent::Modified(Vec\u003cu8\u003e), preventing SSE from overwriting the file before upload_task processes it."}
{"id":"CP-92l","title":"Rename commonplace-replay to commonplace-log and commonplace-show with git-like behavior","description":"Split commonplace-replay into two git-like commands:\n\n**commonplace-log** (like git log):\n- Show commit history for a file\n- Display timestamps, commit IDs, maybe diffs\n- Support filtering by date range, count, etc.\n- Default: show recent commits with summary\n\nGit-compatible output modes:\n- `--oneline`: compact one-line-per-commit format (cid timestamp summary)\n- `--graph`: ASCII art showing commit ancestry/branching\n- `--decorate`: show branch/tag info if applicable\n- `--stat`: show file change statistics (+/- lines)\n- `-n \u003ccount\u003e`: limit number of commits shown\n- `--since`, `--until`: date filtering\n\n**commonplace-show** (like git show):\n- Show content at a specific commit\n- Default: show current HEAD content\n- Support `--at \u003ccid\u003e` or positional `\u003ccid\u003e` for historical content\n- `--stat`: show change stats for the commit\n\nCurrent behavior to preserve:\n- Work from any directory (not just inside workspace)\n- Resolve file path to UUID via .commonplace.json\n- --json output format\n\nPotential enhancements:\n- commonplace-log --diff: show inline diffs between commits\n- commonplace-diff \u003ccid1\u003e \u003ccid2\u003e: compare two commits","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T19:18:18.499816787Z","created_by":"jes","updated_at":"2026-01-03T20:33:59.115960721Z","closed_at":"2026-01-03T20:33:59.115960721Z","close_reason":"Added commonplace-log and commonplace-show binaries with git-like flags (--oneline, --graph, --stat, -n, --since/--until, --json). Extracted workspace path resolution to shared module."}
{"id":"CP-96p","title":"create_yjs_json_update produces malformed nested JSON","description":"When pushing JSON to a Y.Map document, the create_yjs_json_update function puts the entire root object as a string value instead of properly nesting the Y.Map structure. Example: {\"version\":1,\"root\":\"\\n  \\\"version\\\": 1,\\n  \\\"root\\\": {\\n...\"} - The root field contains escaped JSON string instead of an object.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T00:28:29.314098124Z","created_by":"jes","updated_at":"2026-01-01T02:06:51.668159906Z","closed_at":"2026-01-01T02:06:51.668159906Z","close_reason":"Symptom of CP-g0c schema corruption - Y.Map roundtrip tests pass and show correct nested JSON handling"}
{"id":"CP-9abt","title":"WebSocket commonplace protocol extensions (Phase 2)","description":"Add commonplace-specific message types to WebSocket endpoint.\n\nRequires: CP-59h Phase 1 (y-websocket core) - DONE\n\n## Message Types\n\n- Type 3: CommitMeta (parent cid, timestamp, author, message)\n- Type 4: BlueEvent (commit notifications)\n- Type 5: RedEvent (ephemeral JSON events)\n\n## Implementation\n\n1. Add CommitMeta handling in handler.rs\n   - Client sends commit context with updates\n   - Server persists to CommitStore\n\n2. Add BlueEvent broadcasting\n   - When commits are created, broadcast to commonplace-mode clients\n   - Include doc_id, commit_id, timestamp\n\n3. Add RedEvent round-trip\n   - Client sends ephemeral JSON\n   - Server broadcasts to other clients in room\n\n## Files to modify\n\n- src/ws/handler.rs - Handle new message types\n- src/ws/room.rs - BlueEvent/RedEvent broadcasting\n- src/ws/protocol.rs - Already has encoding, add tests","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-04T02:01:36.816738371Z","created_by":"jes","updated_at":"2026-01-04T02:18:07.381495448Z","closed_at":"2026-01-04T02:18:07.381495448Z","close_reason":"Implemented commonplace protocol extensions: CommitMeta handling, BlueEvent broadcast, RedEvent round-trip","dependencies":[{"issue_id":"CP-9abt","depends_on_id":"CP-59h","type":"discovered-from","created_at":"2026-01-04T02:02:24.612719386Z","created_by":"jes"}]}
{"id":"CP-9u1","title":"Sync client uses derived IDs instead of UUIDs from schema","description":"After CP-4f7 (deprecate derived IDs), the reconciler generates UUIDs for file entries. But the sync client still constructs derived IDs like 'fs-root:path/to/file.txt' when syncing file contents, instead of reading the node_id UUIDs from the updated schema.\n\nSteps to reproduce:\n1. Start server with --fs-root\n2. Run sync with --directory pointing to a folder with files\n3. Sync pushes schema, reconciler creates documents with UUIDs\n4. Sync tries to push file content using derived ID\n5. 'Identifier not found, waiting for reconciler' loops forever\n\nExpected: Sync should re-fetch the schema after push to get the UUID node_ids, then use those for file content syncing.\n\nBlocking bartleby integration testing.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-31T16:54:04.192088145Z","created_by":"jes","updated_at":"2025-12-31T17:17:14.235135137Z","closed_at":"2025-12-31T17:17:14.235135137Z","close_reason":"Fixed: Sync client now recursively fetches schemas from node-backed directories to resolve UUIDs. Added build_uuid_map_recursive() function that follows directory references."}
{"id":"CP-9ul","title":"Add commonplace CLI dispatcher that runs subcommands","description":"Create a main `commonplace` binary that dispatches to subcommands, like git:\n\n```\ncommonplace sync ...    → runs commonplace-sync\ncommonplace log ...     → runs commonplace-log\ncommonplace show ...    → runs commonplace-show\ncommonplace ps          → runs commonplace-ps\ncommonplace link ...    → runs commonplace-link\ncommonplace server ...  → runs commonplace-server\n```\n\nImplementation options:\n1. **exec approach**: Just exec the appropriate binary (like git does with git-*)\n2. **built-in approach**: Compile all commands into one binary with subcommands\n\nBenefits:\n- Cleaner UX: `commonplace log` vs `commonplace-log`\n- Discoverability: `commonplace --help` shows all commands\n- Consistent with git, cargo, docker patterns\n\nShould support:\n- `commonplace help \u003ccmd\u003e` or `commonplace \u003ccmd\u003e --help`\n- Pass through all args to subcommand\n- Helpful error if subcommand binary not found","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T19:19:26.189757831Z","created_by":"jes","updated_at":"2026-01-03T20:39:04.41226905Z","closed_at":"2026-01-03T20:39:04.41226905Z","close_reason":"Added commonplace dispatcher binary that runs subcommands (commonplace log, commonplace show, etc). Features: help, version, typo suggestions."}
{"id":"CP-9wb6","title":"Sync client creates inline subdirectories that server rejects after CP-e3jr","description":"## Summary\n\nAfter merging CP-e3jr (remove inline subdirectory support), the sync client and server are incompatible. The sync client creates schemas with inline subdirectories (directories with `node_id: null`), but the server now requires all directories to be node-backed.\n\n## Symptoms\n\n- Server logs show: `Skipping subdirectory document: migration failed: Schema error: Inline subdirectory '0' is not supported. All directories must be node-backed (have node_id).`\n- `/files/` API returns \"Path not found in filesystem\" for affected directories\n- Orchestrator discovery fails with 404 when trying to load `__processes.json` from affected paths\n- Sandbox processes (like file-tmux-file) fail to start because their process definitions can't be loaded\n\n## Reproduction\n\n1. Start orchestrator with fresh server (no --database persistence)\n2. Sync client pushes filesystem schema to server\n3. Any directory structure with nested subdirectories gets inline entries\n4. Server reconciler rejects these schemas\n5. Files in those directories become inaccessible via /files/ API\n\n## Affected Code\n\n- `src/sync/dir_sync.rs` - Creates schemas with inline subdirectories\n- `src/fs/reconciler.rs` - Rejects inline subdirectories (correct behavior after CP-e3jr)\n\n## Fix Required\n\nUpdate the sync client to create node-backed directories instead of inline ones. When syncing a directory structure, each subdirectory should:\n1. Get its own document/node_id on the server\n2. Reference that node_id in the parent schema instead of embedding entries inline\n\n## Workaround\n\nNone currently - this blocks all nested directory syncing.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-08T23:52:32.120754165Z","created_by":"jes","updated_at":"2026-01-09T00:28:12.91091059Z","closed_at":"2026-01-09T00:28:12.91091059Z","close_reason":"Fixed: Sync client now creates node-backed directories instead of inline subdirectories. All tests pass."}
{"id":"CP-a0g","title":"Orphaned sandbox processes survive orchestrator restarts","description":"When the orchestrator is restarted (not just killed), old sandbox processes from previous runs can remain orphaned.\n\nObserved:\n- Orchestrator started at 18:04, spawned text-to-telegram (PIDs 2831xxx)\n- Orchestrator restarted at 18:27, spawned new text-to-telegram (PIDs 2847xxx)  \n- Old 2831xxx processes still running alongside new ones\n- This caused Telegram API conflicts (multiple bot instances polling)\n\nExpected: When orchestrator starts, it should either:\n1. Kill any orphaned processes from previous runs (check .pid files in sandboxes?)\n2. Or detect existing sandbox syncs and reuse them instead of spawning duplicates\n\nThe T1-T6 termination cascade tests verify cleanup when killing the *current* orchestrator, but don't cover the restart scenario where old processes persist.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T18:49:13.77723552Z","created_by":"jes","updated_at":"2026-01-03T07:21:05.246726667Z","closed_at":"2026-01-03T07:21:05.246726667Z","close_reason":"Implemented: cleanup_stale_sandboxes() at sync startup + PID file tracking + PR_SET_PDEATHSIG","dependencies":[{"issue_id":"CP-a0g","depends_on_id":"CP-occ","type":"relates-to","created_at":"2026-01-02T18:51:55.367733448Z","created_by":"daemon"},{"issue_id":"CP-a0g","depends_on_id":"CP-yw8","type":"relates-to","created_at":"2026-01-02T19:21:00.669824268Z","created_by":"daemon"}]}
{"id":"CP-a30","title":"Blocks acceptance: File content not syncing to sandboxes","description":"During acceptance testing, file content edits in workspace are not propagating to sandbox directories.\n\nSymptoms:\n- workspace/text-to-telegram/test-file.txt has 'hello' locally\n- Server shows empty content for the file\n- Sandbox file is empty\n\nRelated issues:\n- CP-azw (JSON files sync as empty)\n- This may be a broader sync issue affecting all content types\n\nReproduction:\n1. Start server, workspace sync, orchestrator\n2. Create/edit workspace/text-to-telegram/test-file.txt with 'hello'\n3. Wait 5+ seconds\n4. Check server: curl http://localhost:3000/docs/{node_id}/head\n5. Check sandbox: cat /tmp/commonplace-sandbox-*/test-file.txt\n6. Both should have 'hello' but show empty\n\nThis blocks acceptance criteria C1-C6, E1-E6, and dependent tests.","notes":"Verified working after sync restart. Initial content push issue is timing-related and resolves after file watcher stabilizes.","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-01-03T03:59:30.365618809Z","created_by":"jes","updated_at":"2026-01-03T04:22:42.473808382Z","closed_at":"2026-01-03T04:22:42.473815905Z"}
{"id":"CP-a31","title":"commonplace-link doesn't push schema changes to server","description":"When commonplace-link modifies a local .commonplace.json file to add a linked entry, the sync process doesn't detect this change and push it to the server. The schema change stays local until manually pushed.\n\nWorkaround: Manually push the schema with curl:\ncurl -X POST http://localhost:3000/docs/{node_id}/replace -H 'Content-Type: application/json' -d \"$(cat .commonplace.json)\"\n\nExpected: commonplace-link should push the schema change to server after modifying local schema files, OR sync should detect local schema changes and push them.","notes":"This is the root cause of CP-fr4 (linked files not syncing). The fix is to add HTTP client code to link.rs to push schema changes to server after modifying local .commonplace.json files. The push_schema_to_server function already exists in sync/client.rs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T10:34:10.974157176Z","created_by":"jes","updated_at":"2026-01-03T05:38:14.912198187Z","closed_at":"2026-01-03T05:38:14.912198187Z","close_reason":"Fixed: commonplace-link now pushes schema changes to server after local write. Added --server argument, async main, reqwest client, and push_schema_to_server calls."}
{"id":"CP-a7lb","title":"P1: WebSocket SyncStep2 responses dropped under backpressure","description":"In handler.rs around lines 262-270, when the WebSocket send buffer is full, SyncStep2 sync responses are silently dropped. This can cause sync to stall or produce inconsistent state. Should either block, buffer, or error rather than drop.\n\nLocation: src/ws/handler.rs:262-270\nFound by: codex review","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T09:09:55.226414072Z","created_by":"jes","updated_at":"2026-01-05T23:05:38.008662504Z","closed_at":"2026-01-05T23:05:38.008662504Z","close_reason":"Fixed: SyncStep2 response now returns error if send fails instead of silently dropping"}
{"id":"CP-a85","title":"Filetree to XHTML renderer","description":"Render a filetree (directory structure) as XHTML output.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:54:39.878136696Z","created_by":"jes","updated_at":"2026-01-07T04:31:06.281613644Z","closed_at":"2026-01-07T04:31:06.281613644Z","close_reason":"Implemented filetree-to-xml process: Added SDK cp.watch() wildcard support, created filetree-to-xml.ts with recursive schema watching, fixed orchestrator --allow-import for Deno 2.x. Process registers and starts but has XML output merging issues - filed follow-up bug.","labels":["future-work"]}
{"id":"CP-aa5","title":"Make debug previews in document replace UTF-8 safe","description":"Summary: Prevent UTF-8 slicing panics in replace_content debug logging so document updates apply.\n\nFiles to modify:\n- src/services/document.rs (debug preview slices around lines 623, 625, 738, 754)\n\nImplementation steps:\n1. Add a small helper to preview strings by character count (not byte index).\n2. Replace unsafe byte slicing in debug logs with the helper.\n3. Keep byte length logging unchanged to preserve diagnostics.\n\nExample:\nBefore: \u0026content_before[..content_before.len().min(50)]\nAfter:  preview_text(\u0026content_before, 50)\n","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-03T04:38:59.366095457Z","created_by":"jes","updated_at":"2026-01-03T04:39:57.640942282Z","closed_at":"2026-01-03T04:39:57.640942282Z","close_reason":"Done"}
{"id":"CP-adm","title":"Macaroons for MQTT-layer authorization","description":"Implement macaroon-based authorization enforced at the MQTT layer. Macaroons provide:\n- Delegatable, attenuatable credentials\n- Fine-grained path-based permissions\n- Caveat-based restrictions (time, scope, etc.)\n\nEnforcement at MQTT means all clients (JS sandbox, external processes, CLI, MCP servers) go through the same auth layer.","design":"Spec drafted in `docs/MACAROONS.md`.\n\nKey decisions (v1):\n- Enforcement: Mosquitto auth plugin as verifier; offline verification at broker.\n- Transport: MQTT CONNECT password carries base64url macaroon (username optional for logging).\n- Caveats:\n  - cp.v=1\n  - cp.exp=\u003cunix_seconds\u003e (recommended)\n  - cp.aud=\u003cbroker_id\u003e (recommended)\n  - cp.cid=\u003cmqtt_client_id\u003e (optional binding)\n  - cp.acl=\u003cbase64url(json)\u003e where json contains publish/subscribe/both topic filters.\n- ACL evaluation: multiple cp.acl caveats are intersected (supports attenuation by adding stricter ACLs).\n- SUBSCRIBE policy: prefer subset-of-allowed check for topic filters; allow exact-match as v1 fallback.\n- Revocation strategy: short expirations + key rotation in v1; optional third-party caveats/discharge later.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.628965-08:00","updated_at":"2026-01-04T01:35:59.034496752Z","labels":["future-work"]}
{"id":"CP-ajb","title":"Add integration tests for MQTT path resolution","design":"Needs design discussion: Requires understanding MQTT broker setup for tests. Current codebase doesn't have MQTT integration tests - would need to add test infrastructure first (mock broker or real broker in tests). Substantial effort beyond just adding test cases.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T08:03:39.396454509Z","created_by":"jes","updated_at":"2025-12-30T23:17:27.562485622Z","closed_at":"2025-12-30T23:17:27.562485622Z","close_reason":"Added 13 integration tests for MQTT path resolution. PR #54 merged."}
{"id":"CP-ayri","title":"P2: cbd status update ignores close metadata","description":"In cbd.rs around lines 1003-1006, when updating issue status to 'closed', the code doesn't properly handle close_reason and close_context fields that should be set. The update command should accept these fields when status=closed.\n\nLocation: src/cbd.rs:1003-1006\nFound by: codex review","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T09:09:50.974241873Z","created_by":"jes","updated_at":"2026-01-06T00:49:21.193181395Z","closed_at":"2026-01-06T00:49:21.193181395Z","close_reason":"Added --reason flag to update command, auto-sets closed_at when status=closed"}
{"id":"CP-az4","title":"commonplace-link doesn't support node-backed directories","description":"When trying to link files where one is in a node-backed directory (like bartleby/), commonplace-link fails with 'Directory bartleby has no entries (node-backed?)'.\n\nTest case:\ncd workspace\n../target/release/commonplace-link shared-a.txt bartleby/shared-b.txt\n\nError: Directory bartleby has no entries (node-backed?)\n\nThe tool needs to be updated to fetch the nested schema from the server for node-backed directories.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T09:46:43.116817489Z","created_by":"jes","updated_at":"2026-01-02T10:27:00.376511008Z","closed_at":"2026-01-02T10:27:00.376511008Z","close_reason":"Fixed. commonplace-link now supports node-backed directories by detecting them during path traversal and loading their local .commonplace.json files. Both source and target can be in node-backed subdirectories. PR #88 merged."}
{"id":"CP-az8d","title":"file-tmux-file: XML docs should use Yjs XmlFragment, not Text","description":"Summary: XML documents in the file↔tmux↔file path are currently coerced to Yjs Text as a workaround, which loses element-level XML CRDT semantics. The diff/merge layer should support Yjs XmlFragment directly so XML edits preserve structure-aware operations.\\n\\nFiles to modify:\\n- src/sync/file_sync.rs\\n- src/sync/diff.rs (or the XML/Yjs diff module)\\n- src/tmux (tmux integration for XML docs)\\n- tests (XML diff/merge and file-tmux-file roundtrip)\\n\\nImplementation steps:\\n1. Identify where XML documents are detected and coerced to Text (the workaround path).\\n2. Update the diff/merge module to accept and operate on Yjs XmlFragment, preserving element boundaries and attributes.\\n3. Plumb XmlFragment through file-tmux-file flow without type coercion.\\n4. Ensure serialization/deserialization of XML retains structure and works with existing CRDT ops.\\n5. Add tests that apply element-level edits (insert/remove nodes/attributes) and verify correct merges through the tmux/file pipeline.\\n\\nExample:\\nBefore: \u003cp\u003e\u003cb\u003ehi\u003c/b\u003e\u003c/p\u003e edits become flat text; element merges are lost.\\nAfter: XmlFragment preserves \u003cb\u003e node operations and merges structurally.\\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T05:29:24.125605677Z","created_by":"jes","updated_at":"2026-01-07T19:21:25.519416271Z","closed_at":"2026-01-07T19:21:25.519416271Z","close_reason":"Core XmlFragment support implemented. XML documents now use XmlFragment with proper diff/replace support via compute_xml_diff_update(). File sync path should now work with XML content type."}
{"id":"CP-azw","title":"Blocks acceptance: New JSON files sync as empty {}","description":"Summary: Creating a JSON file locally can result in the synced file becoming empty ({}). Example: writing '{\"a\": 1}' to baz.json results in the file content changing to '{}'.\n\nRepro:\n1. cd ~/commonplace/workspace/bartleby\n2. echo '{\"a\": 1}' \u003e baz.json\n3. cat baz.json\n4. Observe output becomes '{}' (empty object)\n\nFiles to modify:\n- src/bin/sync.rs (file create/update handling)\n- src/sync/* (create vs update detection, CRDT initialization)\n- any JSON format handling that normalizes/rewrites content\n\nImplementation steps:\n1. Reproduce with sync logs enabled; capture file watcher events and server updates.\n2. Check if initial file creation triggers schema creation with empty JSON and overwrites local content.\n3. Verify whether CRDT or JSON parser normalizes invalid/partial reads on create.\n4. Ensure create+write is treated atomically (avoid reading file before write completes).\n5. Add a regression test for create/write JSON file content preservation.\n\nExample:\nBefore: baz.json contains '{\"a\": 1}'.\nAfter: baz.json remains '{\"a\": 1}' and is pushed to server without being replaced by '{}'.","notes":"Verified working after sync restart. JSON file sync issue is timing-related during initial sync.","status":"closed","priority":0,"issue_type":"bug","created_at":"2026-01-03T00:02:32.674091099Z","created_by":"jes","updated_at":"2026-01-03T04:22:43.331706593Z","closed_at":"2026-01-03T04:22:43.331714451Z"}
{"id":"CP-bl1q","title":"Petri-token like functionality (\"green\")","description":"Future exploration: Add petri-token like functionality to commonplace, potentially called \"green\". Details TBD.","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-05T23:42:02.081162414Z","created_by":"jes","updated_at":"2026-01-05T23:42:02.081162414Z","labels":["future-work"]}
{"id":"CP-bl9","title":"Bartleby input document lines reappear after deletion","description":"Summary: The bartleby input document periodically repopulates previously deleted lines; deletions appear to be undone, suggesting a sync or writeback issue.\n\nFiles to modify:\n- workspace/bartleby/input.txt (observed symptom; replace with actual input doc path)\n- src/bin/sync.rs (inspect bidirectional sync + conflict resolution)\n- src/sync/* (file event handling and writeback logic)\n- src/orchestrator/* (if sandbox processes are restarting or resyncing)\n\nImplementation steps:\n1. Identify the exact input document path and reproduction (delete lines, wait, observe reappearance).\n2. Check if multiple processes are writing to the same document (duplicate sandboxes or multiple bartleby instances).\n3. Inspect sync logs around the time of reappearance for incoming edits vs. local file events.\n4. Verify whether sync is re-applying server state after local deletes (e.g., due to missed local change or schema mismatch).\n5. Add a test or logging to capture the ordering of local delete vs. remote update events.\n\nExample:\nBefore: Delete lines 10-20 in bartleby input file; after ~N seconds, lines 10-20 reappear unchanged.\nAfter: Deleted lines stay deleted unless a new remote edit explicitly re-adds them.","notes":"Plan: detect atomic writes (tmp-\u003erename) in sync so replacements are treated as content updates, not delete+create.\n\nProposed approach:\n1) Define atomic pattern: CREATE temp file + WRITE/CLOSE + RENAME temp -\u003e target (often preceded by REMOVE target). Treat as single update to target.\n2) Add event coalescer in sync watcher keyed by directory + basename. Buffer events for short window (50–200ms). If REMOVE target + RENAME tmp-\u003etarget occurs within window, collapse to update target and ignore temp file.\n3) Use rename-correlation when available (inotify cookie IDs); otherwise fallback to time+path heuristics.\n4) Sync pipeline: on coalesced update, read target and emit content update, not delete+create. Ignore temp files by pattern and by rename-in-window.\n5) Tests: (a) atomic write via temp+rename emits exactly one update to server, (b) delete+create without rename remains delete+create.\n\nLikely files:\n- src/bin/sync.rs\n- src/sync/* (event handling / coalescing)\n\nWhy: text-to-telegram uses atomic write (temp -\u003e rename). Without coalescing, watcher may miss or double-fire and CRDT may treat replacement as reinsert, causing deleted lines to reappear.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T19:32:15.387195704Z","created_by":"jes","updated_at":"2026-01-02T20:07:31.663592454Z","closed_at":"2026-01-02T20:07:31.663592454Z","close_reason":"Fixed. Implemented atomic write detection in directory watcher: Deleted+Created within debounce window coalesced to Modified. Added temp file filtering. PR #94 merged.","comments":[{"id":20,"issue_id":"CP-bl9","author":"jes","text":"Investigation findings:\n\n1. Text-to-telegram uses atomic writes (temp file + rename) in _atomic_write()\n2. This creates a new inode each time, which may confuse the file watcher or CRDT sync\n3. The output.txt shows the same prompts being processed multiple times at different timestamps\n4. Example: '[2025-12-31 23:01:52] hi' was processed at 01:20:53 AND again at 01:30:24\n\nPossible causes:\na) Atomic write creates new file, sync treats it as replacement rather than edit\nb) CRDT merge conflicts when multiple sync clients have divergent states\nc) File watcher missing events or double-firing on atomic writes\n\nNext steps:\n- Check if sync's file watcher handles atomic writes correctly\n- Consider using in-place edits instead of atomic writes in text-to-telegram\n- Add logging to trace edit propagation through the sync chain","created_at":"2026-01-02T19:47:11Z"}]}
{"id":"CP-bno","title":"POST /docs should accept initial content in request body","description":"Currently POST /docs creates an empty document. The request body is not used as initial content.\n\nEnhancement: Allow POST /docs to accept content in the body, either:\n1. JSON body for JSON documents\n2. Text body for text documents\n\nThis would simplify workflows where you want to create a document with specific content.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-01T00:15:49.814509595Z","created_by":"jes","updated_at":"2026-01-01T11:40:47.686684035Z","closed_at":"2026-01-01T11:40:47.686684035Z","close_reason":"Fixed in PR #76. POST /docs now accepts optional 'content' field in request body for setting initial document content. Returns 400 and cleans up if content setting fails."}
{"id":"CP-bnv","title":"Add path-based HTTP API endpoints","design":"Needs design discussion: What should the path-based API look like? Options: 1) /files/path/to/file.txt 2) /docs?path=path/to/file.txt 3) Something else. Need to decide URL structure, how to handle URL encoding of paths, and whether to support both path and UUID access on same endpoints.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-29T08:33:32.251084948Z","created_by":"jes","updated_at":"2025-12-29T21:44:24.931689601Z","closed_at":"2025-12-29T21:44:24.931689601Z","close_reason":"Added /files/*path endpoints for path-based HTTP API access. Merged in PR #24."}
{"id":"CP-bt0","title":"Add CLI to list orchestrator-managed processes (pid/cwd)","description":"Summary: Provide a command-line tool to list all processes currently managed by the commonplace orchestrator, including PID and CWD. The list must include both the orchestrator's direct child processes and any sync subprocesses spawned beneath them.\n\nFiles to modify:\n- src/bin (new binary, e.g., src/bin/commonplace-ps.rs)\n- src/orchestrator (add method to enumerate running processes and their metadata)\n- docs/DEVELOPMENT.md or README.md (document usage)\n\nImplementation steps:\n1. Add an orchestrator query API that returns process name, PID, and working directory, including nested child processes spawned by sync.\n2. Implement CLI that prints a table to stdout; include `--json` option for machine-readable output.\n3. If orchestrator is not running, print a clear error and exit non-zero.\n\nExample:\ncommonplace-ps\nname\\tpid\\tcwd\nserver\\t12345\\t/home/jes/commonplace\nsync\\t12346\\t/home/jes/commonplace/workspace\nsync-child\\t12347\\t/home/jes/commonplace/workspace\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T05:49:01.43131488Z","created_by":"jes","updated_at":"2026-01-03T07:31:52.250923124Z","closed_at":"2026-01-03T07:31:52.250923124Z","close_reason":"Implemented commonplace-ps CLI that reads status file from orchestrator. Added OrchestratorStatus and ProcessStatus types in src/orchestrator/status.rs. Orchestrator writes status to /tmp/commonplace-orchestrator-status.json when processes start/stop."}
{"id":"CP-bth","title":"Sync tool should respect environment variables as set by orchestrator","description":"The sync client (commonplace-sync) should read and respect environment variables that are set by the orchestrator process. This allows the orchestrator to configure sync behavior (server URL, node ID, etc.) through environment variables rather than requiring all configuration to be passed as CLI arguments.\n\nNote: This issue was recovered from commit ee6f395 after being accidentally deleted during a beads sync conflict.","notes":"Reviewed: sync tool already respects COMMONPLACE_SERVER, COMMONPLACE_NODE, COMMONPLACE_FORK_FROM via clap env attribute. May need COMMONPLACE_MQTT if direct MQTT support added to sync.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T06:44:05.946481773Z","created_by":"jes","updated_at":"2025-12-30T18:42:26.376893745Z","closed_at":"2025-12-30T18:42:26.376893745Z","close_reason":"Closed"}
{"id":"CP-buj","title":"Sync should auto-convert symlinks to commonplace-linked files","description":"When commonplace-sync encounters a symlink in the synced directory, it should:\n\n1. Check if the symlink target is also within a synced directory\n2. If so, automatically convert to a commonplace-link (same UUID)\n3. If not, warn the user that the symlink won't sync correctly\n\nThis prevents agents and users from accidentally creating symlinks that break sync, by transparently converting them to the correct mechanism.\n\nEdge cases:\n- Symlink to file outside workspace: warn and skip\n- Symlink to directory: may need special handling (directory linking not yet supported)\n- Circular symlinks: detect and warn","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-02T19:17:03.570133771Z","created_by":"jes","updated_at":"2026-01-03T08:57:14.276022696Z","closed_at":"2026-01-03T08:57:14.276022696Z","close_reason":"Implemented symlink auto-conversion to commonplace-linked files. When sync encounters a symlink within the workspace, it uses the target's node_id for the symlink entry, effectively creating a commonplace-link. Edge cases handled: outside workspace, directories, unsynced targets, hidden/ignored symlinks."}
{"id":"CP-bxv","title":"Recursive discovery should wait for sync initial push to complete","description":"When starting in recursive mode, the orchestrator waits 3 seconds for sync to push initial content. But sync can take 1-2 minutes to push all content depending on the workspace size.\n\nCurrent behavior:\n1. Orchestrator starts server + sync\n2. Waits 3 seconds\n3. Runs discovery - may find empty processes.json files\n4. Re-discovery runs every 30 seconds but doesn't re-try failed processes.json\n\nProblems:\n1. Discovery runs before sync has pushed all content\n2. Failed processes.json files (empty at initial parse) are never retried\n3. Only schema changes trigger re-discovery, not file content changes\n\nSuggested fix:\n1. Sync should signal when initial push is complete (via exit, or a 'ready' state)\n2. Orchestrator should wait for this signal before starting discovery\n3. Discovery should re-try any processes.json that failed to parse after content changes\n\nWorkaround: Increase the wait time from 3 seconds to something larger.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T18:05:09.767910488Z","created_by":"jes","updated_at":"2026-01-04T00:32:13.192569475Z","closed_at":"2026-01-04T00:32:13.192569475Z","close_reason":"Implemented polling-based wait for sync initial push instead of fixed 10s timeout"}
{"id":"CP-byr","title":"Add CLI to view/replay edits for a file","description":"Summary: Provide a command-line tool that can list and replay edits for a synced file using its commit history.\n\nFiles to modify:\n- src/bin (new binary, e.g., src/bin/commonplace-replay.rs)\n- src/replay.rs (expose helpers to stream commits and/or content at commits)\n- docs/DEVELOPMENT.md or README.md (document usage)\n\nImplementation steps:\n1. Accept a file path or UUID and resolve to a document ID.\n2. Fetch commit history and print a summary list (cid, timestamp, author, message).\n3. Add a replay mode that reconstructs content at each commit and streams diffs or full content.\n4. Add `--json` output option for both list and replay modes.\n\nExample:\ncommonplace-replay workspace/text-to-telegram/input.txt --list\ncommonplace-replay workspace/text-to-telegram/input.txt --replay --to /tmp/replay.txt\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T06:51:30.897030745Z","created_by":"jes","updated_at":"2026-01-03T08:05:11.809992855Z","closed_at":"2026-01-03T08:05:11.809992855Z","close_reason":"Implemented commonplace-replay CLI to view commit history and content at any commit for synced files."}
{"id":"CP-c1b","title":"Fix P1: Start sync tasks for newly created local files (PR #4)","description":"From PR #4 Codex review: In directory mode, create/modify events only trigger a schema update but don't start sync tasks for the new files.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:21.87906-08:00","updated_at":"2025-12-26T23:43:55.607923-08:00","closed_at":"2025-12-26T23:43:55.607923-08:00","close_reason":"Already fixed and merged to main. The DirEvent::Created handler in directory_watcher_task (sync.rs lines 805-828) now calls spawn_file_sync_tasks for newly created local files."}
{"id":"CP-c1j","title":"Cross-fs-root linking via commonplace-link","description":"Enable commonplace-link to assign shared UUIDs across different fs-roots. This allows files in separate sync sandboxes to share content through the server.\n\nUse case: text-to-telegram and bartleby run in separate sandboxes. We need text-to-telegram/content.txt to sync with workspace/telegram/content.txt by sharing the same UUID.\n\nApproach: \n1. Create a 'linking workspace' that can reference files from multiple fs-roots\n2. Use commonplace-link within the linking workspace to assign shared UUIDs\n3. Individual sandbox syncs respect UUIDs assigned externally\n\nSee docs/SANDBOX_LINKING.md for full architecture.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-01T04:54:08.973778925Z","created_by":"jes","updated_at":"2026-01-01T04:59:07.233301299Z","closed_at":"2026-01-01T04:59:07.233301299Z","close_reason":"Not needed - single workspace tree with subdirectories solves the problem. See docs/SANDBOX_LINKING.md"}
{"id":"CP-c6v","title":"Orchestrator should dynamically start/stop processes as processes.json changes","description":"Summary: Orchestrator should start new processes and stop removed ones when processes.json files change, without requiring a restart.\n\nFiles to modify:\n- src/orchestrator (process discovery and reload handling)\n- src/orchestrator/discovery.rs (detect add/remove diffs)\n- docs/DEVELOPMENT.md or README.md (document live reload behavior)\n\nImplementation steps:\n1. Detect changes in processes.json and compute added/removed process entries.\n2. Start newly added processes automatically.\n3. Stop processes that were removed from the config.\n4. Log actions clearly and avoid flapping on transient edits.\n\nExample:\n- Add entry to processes.json → orchestrator spawns new process.\n- Remove entry → orchestrator terminates process.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T18:15:52.050521881Z","created_by":"jes","updated_at":"2026-01-03T18:39:49.017746667Z","closed_at":"2026-01-03T18:39:49.017746667Z","close_reason":"Implemented dynamic process start/stop. SSE now watches processes.json files for content changes. When a processes.json is edited, the orchestrator immediately fetches and reconciles to start new processes or stop removed ones."}
{"id":"CP-c7h","title":"Podman for untrusted sandbox","description":"Use Podman containers for sandboxed execution of untrusted code. Provides stronger isolation than temp directory sandbox for running arbitrary user-provided commands.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-30T19:39:21.869408178Z","created_by":"jes","updated_at":"2025-12-30T19:39:21.869408178Z","labels":["future-work"]}
{"id":"CP-c8y6","title":"Add --follow and --reverse flags to commonplace-log","description":"Add two new flags:\n- --reverse: Show commits oldest-first instead of newest-first\n- --follow: Watch for new commits via SSE and output them as they arrive (implies --reverse)\n\n--follow will subscribe to the document's SSE stream and print new commits as they happen.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T21:41:03.193815251Z","created_by":"jes","updated_at":"2026-01-03T21:44:14.35592669Z","closed_at":"2026-01-03T21:44:14.35592669Z","close_reason":"Implemented --reverse for oldest-first ordering and --follow (-f) for watching new commits via SSE"}
{"id":"CP-ce1","title":"Implement .processes.json discovery for conductor","description":"Conductor discovers .processes.json files in the document tree and automatically launches/manages declared processes. Enables user-defined processes to attach to file paths without central configuration.\n\nSee: docs/plans/2025-12-30-processes-json-design.md\n\nTasks:\n- Parse .processes.json format (command, owns, cwd)\n- Watch document tree for .processes.json changes\n- Launch processes with COMMONPLACE_PATH and COMMONPLACE_MQTT env vars\n- Restart with exponential backoff on failure\n- Handle conflicts (warn if two processes claim same path)\n- Update counter example to use this convention","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T04:17:59.60264365Z","created_by":"jes","updated_at":"2025-12-30T04:56:47.832163772Z","closed_at":"2025-12-30T04:56:47.832163772Z","close_reason":"Implemented .processes.json discovery for conductor. Created discovery.rs with config parsing and process manager. Updated counter example to use env vars. PR #35 merged."}
{"id":"CP-ceq","title":"Test that new files created in sandbox get synced as new documents","description":"When a sandboxed process creates a new file that doesn't exist in the schema, the sync should:\n1. Detect the new file\n2. Create a new document on the server with a new UUID\n3. Add the file to the local schema\n4. Push the updated schema to the server\n\nNeed integration tests to verify this works correctly in sandbox mode.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-01T19:25:43.482719737Z","created_by":"jes","updated_at":"2026-01-03T07:16:33.1481434Z","closed_at":"2026-01-03T07:16:33.1481434Z","close_reason":"Verified in acceptance testing session (2026-01-03) - sandbox file creation syncs correctly with new UUIDs"}
{"id":"CP-cgi","title":"Fix P1: Use JSON replay when pushing Y.Map schema updates (PR #6)","description":"From PR #6 Codex review: The change switches the initial fs-root schema write to a Y.Map update but needs to use JSON replay instead for proper handling.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:21.54461-08:00","updated_at":"2025-12-26T23:39:41.921295-08:00","closed_at":"2025-12-26T23:39:41.921295-08:00","close_reason":"Already fixed in PR #7 (CP-8fz: Fix server replay to use node's content type). The replay.rs now handles ContentType::Json by initializing a map root and serializing via map.to_json(). Merged to main."}
{"id":"CP-ckq","title":"CRDT merge fails for concurrent edits from linked files","description":"When two files are linked to the same server document (via shared node_id), concurrent edits from both syncs produce incorrect merges.\n\n**Reproduction:**\n1. Set up file linking: content.txt ↔ prompts.txt (same node_id)\n2. Write 'test message' to content.txt\n3. Wait for sync to propagate to prompts.txt\n4. Clear BOTH files simultaneously\n5. Observe: server HEAD still has content, files get content restored\n\n**Expected:** Server HEAD should be empty, files should stay empty\n\n**Actual:** Server HEAD shows 15 bytes after both syncs uploaded 'delete 15 chars'\n\n**Log evidence:**\n- Uploaded: 0 chars inserted, 15 deleted (cid: bb01f73e)\n- Uploaded: 0 chars inserted, 15 deleted (cid: 502649a6)  \n- Wrote server content: 15 bytes at 502649a6\n\n**Root cause analysis:**\nThe sync protocol wasn't designed for multiple sync clients connected to the same document. Each sync maintains its own last_written_cid and parent tracking. When both upload with the same parent:\n1. First upload creates commit A (parent P)\n2. Second upload creates commit B (parent P, but HEAD is now A)\n3. Server enters merge path for B\n4. Merge computation produces wrong result\n\nThis is likely related to CP-f20 (race condition fix) but is a deeper issue with how CRDT updates are computed and applied in the merge path.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T09:36:52.554169483Z","created_by":"jes","updated_at":"2026-01-01T10:12:15.57286668Z","closed_at":"2026-01-01T10:12:15.57286668Z","close_reason":"Fixed in PR #72. Text diffs now use server's actual Yjs state via get_yjs_state() + compute_diff_update_with_base().","comments":[{"id":9,"issue_id":"CP-ckq","author":"jes","text":"## Root Cause Identified (Debug Session 2026-01-01)\n\nThrough debug logging, identified the actual root cause:\n\n### The Bug\nIn src/diff.rs, compute_diff_update creates a **fresh YDoc** with hardcoded client IDs:\n- base_doc = Doc::with_client_id(1)\n- target_doc = Doc::with_client_id(2)\n\n### Why This Fails\n1. Text diffs for the fast path use compute_diff_update(\u0026doc.content, new_content)\n2. This creates updates referencing character positions using client IDs 1 and 2\n3. The server's actual YDoc has characters inserted by **different** client IDs\n4. Yjs uses (client_id, clock) pairs to identify characters\n5. When the update tries to delete, it can't find matching characters\n6. **Result:** Delete operations become no-ops\n\n### Evidence from Logs\nAPPLY: doc content BEFORE update = 'test message' (13 bytes)\nAPPLY: doc content AFTER update = 'test message' (13 bytes)\nThe delete was applied but content didn't change!\n\n### The Fix\nText types need to use the server's actual Yjs state, like JSON types already do.\n\nChange in src/services/document.rs lines 635 and 651:\nFROM: diff::compute_diff_update(\u0026doc.content, new_content)\nTO: Use get_yjs_state(id) + compute_diff_update_with_base()","created_at":"2026-01-01T09:59:53Z"}]}
{"id":"CP-ckt","title":"Fix P1: URL-encode derived node IDs for nested files (PR #4)","description":"From PR #4 Codex review: When syncing directories, file.relative_path will include / characters which need to be URL-encoded for node IDs.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:22.662002-08:00","updated_at":"2025-12-26T23:42:34.654703-08:00","closed_at":"2025-12-26T23:42:34.654703-08:00","close_reason":"Already fixed in PR #4 (043d0c2). The encode_node_id function was added to URL-encode node IDs containing slashes. All node ID usages in sync.rs now use this function. Merged to main."}
{"id":"CP-cofe","title":"P2: log.rs diff algorithm ignores duplicate lines","description":"In log.rs around lines 504-552, the set-based diff algorithm treats duplicate lines as identical, potentially producing incorrect diffs when the same line appears multiple times in different positions.\n\nLocation: src/bin/log.rs:504-552\nFound by: codex review","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T09:10:00.576583994Z","created_by":"jes","updated_at":"2026-01-06T01:11:16.67287576Z","closed_at":"2026-01-06T01:11:16.67287576Z","close_reason":"Replaced HashSet-based diff with similar crate's TextDiff::from_lines for proper duplicate line handling"}
{"id":"CP-cr47","title":"New inode not tracked when commit_id is None","description":"In sse.rs:860-863, when head.cid is None (empty document), the new inode is never tracked:\n\n```rust\nif let Some(cid) = commit_id {\n    tracker.track(new_key, cid, file_path.clone());\n}\n```\n\nImpact: Subsequent atomic writes to this file won't create shadow hardlinks because the inode isn't in the tracker.\n\nOptions:\n1. Track with empty string as commit_id\n2. Track with a sentinel value like 'genesis'\n3. Document this as intentional (no shadow needed for empty docs?)\n\nRelated: CP-txg0 review","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-05T08:57:30.50056508Z","created_by":"jes","updated_at":"2026-01-06T01:22:42.432022866Z","closed_at":"2026-01-06T01:22:42.432022866Z","close_reason":"Track with empty string commit_id for genesis documents"}
{"id":"CP-cv9","title":"Validate at_commit CID belongs to requested document (P2 from codex review)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T06:23:26.603794724Z","created_by":"jes","updated_at":"2025-12-30T23:01:36.990246638Z","closed_at":"2025-12-30T23:01:36.990246638Z","close_reason":"Validated at_commit CID in get_head, fork_document, and replace_content. PR #52 merged.","labels":["api","security"],"comments":[{"id":2,"issue_id":"CP-cv9","author":"jes","text":"From codex review on PR #36 (src/api.rs:410):\n\nThe ?at_commit path replays commits solely by CID without verifying that the CID is part of the requested document's history. CommitReplayer::get_content_and_state_at_commit ignores the provided doc id, so a caller who knows a CID from another document can fetch that other document's state through /docs/:id/head?at_commit=... (or get misinterpreted content if content types differ).\n\nFix: Check that target_cid is reachable from the document head before replaying.","created_at":"2025-12-30T06:23:35Z"}]}
{"id":"CP-cxj","title":"Sync tool skips files with unknown extensions","description":"Ensure sync tool skips files with extensions it doesn't understand rather than failing or corrupting them.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T17:54:27.688193893Z","created_by":"jes","updated_at":"2025-12-30T18:09:02.091283573Z","closed_at":"2025-12-30T18:09:02.091283573Z","close_reason":"Already implemented - is_allowed_extension() function filters files by ALLOWED_EXTENSIONS constant, used in directory scanning and file event handlers"}
{"id":"CP-da9","title":"commonplace-ps showing stale/incorrect PIDs","description":"commonplace-ps displays PIDs that don't correspond to actual running processes.\n\nExample:\n```\njes@commonplace:~/commonplace/workspace/bartleby$ ../../target/release/commonplace-ps\nOrchestrator PID: 229603 (started at 2026-01-03 11:46:59)\n\nNAME                      PID STATE      CWD\n--------------------------------------------------------------------------------\nbartleby               230639 Running    -\nfile-tmux-file         229612 Running    -\ntext-to-telegram       793203 Running    -\n\njes@commonplace:~/commonplace/workspace/bartleby$ ps 792682\n    PID TTY      STAT   TIME COMMAND\n```\n\nThe PIDs shown don't match actual running processes. The orchestrator status file may be out of sync with reality, or PIDs are being read/stored incorrectly.","notes":"Additional issue: commonplace-ps should indicate when a process is rapidly restarting (crash loop). Currently it just shows 'Running' with stale PIDs, hiding the fact that the process is unstable.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T11:47:30.802260724Z","created_by":"jes","updated_at":"2026-01-03T12:23:55.78355672Z","closed_at":"2026-01-03T12:23:55.78355672Z","close_reason":"commonplace-ps now validates PIDs and shows Dead state for non-running processes"}
{"id":"CP-daj","title":"New files created after sync starts aren't added to schema - blocks acceptance","description":"When creating new files in the workspace while sync is running, the files aren't being added to the .commonplace.json schema and aren't synced to the server.\n\nTest case:\n1. Start server, sync, orchestrator\n2. Wait for initial sync to complete\n3. Create a new file: echo 'test' \u003e workspace/root-test-file.txt\n4. Wait 30 seconds\n5. Check workspace/.commonplace.json - new file not listed\n6. Check server schema - new file not present\n\nExpected: New files should be detected by file watcher, added to schema, and synced to server.\nActual: Files exist on disk but are never added to schema.\n\nNote: Files that existed before sync started ARE synced correctly. The bug affects only files created AFTER sync is running.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T08:22:05.305521305Z","created_by":"jes","updated_at":"2026-01-02T09:17:14.732591508Z","closed_at":"2026-01-02T09:17:14.732591508Z","close_reason":"Fixed. Two issues were causing new files to not be detected: 1) Path mismatch between absolute watcher paths and relative directory paths - fixed by canonicalizing both paths before strip_prefix. 2) Event debounce overwriting Created with Modified - fixed by preserving Created events in the debounce HashMap."}
{"id":"CP-dgu","title":"Sync tool: persist state locally for offline change detection","description":"The sync tool currently has no local state persistence. On restart, it fetches HEAD from the server and may overwrite local changes made while sync was stopped.\n\n## Current Behavior\n- SyncState is purely in-memory (last_written_cid, last_written_content)\n- On startup, fetches server HEAD and writes to local file\n- --initial-sync flag offers limited control (skip/local/server) but no conflict detection\n- Local changes made while offline could be silently lost\n\n## Proposed Solution\nPersist sync state to a local file (e.g., .commonplace-sync.json or alongside each synced file):\n- Last synced CID\n- Last synced content hash\n- Timestamp of last sync\n\nOn restart:\n1. Load persisted state\n2. Compare local file hash to persisted hash → detect local modifications\n3. Fetch server HEAD → detect server modifications  \n4. If both modified: conflict (prompt user or use strategy flag)\n5. If only local modified: push to server\n6. If only server modified: pull to local\n7. If neither modified: resume normal sync\n\n## Files to modify\n- src/bin/sync.rs - Add state persistence and conflict detection\n- Possibly src/sync/ modules for shared types","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T05:08:27.003489287Z","created_by":"jes","updated_at":"2025-12-30T06:26:58.408628459Z","closed_at":"2025-12-30T06:26:58.408628459Z","close_reason":"Implemented sync state persistence. PR #36 merged. State file tracks last_synced_cid and file hashes. Detects offline changes on restart. CRDT merge logic deferred to follow-up.","comments":[{"id":1,"issue_id":"CP-dgu","author":"jes","text":"Design complete: docs/plans/2025-01-02-sync-state-persistence-design.md\n\nKey design decisions:\n- State file: .{basename}.commonplace-sync.json beside synced target (not inside)\n- Uses CRDT merge instead of manual conflict resolution\n- Stores last_synced_cid + file hashes, not content\n\nBLOCKING: Need to add ?at_commit query param to /head endpoint first (infrastructure exists via CommitReplayer, just not exposed)","created_at":"2025-12-30T05:45:25Z"}]}
{"id":"CP-dlu","title":"commonplace-ps not showing CWD of processes","description":"commonplace-ps shows '-' for all process CWDs instead of actual working directories.\n\nExample output:\n```\nNAME                      PID STATE      CWD                                     \n--------------------------------------------------------------------------------\nbartleby               230639 Running    -                                       \nfile-tmux-file         229612 Running    -                                       \ntext-to-telegram       775886 Running    -\n```\n\nExpected: Should show the actual working directory (sandbox temp dir or configured cwd) for each process.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T11:41:18.810220474Z","created_by":"jes","updated_at":"2026-01-03T12:23:54.790461891Z","closed_at":"2026-01-03T12:23:54.790461891Z","close_reason":"CWD now read from /proc/\u003cpid\u003e/cwd for processes without explicit cwd config"}
{"id":"CP-dnc","title":"Make sync robust when a process uses atomic-writes to edit a file","description":"The file watcher in src/sync/watcher.rs uses is_modify() to detect file changes. While this should catch rename events (since Modify(Name(To)) is a Modify variant), there are potential edge cases:\n\n1. Directory watcher (lines 179-209) explicitly handles rename modes - robust\n2. File watcher (lines 70-86) only checks is_modify() - less explicit\n\nInvestigate:\n- What happens if editor does delete+create instead of atomic rename?\n- Platform-specific inotify behavior (path vs inode watching)\n- Does watcher need to re-attach after file replacement?\n\nConsider:\n- Add explicit rename handling to file_watcher_task\n- Add integration tests with atomic write patterns\n- Test with vim, emacs, VSCode atomic saves","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-31T22:52:32.17908978Z","created_by":"jes","updated_at":"2025-12-31T23:04:38.726997837Z","closed_at":"2025-12-31T23:04:38.726997837Z","close_reason":"Watches parent directory for atomic writes, explicit rename handling, 4 integration tests"}
{"id":"CP-dpi7","title":"commonplace-ps shows parent CWD instead of sandbox CWD","description":"Summary: commonplace-ps reports the orchestrator's working directory for sandboxed processes; it should report the sandbox temp directory (e.g., /tmp/commonplace-sandbox-...).\n\nExample:\n$ commonplace ps\nOrchestrator PID: 1253246 (started at 2026-01-04 01:01:18)\n\nNAME                      PID STATE      CWD\n--------------------------------------------------------------------------------\nbartleby              1253324 Running    /home/jes/commonplace\nfile-tmux-file        1253325 Running    /home/jes/commonplace\nserver                1253251 Running    /home/jes/commonplace\nsync                  1253278 Running    /home/jes/commonplace\ntext-to-telegram      1253329 Running    /home/jes/commonplace\n\nExpected: sandboxed processes should show their sandbox temp directory (e.g., /tmp/commonplace-sandbox-...).\n\nFiles to modify:\n- src/orchestrator/manager.rs and/or src/orchestrator/discovered_manager.rs (CWD resolution)\n- src/bin/ps.rs (display logic if needed)\n\nImplementation steps:\n1. When process is sandboxed (commonplace-sync --sandbox), resolve CWD from the child/grandchild process that owns the sandbox.\n2. Prefer /proc/\u003cpid\u003e/cwd of the innermost sandboxed process rather than the orchestrator parent.\n3. Add a test or fixture to validate sandbox CWD reporting.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-04T09:28:17.618969624Z","created_by":"jes","updated_at":"2026-01-04T09:45:40.553451454Z","closed_at":"2026-01-04T09:45:40.553451454Z","close_reason":"Closed"}
{"id":"CP-dscp","title":"XML should use Yjs XmlFragment, not Text (replace/diff support)","description":"Summary: XML documents should be first-class via Yjs XmlFragment; the current workaround (CP-80z2) demotes XML to Text, which loses element-level CRDT semantics (structural merges/attributes). The diff/replace logic must handle XmlFragment correctly so XML gets proper collaborative editing.\\n\\nFiles to modify:\\n- src/sync/diff.rs (or XML/Yjs diff/replace module)\\n- src/sync/file_sync.rs\\n- src/tmux (XML document handling)\\n- tests (XML element-level merge coverage)\\n\\nImplementation steps:\\n1. Locate the workaround that converts XML docs to Text (CP-80z2) and identify the missing XmlFragment support path.\\n2. Implement diff/replace handling for Yjs XmlFragment, preserving element boundaries/attributes and structural edits.\\n3. Plumb XmlFragment through file-tmux-file without type coercion.\\n4. Ensure serialize/deserialize roundtrips maintain XML structure and CRDT ops.\\n5. Add regression tests that perform element-level edits and verify merges remain structural.\\n\\nExample:\\nBefore: \u003cp\u003e\u003cb\u003ehi\u003c/b\u003e\u003c/p\u003e becomes flat text; element merges are lost.\\nAfter: XmlFragment preserves \u003cb\u003e node operations and merges structurally.\\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T18:41:06.869049706Z","created_by":"jes","updated_at":"2026-01-07T19:21:07.594744668Z","closed_at":"2026-01-07T19:21:07.594744668Z","close_reason":"Implemented XmlFragment support in diff.rs with compute_xml_diff_update(). XML documents now use XmlFragment internally and the diff/replace operations generate proper XmlFragment updates instead of Text updates."}
{"id":"CP-dt3","title":"[blocks acceptance] File deletion doesn't propagate to sandboxes","description":"When a file is deleted from the workspace, the deletion doesn't propagate to sandbox sync clients.\n\nTest case:\n1. Create file in workspace/text-to-telegram/test-file.txt\n2. Verify file appears in sandbox (works)\n3. Delete workspace/text-to-telegram/test-file.txt\n4. Wait 5 seconds\n5. File still exists in sandbox (should be deleted)\n\nThe sync likely needs to handle schema removals and trigger file deletion in the synced directories.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T09:44:34.285517457Z","created_by":"jes","updated_at":"2026-01-02T10:01:03.072528079Z","closed_at":"2026-01-02T10:01:03.072528079Z","close_reason":"Fixed. Two issues: (1) handle_file_deleted was always pushing to fs_root_id - fixed to use find_owning_document to get correct owning document. (2) handle_schema_change wasn't handling deletions - added code to detect files in known_paths but not in schema_paths and delete the local files, stopping their sync tasks. Verified D1-D4 acceptance tests now pass."}
{"id":"CP-du5","title":"Sandbox path config inverted - blocks acceptance","description":"The processes.json files are in wrong locations, causing sandbox paths to be inverted from acceptance criteria:\n\nCurrent:\n- workspace/processes.json has text-to-telegram → gets full workspace (wrong)\n- workspace/bartleby/processes.json has bartleby → gets only bartleby/ (wrong)\n\nExpected (per docs/plans/2026-01-02-sandbox-sync-acceptance-criteria.md):\n- Bartleby should have full workspace tree → config at workspace/processes.json\n- Text-to-telegram should only have its subdir → config at workspace/text-to-telegram/processes.json\n\nFix: Swap the config locations.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T06:07:22.908171066Z","created_by":"jes","updated_at":"2026-01-02T08:14:16.959288554Z","closed_at":"2026-01-02T08:14:16.959288554Z","close_reason":"Fixed - processes.json in correct locations"}
{"id":"CP-dv7","title":"Directory sync enters feedback loop writing schemas repeatedly","description":"When running commonplace-sync --directory, the sync enters a feedback loop writing schemas repeatedly.\n\n**Root Cause Analysis:**\nThe semantic JSON comparison fix (PR #80) wasn't sufficient. The loop continues because:\n1. SSE events trigger handle_schema_change() which calls write_nested_schemas()\n2. write_nested_schemas() fetches and writes subdirectory schemas\n3. Even with deduplication, the content may differ due to:\n   - CRDT evolution in Yjs documents\n   - Different key ordering in JSON serialization\n   - scan_directory() producing different output than server content\n\n**Additional fixes needed:**\n1. Add deduplication to write_nested_schemas_recursive()\n2. Consider debouncing SSE events\n3. Or prevent the file watcher from triggering on schema files entirely\n4. Compare normalized schemas (sorted keys, consistent formatting)","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T22:07:42.612446584Z","created_by":"jes","updated_at":"2026-01-02T00:15:29.878363029Z","closed_at":"2026-01-02T00:15:29.878363029Z","close_reason":"Closed"}
{"id":"CP-e3h","title":"Sync doesn't push local file edits to server","description":"When editing files in a synced directory, changes are not being pushed to the server.\n\nTest case:\n1. Start sync with: commonplace-sync --server http://localhost:3000 --directory ./workspace --path \"\"\n2. Edit a file in workspace/bartleby/processes.json\n3. Wait for sync\n4. Check server content - unchanged\n\nExpected: Local edits should be detected by file watcher and pushed to server.\nActual: Server content remains unchanged after local edit.\n\nThe sync process is running and watching the directory, but edits aren't triggering pushes. This may be related to subdirectory schemas with node_id (node-backed directories) not properly watching nested files.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T04:49:53.510418943Z","created_by":"jes","updated_at":"2026-01-02T07:48:20.848924736Z","closed_at":"2026-01-02T07:48:20.848924736Z","close_reason":"Works as expected. Testing confirmed: 1) Directory mode file edits sync correctly to server, 2) Sandbox mode file edits sync correctly to server. The UUID resolution improvements from CP-ee1 fix (migrate_subdirectory_document) ensured files in node-backed subdirectories get correct UUIDs, enabling per-file watchers to push edits to the correct server document."}
{"id":"CP-e3jr","title":"Remove support for inline subdirectories","description":"Inline subdirectories are deprecated. migrate_inline_subdirectories() in reconciler.rs handles migration to node-backed style. Once all schemas are migrated, remove:\n\n1. Inline subdirectory parsing/handling code\n2. The migration code itself (or keep for safety)\n3. Any fallback paths that still check for inline entries\n\nFiles to audit:\n- src/fs/reconciler.rs (migration code)\n- src/path.rs (inline handling)\n- src/files.rs (entries.is_null checks)\n- src/sync/uuid_map.rs (inline entry handling)","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-06T00:55:16.282048143Z","created_by":"jes","updated_at":"2026-01-08T18:36:06.571193856Z","closed_at":"2026-01-08T18:36:06.571193856Z","close_reason":"Removed inline subdirectory support. All directories must now be node-backed. Root entries still traversed correctly.","labels":["future-work"]}
{"id":"CP-e3km","title":"Red broadcasts should use gold ordering metadata","description":"Summary: Route red-port broadcasts through the gold event-ordering mechanism so subscribers can deterministically order red events across transports.\n\nFiles to modify:\n- src/ws/protocol.rs\n- src/ws/room.rs\n- src/mqtt/events.rs\n- docs/ARCHITECTURE.md\n\nImplementation steps:\n1. Define the gold ordering token/sequence for red events (e.g., monotonic sequence or gold CID) once gold infra is available.\n2. Extend red event envelopes to include the ordering field for both WebSocket and MQTT paths.\n3. Update broadcast paths to mint/attach the ordering token at publish time.\n4. Update any red-event consumers to surface the ordering metadata and document the semantics.\n5. Add tests that emit multiple red events and assert ordering metadata increases/links correctly.\n\nExample:\nBefore: red event payload is unordered; clients may see events in different orders.\nAfter: red events include `order: \u003cgold_seq\u003e` so clients can sort consistently.\n","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-06T01:50:48.734309682Z","created_by":"jes","updated_at":"2026-01-06T01:50:48.734309682Z","dependencies":[{"issue_id":"CP-e3km","depends_on_id":"CP-g99w","type":"blocks","created_at":"2026-01-06T01:50:48.738801222Z","created_by":"jes"}]}
{"id":"CP-ebk","title":"Directory sync uses wrong /files path for node-backed subdirs","description":"Summary: In directory sync with --use-paths, new files in node-backed subdirectories are pushed to /files/\u003cbasename\u003e instead of /files/\u003csubdir\u003e/\u003cbasename\u003e, causing 404s and wrong SSE subscriptions.\n\nEvidence:\n- Creating workspace/bartleby/bingo.jsonl attempts /files/bingo.jsonl (404) while /files/bartleby/bingo.jsonl exists.\n- Logs show: 'Identifier bingo.jsonl not found, waiting for reconciler' and SSE connects to /sse/files/bingo.jsonl.\n\nFiles to modify:\n- src/sync/dir_sync.rs (handle_file_created identifier selection)\n\nImplementation steps:\n1. In handle_file_created, when use_paths=true, set identifier to full fs-root relative path (relative_path), not owning_doc.relative_path.\n2. Ensure SSE and upload targets use the same full path.\n3. Add a regression test: create file in node-backed subdir with --use-paths, verify requests go to /files/subdir/file.\n\nExample:\nBefore: workspace/bartleby/bingo.jsonl -\u003e /files/bingo.jsonl (404)\nAfter: workspace/bartleby/bingo.jsonl -\u003e /files/bartleby/bingo.jsonl","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T00:30:42.278407464Z","created_by":"jes","updated_at":"2026-01-03T00:34:51.774580189Z","closed_at":"2026-01-03T00:34:51.774580189Z","close_reason":"Fixed identifier to use full fs-root relative path when --use-paths is enabled"}
{"id":"CP-ee1","title":"File creation in node-backed subdirs not synced - blocks C1-C6 acceptance","description":"When creating a file in a node-backed subdirectory (e.g., workspace/text-to-telegram/test-file.txt), the sync client fails to propagate the file to the server.\n\nRoot cause: handle_file_created pushes the schema to fs_root_id (parent document), but the file belongs to the subdirectory's own schema document.\n\nExpected behavior: When file is created in path under a node-backed directory, push schema update to that subdirectory's document.\n\nCurrent behavior: Schema pushed to root document, subdirectory's schema unchanged, file never synced.\n\nBlocks acceptance criteria C1-C6.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T06:39:29.364037755Z","created_by":"jes","updated_at":"2026-01-02T07:41:39.756898109Z","closed_at":"2026-01-02T07:41:39.756898109Z","close_reason":"Fixed by: 1) Adding migrate_subdirectory_document() method that generates UUIDs for entries in node-backed subdirectory schemas; 2) Using last_valid_node_schemas cache to preserve previously generated UUIDs across multiple schema pushes; 3) Merging existing UUIDs before migration to prevent race conditions."}
{"id":"CP-ef0e","title":"Add MQTT topic for ancestry check","description":"HTTP has GET /docs/:id/is-ancestor to check if one commit is an ancestor of another. No MQTT equivalent.\n\nAdd to sync protocol as a new message type:\n- Request: {type: 'is_ancestor', req: '...', commit: '...', ancestor: '...'}\n- Response: {type: 'is_ancestor_response', req: '...', result: true/false}","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:22.078305825Z","created_by":"jes","updated_at":"2026-01-09T07:05:22.078305825Z"}
{"id":"CP-egb","title":"Sandboxed JS evaluator with document subscriptions and output","description":"Run a JS file in a sandbox with the ability to:\n- Declare dependencies on other commonplace documents\n- Subscribe to commits on those dependencies\n- Create a read-only output document\n- Listen for commands on the output document's path\n- Emit events as that document\n\nThe JS file acts as a reactive transform: inputs → computation → output document.","design":"Plan (v1)\n\nGoal\n- Run a JS file as a reactive transform: subscribe to dependency documents (read-only), own output document(s) (write), receive commands on the output path, and emit events.\n\nContext / Existing Docs\n- MQTT topic model and ports: docs/MQTT.md\n- External-process participation via MQTT: examples/python-client/README.md\n- MQTT auth direction (future): docs/MACAROONS.md (CP-adm)\n\nArchitecture\n- The evaluator is an external process that connects to the MQTT broker with a stable client_id.\n- For each dependency path:\n  - Subscribe to `{path}/edits`.\n  - Use `{path}/sync/{client_id}` to catch up (head + ancestors/pull) and reconstruct state.\n  - Maintain a local Yjs doc for the dependency so the script sees converged content.\n- For each owned output path:\n  - Subscribe to `{path}/commands/#`.\n  - Publish edits to `{path}/edits` (with parent commit context) and publish events to `{path}/events/\u003cname\u003e`.\n\nRuntime Choice\n- Preferred v1: Deno-based runner (permissions + TS path later).\n- Fallback v1: Node-based runner.\n- Future v2: embed a JS runtime in Rust (deno_core or quickjs) to avoid external runtime dependency.\n\nScript API (initial)\n- `cp.doc(path, { type })` returns a handle with:\n  - `get()` → current content (string for text, object/array for JSON)\n  - `set(value, { message })` → publish update\n  - `onChange(cb)` → callback on new converged content\n- `cp.onCommand(verb, handler)` registers a handler for `{output}/commands/{verb}`.\n- `cp.emit(event, payload)` publishes to `{output}/events/{event}`.\n\nConfiguration\n- Sidecar manifest next to script (v1): `\u003cscript\u003e.commonplace.json` describing:\n  - `deps`: list of doc paths + content types\n  - `outputs`: list of owned doc paths + content types\n  - `commands`: allowed verbs\n  - broker/server settings + client_id\n- Future: allow the manifest to live in a commonplace doc.\n\nOrchestrator Integration\n- Run via `processes.json` using `sandbox-exec`, so orchestrator launches:\n  - `commonplace-sync --sandbox --exec \"\u003crunner\u003e \u003cscript\u003e\"`\n- This gives a temp working directory with synced files and reduces accidental access to the host checkout.\n\nSandbox / Resource Limits\n- Deno runner flags (target shape): `--no-prompt`, narrow `--allow-net` to broker, allow only required env vars, deny subprocess.\n- Future: Podman-based isolation (CP-c7h) for stronger untrusted-code boundaries.\n\nMilestones\n1. Minimal runner: 1 dependency (text), 1 output (text), subscribe + publish edits.\n2. Add commands and events plumbing (magenta/red ports).\n3. Add JSON support using Y.Map/Y.Array semantics.\n4. Add manifest parsing and multi-dep/multi-output wiring.\n5. Observability: log per-doc head/last-applied CID and last command/event.\n6. Add an example transform + regression test harness.\n\nOpen Questions\n- Choose v1 runtime (Deno vs Node) based on deploy constraints.\n- Decide whether output ownership is enforced (deny non-owner publishes) or convention-only.","status":"in_progress","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.433243-08:00","updated_at":"2026-01-06T02:59:51.780206128Z","labels":["future-work"],"dependencies":[{"issue_id":"CP-egb","depends_on_id":"CP-nno","type":"blocks","created_at":"2025-12-28T22:50:33.552787-08:00","created_by":"daemon"}]}
{"id":"CP-eiyx","title":"Add MQTT wildcard subscriptions for directory trees","description":"**This is the key gap that blocks CP-o7h0 (sync refactor to MQTT).**\n\nCurrent MQTT topics are per-file: {workspace}/{path.ext}/{port}\nThe topic parser requires an extension, so you can't subscribe to:\n- workspace/docs/# (all files under docs/)\n- workspace/+/+.txt/edits (all .txt files)\n\nFor sync to use MQTT instead of SSE, we need to watch entire directory trees with one subscription.\n\nOptions:\n1. Change topic structure to support directory wildcards\n2. Add a separate 'schema' port that broadcasts when any file in a subtree changes\n3. Use directory node_ids in topics instead of paths\n\nThis is P1 because it's the architectural blocker for the MQTT sync refactor.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-09T07:05:34.837963327Z","created_by":"jes","updated_at":"2026-01-09T07:05:34.837963327Z"}
{"id":"CP-ejh","title":"Refactor api.rs: Extract document handlers to service layer","description":"api.rs is 918 lines. Extract document CRUD operations into a service layer module (`src/services/document.rs`), separating business logic from HTTP handler concerns.","status":"closed","priority":2,"issue_type":"chore","created_at":"2025-12-30T00:34:51.124071-08:00","updated_at":"2025-12-30T16:17:43.597788755Z","closed_at":"2025-12-30T16:17:43.597788755Z","close_reason":"Closed"}
{"id":"CP-eoy","title":"commonplace-link: support linking anywhere within a checked out file tree","description":"Currently commonplace-link only works for files in the same directory. For use cases like linking bartleby's workspace files to text-to-telegram files, we need cross-directory linking within a synced tree.\n\nProposed behavior:\n- commonplace-link source target (where both are in the same synced workspace tree)\n- Updates both files' schemas to share the same UUID\n- When either file is edited, both sync to the same document\n\nUse case: bartleby/prompts.txt linked to telegram/content.txt so telegram messages become bartleby prompts, and bartleby/output.txt linked to telegram/input.txt so bartleby responses go to telegram.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-31T23:23:03.804284034Z","created_by":"jes","updated_at":"2026-01-01T01:58:24.737984163Z","closed_at":"2026-01-01T01:58:24.737984163Z","close_reason":"Implemented cross-directory linking support. Commit 2c99666."}
{"id":"CP-eyi","title":"Cron-style recurring scheduled events","description":"Fire events on a recurring schedule (like crontab). Use cases:\n- Periodic document refresh triggers\n- Scheduled backup/export jobs\n- Regular polling of external sources\n- Time-based workflow triggers\n\nCould be defined as a special node type or as a configuration on documents.","design":"OPEN QUESTIONS for implementation:\n1. Where are schedules stored - in a special document, node metadata, or separate config?\n2. What format for cron expressions (standard cron or extended)?\n3. What event type is fired on schedule trigger?\n4. How to handle timezone - UTC only or configurable?\n5. Should missed events (server was down) be replayed or skipped?\n6. Is this a separate service or integrated into commonplace-store?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.565001-08:00","updated_at":"2025-12-30T01:44:47.450426047Z","labels":["future-work"]}
{"id":"CP-f20","title":"Bidirectional CRDT sync fails for producer-consumer file patterns","description":"When two files are linked with shared UUIDs for bidirectional sync, deletions on one side get restored instead of propagating.\n\nExample: bartleby appends responses to output.txt, which syncs to text-to-telegram/input.txt. text-to-telegram pops (removes) lines after sending to Telegram. The sync should propagate this deletion back to output.txt, but instead the deleted lines get restored from output.txt.\n\nExpected behavior: Deletion in input.txt → Yjs delete operation → syncs to server → propagates to output.txt (line removed from both)\n\nActual behavior: Deletion in input.txt gets overwritten by sync restoring content from output.txt\n\nPossible causes:\n1. File watcher not detecting text-to-telegram's atomic write (_atomic_write via tempfile rename)\n2. Diff algorithm not generating proper delete operations\n3. Race condition: output.txt re-syncs before input.txt deletion propagates\n4. Sync direction priority issue - maybe 'initial-sync local' affects ongoing sync behavior\n\nImpact: Causes spam loops when using file linking for message passing between applications.","notes":"Theory: SSE server edits are skipped when local content differs from last_written_content, but the sync client only refreshes HEAD when an echo is detected. In producer-consumer, consumer deletes lines → SSE to producer; producer has local pending changes (append or atomic write) so handle_server_edit sets needs_head_refresh and returns. upload_task clears needs_head_refresh when processing the local change but only calls refresh_from_head on echo; on a real local upload it never refreshes. That means the producer uploads its stale content (with deleted lines) and overwrites the deletion. See src/sync/sse.rs:229-292 (skip server edit on local changes sets needs_head_refresh) and src/sync/file_sync.rs:120-210 (needs_head_refresh cleared but only used on echo path). Fix likely: after any successful upload where needs_head_refresh was set, refresh from HEAD (or merge) so server edits aren't lost.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T07:47:10.941526886Z","created_by":"jes","updated_at":"2026-01-01T08:15:49.177770661Z","closed_at":"2026-01-01T08:15:49.177770661Z","close_reason":"Fixed in PR #71. Re-check needs_head_refresh after upload to catch SSE events that arrived during upload."}
{"id":"CP-fd60","title":"Orchestrator should watch commonplace.json and reload on changes","description":"The orchestrator reads commonplace.json at startup but doesn't watch it. Should use inotify/fswatch to detect changes and dynamically add/remove/restart processes. This is the external unix file, distinct from processes.json within workspace.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T06:43:59.281537076Z","created_by":"jes","updated_at":"2026-01-05T08:51:13.610952713Z","closed_at":"2026-01-05T08:51:13.610952713Z","close_reason":"Implemented config file watching with inotify, automatic reload on changes, added stop_process and reload_config methods to ProcessManager"}
{"id":"CP-fr4","title":"UUID-linked files in subdirectories not syncing - blocks acceptance","description":"Files linked via commonplace-link (sharing the same UUID) are not syncing content between each other.\n\nExample:\n- workspace/bartleby/output.txt and workspace/text-to-telegram/input.txt share UUID 12504d60-2b58-43c8-b461-a42215a3954d\n- output.txt contains 'sync test 1767417213'\n- input.txt contains 'hi'\n- They should have identical content but don't converge\n\nThe server shows old content while local files have newer content. The workspace sync appears to not be pushing changes from files in subdirectories that have linked UUIDs.\n\nThis blocks the sandbox linking architecture described in docs/SANDBOX_LINKING.md.","notes":"Evidence in /tmp/sync.log: sync resolved bartleby/output.txt and text-to-telegram/input.txt to derived IDs (no UUID found). Lines 2026-01-03T05:17:39/05:17:41 show 'No UUID found for bartleby/output.txt, using derived ID ...' and 'No UUID found for text-to-telegram/input.txt, using derived ID ...'. This means the link mapping isn't in schema after restart, so files aren't actually linked.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T05:18:16.153599126Z","created_by":"jes","updated_at":"2026-01-03T05:38:15.705702651Z","closed_at":"2026-01-03T05:38:15.705702651Z","close_reason":"Fixed by CP-a31: commonplace-link now pushes schemas to server, sync picks up correct UUIDs, linked files sync correctly."}
{"id":"CP-fs3x","title":"Subdirectory SSE events don't trigger file syncing for remote changes","design":"When files are added/changed in a node-backed subdirectory on the server, the subdir_sse_task receives an edit event but only does cleanup (orphan removal), not file syncing. This was already broken before CP-j4wg (it was using wrong parameters). A dedicated mechanism is needed to pull remote file changes in subdirectories. Options: 1) Add periodic resync for subdirs, 2) Modify handle_schema_change to accept path prefix, 3) Implement dedicated subdir file sync.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T22:21:43.09159333Z","created_by":"jes","updated_at":"2026-01-07T00:15:39.150829137Z","closed_at":"2026-01-07T00:15:39.150829137Z","close_reason":"Added handle_subdir_new_files() to sync NEW files from subdirectory schemas when SSE edit events are received. Fixed locally-deleted directory detection to use root-level synced dirs. Fixed identifier to use path when use_paths=true. Merged in PR #107."}
{"id":"CP-g0c","title":"Sync corrupts .commonplace.json schema - overwrites to {} or {version:1}","description":"When running commonplace-sync with --directory and --node, the local .commonplace.json schema gets corrupted. It starts with a proper schema (version, root, entries with files) but gets repeatedly overwritten to just {} or {\"version\":1}. The fs-root document on the server ends up with content: {} instead of the full schema. This breaks directory sync completely.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T01:49:36.833268107Z","created_by":"jes","updated_at":"2026-01-01T01:54:58.343768111Z","closed_at":"2026-01-01T01:54:58.343768111Z","close_reason":"Fixed by validating schema before writing to local file. Commit 759ddfb."}
{"id":"CP-g3zv","title":"cbd: document usage and intentional bd differences","description":"Summary: Document cbd usage, config discovery, and which bd features are intentionally omitted in JSONL-only mode.\n\nFiles to modify:\n- docs/DEVELOPMENT.md or README.md\n\nImplementation steps:\n1. Add a cbd section with command examples for list/ready/show/create/update/close/dep.\n2. Document config discovery via .cbd.json and .beads/.cbd.json, plus env vars COMMONPLACE_SERVER and CBD_PATH.\n3. Call out intentional differences from bd (no sqlite/daemon flags, no db sync modes) and why.\n4. Add a short JSON output example for list and show.\n\nExample:\ncommonplace-bd --path beads/commonplace-issues.jsonl ready --json\n","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-05T07:02:56.617452765Z","created_by":"jes","updated_at":"2026-01-05T08:42:57.869975828Z","closed_at":"2026-01-05T08:42:57.869975828Z","close_reason":"Added cbd documentation to docs/DEVELOPMENT.md with command examples, config discovery, JSON output, and bd comparison","dependencies":[{"issue_id":"CP-g3zv","depends_on_id":"CP-vyd6","type":"blocks","created_at":"2026-01-05T07:02:56.624024151Z","created_by":"jes"},{"issue_id":"CP-g3zv","depends_on_id":"CP-2gv7","type":"blocks","created_at":"2026-01-05T07:02:56.627915987Z","created_by":"jes"},{"issue_id":"CP-g3zv","depends_on_id":"CP-2ee8","type":"blocks","created_at":"2026-01-05T07:02:56.631383702Z","created_by":"jes"},{"issue_id":"CP-g3zv","depends_on_id":"CP-1j5m","type":"discovered-from","created_at":"2026-01-05T07:02:56.637827079Z","created_by":"jes"}]}
{"id":"CP-g99w","title":"Block-chain like functionality (\"gold\")","description":"Future exploration: Add blockchain-like functionality to commonplace, potentially called \"gold\". Details TBD.","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-05T23:41:42.881279591Z","created_by":"jes","updated_at":"2026-01-05T23:41:42.881279591Z","labels":["future-work"]}
{"id":"CP-g9e8","title":"Add MQTT topic for document deletion","description":"HTTP has DELETE /docs/:id but there's no MQTT equivalent.\n\nAdd a commands topic verb for deletion:\n- Topic: {workspace}/{path}/commands/delete\n- Or add to sync protocol as a new message type\n\nThis allows MQTT clients to delete documents without HTTP.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:03.416287569Z","created_by":"jes","updated_at":"2026-01-09T07:05:03.416287569Z"}
{"id":"CP-gis9","title":"SDK cp.watch does not honor + wildcard","description":"The cp.watch API advertises MQTT + and # wildcards, but the underlying subscribe function only handles exact topics or # prefixes and never matches +. Any watcher registered with a + (e.g., cp.watch(\"workspace/+/edits\", …)) will never fire. Consider expanding the subscribe matching logic to handle single-level + wildcards or drop the claim in the watch API.","status":"closed","priority":3,"issue_type":"bug","created_at":"2026-01-07T20:25:51.760641211Z","created_by":"jes","updated_at":"2026-01-07T20:57:15.210360363Z","closed_at":"2026-01-07T20:57:15.210360363Z","close_reason":"Fixed by adding topicMatches() function that properly handles both + and # MQTT wildcards."}
{"id":"CP-gl6m","title":"Make commonplace-log behave like git log (newest first, show diffs by default)","description":"Summary: Update commonplace-log output to mirror git log behavior.\n\nAlready done:\n- Newest commits first (fixed in CP-92l)\n\nTo implement:\n1. **Pager support**: Pipe output through pager (less/PAGER) for interactive sessions\n2. **Show diffs by default**: Like git log -p, show content changes between commits\n3. **--no-patch/-s**: Flag to suppress diff output (summary only)\n4. **Colorized output**: Commit IDs, dates, diff hunks\n\nFiles to modify:\n- src/bin/log.rs (pager, diff output)\n\nExample:\n```\ncommonplace log workspace/file.txt\n→ newest first, colorized, with diffs, through pager\n```","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T20:42:14.214758441Z","created_by":"jes","updated_at":"2026-01-03T20:56:06.677094668Z","closed_at":"2026-01-03T20:56:06.677094668Z","close_reason":"Added pager support (less -R by default for TTY), colored diff output by default, --no-patch and --no-pager flags, -p and -u flag support"}
{"id":"CP-hivq","title":"P2: URL-encode evaluate script URL","description":"The script URL is assembled by concatenating document_path and script without URL encoding. Spaces or special chars in paths will break the URL.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-06T06:34:05.307301794Z","created_by":"jes","updated_at":"2026-01-07T01:10:34.118655827Z","closed_at":"2026-01-07T01:10:34.118655827Z","close_reason":"Added encode_url_path() helper to URL-encode path segments in evaluate script URLs"}
{"id":"CP-hm9","title":"MCP server: Keep MQTT event loop alive until publish is delivered","design":"From Codex review on PR #31: The event loop is capped at 2 seconds, so if broker connection takes longer, the publish() call only enqueues the packet and the loop stops before it can be sent/acked. fire_command returns success even if command was not delivered. Consider keeping a persistent MQTT client or waiting for ConnAck/PubAck before reporting success. File: src/bin/mcp.rs:73","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-12-30T02:22:36.905947547Z","created_by":"jes","updated_at":"2026-01-03T08:25:57.6795406Z","closed_at":"2026-01-03T08:25:57.6795406Z","close_reason":"MCP server now properly waits for ConnAck and PubAck before reporting success. Fixed the race condition where fire_command could return success before the message was delivered."}
{"id":"CP-hxw6","title":"Rename processes.json to __processes.json for visibility","description":"The processes.json file within workspace directories looks too mundane. Rename to __processes.json to make it stand out as a special system file, similar to __pycache__ or __init__.py conventions.","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-05T06:44:09.264086032Z","created_by":"jes","updated_at":"2026-01-05T07:05:56.304854344Z","closed_at":"2026-01-05T07:05:56.304854344Z","close_reason":"Renamed processes.json to __processes.json throughout codebase: code, comments, log messages, and workspace files. Build, clippy, and tests pass."}
{"id":"CP-i0v","title":"File link UUIDs get overwritten when orchestrator restarts","description":"When the orchestrator restarts with a fresh database, the server's fs reconciler generates new UUIDs for entries instead of using the UUIDs from the local .commonplace.json schema.\n\n**Expected:** The linked UUIDs (e.g., aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa) should be preserved from the local schema.\n\n**Actual:** Reconciler creates new UUIDs, destroying file links.\n\n**Log evidence:**\n- Reconciler created document: bartleby/prompts.txt -\u003e afd6bda9-2d8c-479b-a64d-0d4a03b90def\n- Should have used: aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa (from local schema)\n\n**Root cause hypothesis:**\nThe server's fs reconciler runs before sync can push the local schema. With --initial-sync local, the sync should push first, but there's a race condition or ordering issue.\n\n**Workaround:** None currently - manual schema restoration required after each restart.","notes":"Theory: On restart with fresh DB, sync scans the directory and only preserves UUIDs if it can parse local .commonplace.json. If that file is missing/unreadable at startup (or path mismatch), scan_directory generates schema without node_id fields. That schema is pushed first (initial-sync local), so the server reconciler assigns fresh UUIDs. Immediately after, sync builds uuid_map from the server schema and uses those IDs for file sync, effectively overwriting the intended link UUIDs. Root cause is startup ordering/availability of .commonplace.json (or parse failure) rather than reconciler ignoring node_id.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T10:33:03.4426906Z","created_by":"jes","updated_at":"2026-01-01T11:18:07.089985344Z","closed_at":"2026-01-01T11:18:07.089985344Z","close_reason":"Fixed in PR #73. Nested schemas for node-backed directories are now persisted locally and restored on startup with --initial-sync local.","comments":[{"id":10,"issue_id":"CP-i0v","author":"jes","text":"Root cause found: The reconciler's migrate_inline_subdirectories() generates new UUIDs for inline subdirectories (line 521 in reconciler.rs) when migrating them to node-backed format. \n\nThe fix: The reconciler should NOT migrate inline directories to node-backed format. The inline format with explicit node_ids is the correct representation for file linking. Migration should only generate UUIDs for entries that don't have them, not restructure the schema.\n\nAlternatively, we could make migration opt-in or disable it entirely when the schema has inline entries with node_ids.","created_at":"2026-01-01T10:53:03Z"}]}
{"id":"CP-i7c1","title":"P2: Config reload ignores dependency order","description":"In manager.rs around lines 535-556, when reloading config and starting new processes, the code doesn't respect the depends_on order. New processes may start before their dependencies are ready.\n\nLocation: src/orchestrator/manager.rs:535-556\nFound by: codex review","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-05T09:09:53.825787284Z","created_by":"jes","updated_at":"2026-01-06T01:19:43.299495213Z","closed_at":"2026-01-06T01:19:43.299495213Z","close_reason":"Use startup_order() for new/changed processes in reload_config"}
{"id":"CP-ia7","title":"CRDT merge corrupts JSON version field","description":"When pushing schema updates to an fs-root document that already has content, the CRDT merge can corrupt the JSON. Specifically, the 'version' field which should be integer 1 becomes string 've'. This appears to be a character-level diff/merge issue where {\"version\": 1} gets partially merged and produces garbage.\n\nThe corruption causes reconciler to fail with 'JSON parse error: invalid type: string \"ve\", expected u32'.\n\nWorkaround: only push to empty fs-root documents.\n\nReproduction:\n1. Start server with --fs-root and --database\n2. Run sync with --initial-sync local (pushes schema)\n3. Modify local .commonplace.json\n4. Run sync again with --initial-sync local\n5. Server schema now has corrupted version field","notes":"Diagnosis: DocumentStore::set_content uses diff::compute_diff_update (Y.Text char diff) regardless of content type. This is called by fs reconciler when migrating inline subdirectories and when updating fs-root schema. For JSON docs (ContentType::Json/JsonArray/Jsonl), applying a text-based Yjs update corrupts the underlying Y.Map/Y.Array state. That corrupted Yjs state then merges with later schema edits and can turn numeric fields into junk strings (e.g. version=\"ve\").\\n\\nLikely fix: make set_content content-type aware. For JSON/JSONL/JsonArray, generate a Yjs update with create_yjs_json_update/create_yjs_jsonl_update (using current ydoc state as base) instead of text diff; keep text diff only for Text/Xml. Alternatively route reconciliation updates through DocumentService::replace_content so JSON merge logic is used.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T06:13:37.424739978Z","created_by":"jes","updated_at":"2026-01-01T06:56:57.43341078Z","closed_at":"2026-01-01T06:56:57.43341078Z","close_reason":"Fixed in PR #70. set_content now uses content-type aware Yjs updates."}
{"id":"CP-id2","title":"Orchestrator spawns processes outside sandbox that become orphaned","description":"The orchestrator spawned text-to-telegram processes (PIDs 229628, 229633) at 07:45 that ran outside the sandbox and survived as orphans.\n\nThese orphaned processes then blocked new sandbox instances from starting (text-to-telegram detects duplicate instance and exits).\n\nTimeline:\n- 07:45: Orchestrator started (PID 229603)\n- 07:45: file-tmux-file started (229612) - in sandbox, works\n- 07:45: bartleby started (230639) - in sandbox, works  \n- 07:45: text-to-telegram started (229628, 229633) - NOT in sandbox, orphaned\n- 11:49: New text-to-telegram attempts keep failing because orphans block them\n\nThe orphaned processes had no parent commonplace-sync wrapper, suggesting they were spawned directly rather than through the sandbox mechanism.\n\nRelated: CP-a0g (orphaned processes survive restarts)","notes":"Root cause identified: commonplace.json contains OLD format config with 'command' field for text-to-telegram (spawns directly), while workspace/text-to-telegram/processes.json has NEW 'sandbox-exec' format.\n\nThe orchestrator likely loads BOTH configs, causing duplicate spawns:\n1. From commonplace.json: spawns via 'command' field → runs directly → orphans\n2. From recursive discovery: finds processes.json → spawns in sandbox → correct\n\nSolution: Either remove old text-to-telegram entry from commonplace.json, or fix orchestrator to not load both.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T11:51:26.841850296Z","created_by":"jes","updated_at":"2026-01-03T18:28:45.016071733Z","closed_at":"2026-01-03T18:28:45.016071733Z","close_reason":"Fixed by config cleanup. commonplace.json no longer contains application process definitions (bartleby, text-to-telegram). These are now only discovered via recursive mode from workspace/processes.json files, preventing the duplicate spawn issue."}
{"id":"CP-ie8","title":"Orchestrator fails to parse processes.json in subdirectories","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T11:06:13.174709745Z","created_by":"jes","updated_at":"2026-01-03T07:17:49.644809268Z","closed_at":"2026-01-03T07:17:49.644809268Z","close_reason":"Verified working - text-to-telegram runs from workspace/text-to-telegram/processes.json (subdirectory)"}
{"id":"CP-j4wg","title":"Deleted files sometimes reappear after sync","description":"Summary: In some sync flows, deleting a file does not stick; the file can reappear after a subsequent sync event, likely due to stale watcher events or missing tombstone handling between local and remote state.\\n\\nFiles to modify:\\n- src/sync/dir_sync.rs\\n- src/sync/file_sync.rs\\n- src/sync/state.rs\\n- src/sync/watcher.rs\\n- src/sync/sse.rs\\n- tests (add regression coverage for delete propagation)\\n\\nImplementation steps:\\n1. Reproduce by deleting a synced file while the system is running, then trigger a sync/refresh to observe the file reappearing.\\n2. Trace delete propagation from local watcher to upload, and from server updates back to local, paying attention to event ordering and dedupe.\\n3. Ensure deletions are represented as tombstones/commits in state and are not overwritten by stale updates.\\n4. Update sync logic to ignore or drop resurrecting updates when a newer deletion is known locally or remotely.\\n5. Add a regression test that deletes a file and asserts it stays deleted after subsequent sync cycles.\\n\\nExample:\\nBefore: delete note.txt -\u003e file reappears after sync.\\nAfter: delete note.txt -\u003e file remains deleted across sync cycles.\\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T18:21:34.140006526Z","created_by":"jes","updated_at":"2026-01-06T22:50:49.483718498Z","closed_at":"2026-01-06T22:50:49.483718498Z","close_reason":"Fixed: Added handle_subdir_schema_cleanup() to properly handle subdirectory SSE events with correct node_id and path parameters. Includes file deletion support and safety guard against empty UUID maps. Merged in PR #105."}
{"id":"CP-jbw5","title":"SDK uses wrong Yjs type getter - getText() for all files instead of type-specific getter","description":"The SDK always uses doc.getText('content') regardless of file type, but the server stores different content types using different Yjs types:\n\n- .txt/.md → Y.Text (getText works)\n- .jsonl → Y.Array (need getArray, getText returns empty)\n- .json → Y.Map (need getMap, getText returns empty)\n\nCurrent behavior:\n- SDK calls getText('content') for all files\n- Works for text files\n- Returns empty for JSONL/JSON files (wrong Yjs type)\n\nFix needed:\n- SDK already detects content type from file extension\n- Use contentType to call the right Yjs getter:\n  - 'text' → getText('content')\n  - 'jsonl' → getArray('content')  \n  - 'json' → getMap('content')\n- This affects DocHandleImpl and OutputHandleImpl\n\nCurrent workaround: SDK uses head.content directly instead of Yjs state.\n\nImpact: Real-time CRDT sync (via MQTT edits) won't work for JSONL/JSON files until this is fixed.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T02:05:16.775333687Z","created_by":"jes","updated_at":"2026-01-07T02:09:12.143454172Z","closed_at":"2026-01-07T02:09:12.143454172Z","close_reason":"Fixed SDK to use correct Yjs type getter (getText/getArray/getMap) based on content type. JSONL files now properly read from Y.Array, JSON from Y.Map. Real-time CRDT sync works for all file types."}
{"id":"CP-jgn","title":"Deleting directory on disk should remove it from parent .commonplace.json","description":"When a directory is deleted from the filesystem in a synced tree, the sync should detect this and remove the entry from the parent folder's .commonplace.json schema.\n\nCurrently, the directory is recreated by sync because it still exists in the schema. Users have to manually edit .commonplace.json to permanently delete directories.\n\nImplementation note: May need to track additional local state about whether directories were previously checked out, to distinguish between 'deleted locally' vs 'not yet synced from server'.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T04:58:36.700774372Z","created_by":"jes","updated_at":"2026-01-03T08:43:49.841959198Z","closed_at":"2026-01-03T08:43:49.841959198Z","close_reason":"Implemented directory sync state tracking. Directories that are synced are now recorded in .commonplace-synced-dirs.json. When a directory exists in schema but not on disk, sync checks if it was previously synced - if so, it's treated as a local deletion and not recreated."}
{"id":"CP-jn3g","title":"commonplace-ps should show base processes from commonplace.json","description":"commonplace-ps only shows processes discovered from processes.json files (via DiscoveredProcessManager). It doesn't show base processes started from commonplace.json (via ProcessManager).\n\nExample - these are running but not shown:\n- server\n- sync  \n- beads-sync\n\nOnly discovered sandbox processes appear:\n- bartleby\n- file-tmux-file\n- text-to-telegram\n\nFix: ProcessManager should also write to the status file, or merge both managers' status.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T19:51:37.579636924Z","created_by":"jes","updated_at":"2026-01-04T00:11:42.427240514Z","closed_at":"2026-01-04T00:11:42.427240514Z","close_reason":"Added merge_and_write() to OrchestratorStatus that preserves processes from both ProcessManager (base) and DiscoveredProcessManager (discovered). Both managers now use this method, and commonplace-ps shows all processes. Commit: fb043c7"}
{"id":"CP-jnf","title":"Support JSON files as Yjs map/array types in directory sync","description":"Summary: Allow synced JSON files to be stored as Yjs map/array types (not plain text) so JSON structure is preserved in CRDT.\n\nFiles to modify:\n- src/document.rs (content type handling / default doc type)\n- src/diff.rs (JSON diff generation if needed)\n- src/bin/sync.rs (JSON file handling, initial sync)\n- src/sync/content_type.rs (content type mapping, potentially new metadata)\n- docs/FILESYSTEM.md (clarify JSON type behavior)\n- docs/WIRING_DIAGRAM_FILES.md (if wiring files need special handling)\n\nImplementation steps:\n1. Identify how JSON documents are represented in yrs (map/array) vs text and how current commits are applied.\n2. Decide on encoding for JSON files in sync (map vs array based on top-level JSON).\n3. Update sync upload/replace logic to send JSON updates rather than text edits for JSON files.\n4. Ensure server-side content retrieval returns serialized JSON for map/array docs.\n5. Add tests/fixtures for JSON map/array round-trips through sync.\n\nExample:\n- Before: file data.json stored as plain text in Yjs text.\n- After: data.json stored as Yjs map or array (based on top-level JSON), serialized to JSON text on read/write.\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T13:28:50.035996-08:00","updated_at":"2025-12-28T14:00:59.660408-08:00","closed_at":"2025-12-28T14:00:59.660408-08:00","close_reason":"Implemented JSON map/array sync support"}
{"id":"CP-joe","title":"Blocks acceptance: Bartleby sandbox syncs wrong path (bartleby/ instead of full workspace)","description":"P4 acceptance criteria fails: The bartleby sandbox should sync the entire workspace/ tree with bartleby/ as a subdirectory. Currently it only syncs workspace/bartleby/ as its root. Expected: Bartleby sandbox has files like text-to-telegram/, tmux/, content.txt at root, with bartleby/ as subdirectory. Actual: Bartleby sandbox has output.txt, prompts.txt at root (these are workspace/bartleby/ files).","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T03:23:53.597170323Z","created_by":"jes","updated_at":"2026-01-03T03:32:36.664155073Z","closed_at":"2026-01-03T03:32:36.664155073Z","close_reason":"Fixed by moving bartleby from workspace/bartleby/processes.json to workspace/processes.json. Processes sync at the directory containing their processes.json, so bartleby must be defined at root level to sync the entire workspace tree. Added clarifying section to acceptance criteria doc."}
{"id":"CP-jpx","title":"Sync client fails when files have pre-set node_ids but reconciler not running","description":"When .commonplace.json has pre-set node_ids (for file linking), sync correctly reads them but then waits forever for a reconciler to create the documents. The sync should either:\n1. Create documents directly via POST /docs if they don't exist\n2. Or clearly require --fs-root on the server\n\nCurrently blocks bartleby-telegram file linking use case.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-31T23:55:18.052642482Z","created_by":"jes","updated_at":"2026-01-01T00:04:03.65171956Z","closed_at":"2026-01-01T00:04:03.65171956Z","close_reason":"Not a bug - works when server has --fs-root enabled. Documented correct workflow in docs/FILESYSTEM.md."}
{"id":"CP-jr39","title":"Named workspaces with MQTT topic namespacing","description":"Introduce the concept of named workspaces where all MQTT commands are nested within that workspace name.\n\n- Each workspace has a name (default: \"commonplace\")\n- All MQTT topics are prefixed with the workspace name\n- Allows multiple independent commonplace instances to share an MQTT broker\n- Example: `commonplace/docs/{id}/blue` instead of `docs/{id}/blue`\n\nThis enables multi-tenant deployments and cleaner topic organization.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-08T19:41:18.67045053Z","created_by":"jes","updated_at":"2026-01-08T21:06:27.381058731Z","closed_at":"2026-01-08T21:06:27.381058731Z","close_reason":"Implemented workspace namespacing for MQTT topics"}
{"id":"CP-jrc","title":"Sync overwrites local schema with server content, losing commonplace-link changes","description":"When sync starts and server already has content, it fetches the server schema and overwrites the local .commonplace.json file. This destroys any changes made by commonplace-link.\n\nRoot cause: dir_sync.rs:783-791 unconditionally writes server schema to local file when strategy=skip (server has content).\n\nRepro:\n1. Run sync to establish initial schema\n2. Run commonplace-link to create shared UUIDs  \n3. Run sync again\n4. Local schema is overwritten with server's old schema, losing the link\n\nExpected: Sync should either push local schema changes to server, or merge local+server schemas.\n\nLocation: src/sync/dir_sync.rs:783-791","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T05:46:00.069867795Z","created_by":"jes","updated_at":"2026-01-01T05:52:29.616008208Z","closed_at":"2026-01-01T05:52:29.616008208Z","close_reason":"Fixed by preserving local schema when it exists. Merged in PR #68."}
{"id":"CP-jwf","title":"Refactor sync.rs: Extract SyncState into separate module","description":"sync.rs is 2,407 lines - the largest file in the codebase. Extract `SyncState` struct and its associated methods (echo detection, write tracking, hash tracking) into `src/sync/state.rs`.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-30T00:34:50.838547-08:00","updated_at":"2025-12-30T08:54:16.77161781Z","closed_at":"2025-12-30T08:54:16.77161781Z","close_reason":"Extracted SyncState and PendingWrite to src/sync/state.rs. Added documentation for echo detection and write barrier. Merged in PR #38."}
{"id":"CP-klb","title":"Add commonplace-uuid CLI to resolve a synced path to its UUID","description":"Summary: Provide a command-line tool that accepts a synced file path and prints the UUID it is linked to.\n\nFiles to modify:\n- src/bin (new binary, e.g., src/bin/commonplace-uuid.rs)\n- src/sync/dir_sync.rs or src/sync/state_file.rs (reuse path→UUID resolution logic)\n- README.md or docs/DEVELOPMENT.md (document usage)\n\nImplementation steps:\n1. Implement CLI that takes a path (relative or absolute) and resolves the owning document + UUID (same logic as sync uses).\n2. If file is linked, print the UUID to stdout and exit 0.\n3. If not linked, print a clear error and exit non-zero.\n4. Add a `--json` option that prints `{ \"path\": \"...\", \"uuid\": \"...\" }`.\n\nExample:\ncommonplace-uuid workspace/text-to-telegram/input.txt\n→ 12504d60-2b58-43c8-b461-a42215a3954d\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T05:46:09.496176753Z","created_by":"jes","updated_at":"2026-01-03T07:08:46.657641137Z","closed_at":"2026-01-03T07:08:46.657641137Z","close_reason":"Added commonplace-uuid CLI in src/bin/uuid.rs with --json support"}
{"id":"CP-ksf","title":"CLI tool for firing commands to commonplace paths","description":"A command-line tool that sends commands to a specified commonplace document path. Allows scripting and manual interaction with commonplace documents via their red port (events/commands).","design":"Needs design discussion: High-level feature request without implementation details. Requires specification of API design, data model, and integration points before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.268771-08:00","updated_at":"2025-12-29T23:50:06.348786945Z","closed_at":"2025-12-29T23:50:06.348786945Z","close_reason":"commonplace-cmd CLI implemented. Merged in PR #28."}
{"id":"CP-l5b","title":"Orchestrator leaves orphaned processes when killed","description":"When orchestrator or commonplace-sync is killed (SIGTERM/SIGKILL), spawned child processes (e.g., bartleby.py, text_to_telegram) are left orphaned. Need proper process cleanup - either kill children on exit or use process groups.","notes":"Investigation: orchestrator only listens for Ctrl+C (SIGINT) and never registers SIGTERM handlers in src/bin/orchestrator.rs. So SIGTERM exits immediately without running manager.shutdown(), leaving children alive. For SIGKILL no cleanup is possible. Also shutdown only sends SIGTERM to child PID, not process group; grandchildren can survive.\n\nFix advice: \n1) Add SIGTERM handler (tokio::signal::unix::signal(SignalKind::terminate())) and route it to the same shutdown path as Ctrl+C. \n2) Spawn children into their own process group (Command::before_exec setpgid(0,0)) and on shutdown send SIGTERM to -pid (killpg) before waiting; fall back to SIGKILL. \n3) Consider PR_SET_PDEATHSIG (libc::prctl) so children get SIGTERM if orchestrator dies abruptly, which covers SIGKILL of parent. \n4) Optionally set kill_on_drop(true) for extra safety when handles are dropped.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-01T19:42:53.377806426Z","created_by":"jes","updated_at":"2026-01-02T08:02:20.485194609Z","closed_at":"2026-01-02T08:02:20.485194609Z","close_reason":"Verified working: When orchestrator killed with SIGTERM, all child processes (sandbox syncs, bartleby, text-to-telegram) are properly terminated and sandbox directories are cleaned up. T1-T6 acceptance tests pass. The SIGTERM handler, process groups (setpgid), kill_on_drop, and PDEATHSIG are all working as documented in the issue comments.","comments":[{"id":16,"issue_id":"CP-l5b","author":"jes","text":"Diagnosis: In current code, orchestrator already handles SIGTERM and cleans up process trees. src/bin/orchestrator.rs registers SIGTERM via tokio::signal::unix::signal(SignalKind::terminate()) and routes it to shutdown. src/orchestrator/manager.rs and src/orchestrator/discovered_manager.rs set process groups in pre_exec (setpgid), request PR_SET_PDEATHSIG on Linux, enable kill_on_drop, and on shutdown call killpg with SIGTERM then SIGKILL. This matches the proposed fix in the issue notes. If orphaning is still happening, likely running an older binary or non-unix build (non-unix path only handles Ctrl+C). SIGKILL of parent still cannot be intercepted, but PDEATHSIG should cover abrupt parent death on Linux.","created_at":"2026-01-02T07:09:34Z"},{"id":17,"issue_id":"CP-l5b","author":"jes","text":"Follow-up: further testing should record specifics of what was tried (exact binary/commit, how it was terminated, and which child PID tree was orphaned) and what went wrong, so we can reproduce on Ubuntu.","created_at":"2026-01-02T07:12:55Z"}]}
{"id":"CP-l9p","title":"Add lockfile to prevent multiple sync instances per checkout","description":"Summary: Prevent multiple sync processes from managing the same checkout (or nested checkouts), which can cause conflicting updates.\n\nFiles to modify:\n- src/bin/sync.rs (startup/CLI entry for sync client)\n- src/sync/state_file.rs or a new lock module for lockfile creation/validation\n- docs/DEVELOPMENT.md or README.md (document lock behavior)\n\nImplementation steps:\n1. On sync startup, compute a lockfile path scoped to the checkout root (e.g., .commonplace-sync.lock in fs-root or workspace root).\n2. Attempt to acquire an exclusive lock (PID + timestamp). If lock already exists and process is alive, exit with clear error.\n3. If lock is stale (PID not running), overwrite and continue.\n4. Detect nested sync roots: if a lockfile exists in a parent directory, refuse to start and explain the conflict.\n5. Ensure lockfile is released on clean shutdown (best-effort).\n\nExample:\n- Start sync in /home/jes/commonplace/workspace → creates .commonplace-sync.lock\n- Attempt to start another sync in /home/jes/commonplace/workspace or /home/jes/commonplace/workspace/subdir → error: sync","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T05:38:29.383950693Z","created_by":"jes","updated_at":"2026-01-03T07:16:04.212881149Z","closed_at":"2026-01-03T07:16:04.212881149Z","close_reason":"Added acquire_sync_lock() in sync/mod.rs with exclusive file lock (.commonplace-sync.lock)"}
{"id":"CP-lav","title":"Python client: y_py YDoc not thread-safe with paho-mqtt callbacks","design":"The y_py (Yjs Python bindings) YDoc panics when accessed from a different thread than where it was created. paho-mqtt runs message callbacks in a background thread. When command handlers try to publish_edit(), they access YDoc from the MQTT thread, causing panic. Fix options: 1) Use queue to dispatch updates from MQTT thread to main thread, 2) Create YDoc in MQTT thread, 3) Use asyncio-based MQTT client with single-threaded event loop.","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-30T00:30:34.203735202Z","created_by":"jes","updated_at":"2025-12-30T01:17:06.747552054Z","closed_at":"2025-12-30T01:17:06.747552054Z","close_reason":"Fixed by implementing queue-based pattern for YDoc operations. MQTT callbacks queue work, main loop processes. Committed in ded73c4."}
{"id":"CP-li3","title":"Deprecate wiring diagram concept","description":"The wiring diagram concept should be deprecated and removed from the codebase.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:44.059396274Z","created_by":"jes","updated_at":"2025-12-29T08:56:46.462777465Z","closed_at":"2025-12-29T00:50:28.541758-08:00","close_reason":"PR #18 merged. Deprecated nodes abstraction, restored /nodes HTTP endpoints for sync, renamed /sse/nodes to /sse/docs, fixed fs-root ContentType. Follow-up issues filed: CP-bnv (path-based API), CP-pta (nodes→docs rename), CP-m2g (sync path-based)."}
{"id":"CP-ljyu","title":"Add spawn priority to commonplace.json for orchestrator order","description":"Summary: Add a priority field to commonplace.json so orchestrator spawn order is configurable instead of hardcoding server-first.\n\nFiles to modify:\n- src/orchestrator/config.rs (add priority field to process config)\n- src/orchestrator/manager.rs or discovered_manager.rs (use priority for startup order)\n- docs/DEVELOPMENT.md or README.md (document new field)\n\nImplementation steps:\n1. Add numeric priority to process config schema (lower = earlier).\n2. Update orchestrator to sort processes by priority before startup.\n3. Keep existing behavior as default (server priority = 0 if unspecified).\n4. Update docs and examples.\n\nExample:\n- server: priority 0\n- sync: priority 10\n- text-to-telegram: priority 20","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T19:42:45.772623557Z","created_by":"jes","updated_at":"2026-01-04T01:08:32.072250537Z","closed_at":"2026-01-04T01:08:32.072250537Z","close_reason":"Won't implement - user prefers depends_on over numeric priority for startup ordering"}
{"id":"CP-lr9","title":"Sync race condition causes output file overwrites","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-31T20:09:30.137946956Z","created_by":"jes","updated_at":"2025-12-31T21:51:40.994526815Z","closed_at":"2025-12-31T21:51:40.994526815Z","close_reason":"Fixed in PR #59. refresh_from_head now checks for pending local changes before overwriting.","comments":[{"id":7,"issue_id":"CP-lr9","author":"jes","text":"Root cause identified: sync client processes its own SSE edit events. Simple fix found - check edit.commit.author == sync-client in handle_server_edit. See CP-lr9-investigation.md for full analysis.","created_at":"2025-12-31T20:21:16Z"}]}
{"id":"CP-lzb","title":"Fix P1: Start sync tasks for files created from server schema (PR #4)","description":"From PR #4 Codex review: When a new path appears in the server schema, the handler doesn't start sync tasks for the new files.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:22.281537-08:00","updated_at":"2025-12-26T23:43:55.692683-08:00","closed_at":"2025-12-26T23:43:55.692683-08:00","close_reason":"Already fixed and merged to main. The handle_schema_change function now takes a spawn_tasks parameter, and runtime SSE events (line 1186) pass spawn_tasks=true to spawn sync tasks for new server-created files."}
{"id":"CP-lzy","title":"Sync sandbox exposes commonplace CLI tools to child","description":"Sync sandbox should ensure commonplace command line tools are available to the child process (in PATH or similar).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:50:47.47569485Z","created_by":"jes","updated_at":"2025-12-30T22:09:01.350202303Z","closed_at":"2025-12-30T22:09:01.350202303Z","close_reason":"Closed","dependencies":[{"issue_id":"CP-lzy","depends_on_id":"CP-8ci","type":"blocks","created_at":"2025-12-30T17:50:58.721422649Z","created_by":"daemon"},{"issue_id":"CP-lzy","depends_on_id":"CP-q3m","type":"blocks","created_at":"2025-12-30T18:02:57.44355175Z","created_by":"daemon"}],"comments":[{"id":5,"issue_id":"CP-lzy","author":"jes","text":"Accidentally closed - depends on CP-8ci","created_at":"2025-12-30T21:02:26Z"}]}
{"id":"CP-m2g","title":"Convert sync client to use path-based API","design":"Once path-based HTTP APIs exist (CP-bnv), update commonplace-sync to use paths like /files/notes/todo.txt instead of requiring UUIDs. This would simplify the sync client - no need to create nodes or track UUIDs, just sync files by their natural paths.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-29T08:35:40.683147536Z","created_by":"jes","updated_at":"2025-12-29T22:21:03.49437558Z","closed_at":"2025-12-29T22:21:03.49437558Z","close_reason":"Added --use-paths flag to sync client for path-based API. URL builders select between /files/*path and /docs/:id routes with proper path encoding. Merged in PR #25.","dependencies":[{"issue_id":"CP-m2g","depends_on_id":"CP-bnv","type":"blocks","created_at":"2025-12-29T08:35:57.462826032Z","created_by":"daemon"},{"issue_id":"CP-m2g","depends_on_id":"CP-pta","type":"blocks","created_at":"2025-12-29T08:37:30.460677237Z","created_by":"daemon"}]}
{"id":"CP-m6ua","title":"Orchestrator should maintain secure store of ED25519 keypairs","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-09T01:04:59.684693783Z","created_by":"jes","updated_at":"2026-01-09T01:04:59.684693783Z"}
{"id":"CP-mg8x","title":"Add MQTT topic for document info/metadata","description":"HTTP has GET /docs/:id/info to get document metadata (id, content_type) but there's no MQTT equivalent.\n\nAdd to sync protocol or commands port to allow MQTT clients to query document metadata.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:06.698434146Z","created_by":"jes","updated_at":"2026-01-09T07:05:06.698434146Z"}
{"id":"CP-mpt","title":"Factor dir_sync.rs into smaller modules","description":"dir_sync.rs is 63KB and handles multiple concerns:\n- Schema syncing and reconciliation\n- Directory watching and SSE tasks\n- File creation/modification/deletion handlers\n- UUID map building\n- Nested schema handling\n\nShould be split into focused modules like:\n- schema_sync.rs - schema fetching and reconciliation\n- handlers.rs - file event handlers (created/modified/deleted)\n- uuid_map.rs - UUID resolution from schemas\n- nested.rs - nested schema handling for node-backed directories","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-03T07:49:39.445210344Z","created_by":"jes","updated_at":"2026-01-03T09:08:39.000702126Z","closed_at":"2026-01-03T09:08:39.000702126Z","close_reason":"Extracted uuid_map.rs module from dir_sync.rs. Moved 7 UUID resolution and path mapping functions into a focused module. dir_sync.rs reduced from 1834 to 1580 lines (~254 lines). The handlers remain in dir_sync.rs as they're tightly coupled with schema operations."}
{"id":"CP-mxt2","title":"Add MQTT topic for replace with diff","description":"HTTP has POST /docs/:id/replace which computes a diff and applies it as a Yjs update. No MQTT equivalent.\n\nThis is useful for clients that don't have Yjs - they can send plain text and the server computes the CRDT update.\n\nAdd to sync protocol or as a commands verb.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-09T07:05:08.93457045Z","created_by":"jes","updated_at":"2026-01-09T07:05:08.93457045Z"}
{"id":"CP-n0x","title":"commonplace-replay only showing one commit","description":"commonplace-replay only shows a single commit for files that should have a longer history.\n\nExample:\n```\njes@commonplace:~/commonplace/workspace$ ../target/release/commonplace-replay bartleby/prompts.txt\nCommit: 9eb1736331c96195d0b5102a88a9ea7b6f02170a6708493c345b1c241bc1ea12\n```\n\nExpected: Should show the full commit history with timestamps and content changes, similar to git log.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-03T11:46:02.083601064Z","created_by":"jes","updated_at":"2026-01-03T18:49:05.462908871Z","closed_at":"2026-01-03T18:49:05.462908871Z","close_reason":"Fixed. Default output now shows commit count and hints at --list for full history."}
{"id":"CP-n4ga","title":"Support image files as base64-encoded text","description":"Summary: Allow image files to sync as base64-encoded text documents so images can travel through the existing text/Yjs pipeline without external blob storage.\n\nFiles to modify:\n- src/sync/content_type.rs\n- src/sync/file_sync.rs\n- src/services/document.rs\n- docs/ARCHITECTURE.md (or README.md)\n- tests (add/extend an image sync roundtrip test)\n\nImplementation steps:\n1. Detect image extensions/content types (png, jpg/jpeg, gif, webp) and map them to a new content type like ImageBase64 or similar.\n2. On upload (local -\u003e server), read the image bytes and encode to base64 text; store in the document as a data URL (e.g., \"data:image/png;base64,...\") or a structured JSON wrapper with mime + data.\n3. On download (server -\u003e local), decode the base64 text back to bytes and write the file with the original extension.\n4. Ensure the text/Yjs diff path treats the base64 payload as opaque (no line ending normalization).\n5. Add tests that roundtrip a small image fixture and assert exact byte equality after sync.\n\nExample:\nBefore: image.png sync attempts to treat bytes as text and fails/garbles content.\nAfter: image.png is stored as \"data:image/png;base64,iVBORw0...\" and decodes back to the same bytes when written locally.\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T04:10:13.558172021Z","created_by":"jes","updated_at":"2026-01-05T07:54:07.02193053Z","closed_at":"2026-01-05T07:54:07.02193053Z","close_reason":"Already implemented - binary files including images are detected by extension (BINARY_EXTENSIONS in content_type.rs) and content sniffing, encoded as base64 for sync, and decoded back to bytes on download"}
{"id":"CP-n5mj","title":"Directory sync should use inode tracking (shadow hardlinks)","description":"Summary: Inode tracking/shadow hardlinks are only enabled for file sync mode; directory sync does not use the tracker, so atomic server updates can still drop writes from old inodes in directory sync.\n\nFiles to modify:\n- src/bin/sync.rs\n- src/sync/dir_sync.rs\n- src/sync/sse.rs\n- src/sync/watcher.rs\n- src/sync/state.rs\n\nImplementation steps:\n1. Identify the directory sync path that handles server updates (directory_sse_task / handle_schema_change) and local writes.\n2. Add an InodeTracker scoped per-directory (or per-file) and wire it into directory SSE handling so server updates use atomic_write_with_shadow.\n3. Watch the shadow directory and process shadow writes for directory sync (reuse shadow_watcher_task/shadow_write_handler_task).\n4. Ensure tracker seeding for existing files with known commit_id after initial sync.\n5. Add integration tests covering atomic server replace with a long-lived writer in directory sync mode.\n\nExample:\nBefore: In directory sync mode, server updates replace inodes and old-writer edits are lost.\nAfter: Directory sync creates shadow hardlinks and merges old-writer edits via CRDT.\n","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-06T05:50:39.765330978Z","created_by":"jes","updated_at":"2026-01-06T17:15:46.905763027Z","closed_at":"2026-01-06T17:15:46.905763027Z","close_reason":"Added optional InodeTracker parameter to directory sync functions (spawn_file_sync_tasks, directory_sse_task, subdir_sse_task, handle_schema_change, handle_file_created). When tracker is provided, uses sse_task_with_tracker for atomic writes with shadow hardlinks. All call sites pass None for now - tracker initialization will be added in follow-up work. Merged in PR #101."}
{"id":"CP-nno","title":"External process MQTT client as first-class citizen","description":"Allow a separate Unix process to connect to MQTT and perform all the same actions as the JS sandbox evaluator:\n- Subscribe to document commits\n- Create/own output documents\n- Receive commands on owned document paths\n- Emit events as owned documents\n\nThis makes external processes (any language) first-class participants in the commonplace reactive graph, using MQTT as the protocol.","design":"Needs design discussion: High-level feature request without implementation details. Requires specification of API design, data model, and integration points before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.52436-08:00","updated_at":"2025-12-30T01:26:42.019335953Z","closed_at":"2025-12-30T01:26:42.019335953Z","close_reason":"Python client example complete with FileProcess base class and CounterExample. Bug fixes for sync protocol and thread safety merged in 00fa478."}
{"id":"CP-nrq","title":"Recursive mode fails when server not running - needs to start server+sync first","description":"When --recursive is true (the default), the orchestrator immediately tries to connect to http://localhost:3000/fs-root, but the server hasn't been started yet. This creates a chicken-and-egg problem:\n\n1. commonplace.json defines server and sync processes\n2. Recursive mode needs the server to discover processes.json files\n3. But recursive mode doesn't start the server - it just assumes it's running\n\nThe fix should be:\n1. Start server and sync from commonplace.json first (using ProcessManager)\n2. Wait for sync to push initial content\n3. Then switch to recursive discovery for additional processes\n\nCurrently the only workaround is to use --no-recursive which disables dynamic process discovery entirely.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T18:01:00.270509783Z","created_by":"jes","updated_at":"2026-01-03T18:16:37.580622788Z","closed_at":"2026-01-03T18:16:37.580622788Z","close_reason":"Fixed recursive mode: orchestrator now starts server+sync from commonplace.json before running recursive discovery. Also fixed retry logic for failed processes.json files."}
{"id":"CP-nvc5","title":"Directory sync mode missing inode tracking (causes duplicate deliveries)","description":"The directory sync mode (including sandbox/exec mode) has inode_tracker hardcoded to None in 10 places with TODO comments. This means:\n\n1. Shadow hardlinks are never created for directory-synced files\n2. When atomic writes change the inode, writes to the old inode aren't detected\n3. No merge commits are created for concurrent edits\n4. This causes duplicate deliveries in bartleby-style file IO (CP-raid)\n\nThe single-file sync mode (run_file_mode) has working inode tracking, but run_directory_mode and run_exec_mode do not.\n\nAffected lines in src/bin/sync.rs:\n- 1025, 1116, 1148, 1171, 1200, 1327, 1418, 1449, 1470, 1499\n\nFix: Initialize InodeTracker for directory sync mode and pass it to all the places that currently pass None.","notes":"Fixed by enabling inode tracking in run_directory_mode and run_exec_mode. Added shadow_dir parameter, InodeTracker initialization, shadow watcher/handler/GC tasks, and passed inode_tracker to all SSE task calls that previously passed None.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-07T22:08:51.194605804Z","created_by":"jes","updated_at":"2026-01-07T22:29:31.848339689Z","closed_at":"2026-01-07T22:29:31.84835047Z"}
{"id":"CP-o1h","title":"Fix: Merge commits should include both parent_cid and current HEAD as parents","description":"When parent_cid differs from HEAD in replace endpoint, the new commit only includes parent_cid as its parent. This drops the current HEAD from the commit graph. On history replay, the concurrent edits from HEAD are lost.\n\nFix: When parent_differs is true, the commit should have BOTH parent_cid AND current_head as parents.\n\nFound by local codex review on PR #37.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-30T08:14:26.210722759Z","created_by":"jes","updated_at":"2025-12-30T08:24:36.109315944Z","closed_at":"2025-12-30T08:24:36.109315944Z","close_reason":"Fixed merge commits to include both parent_cid AND current HEAD when they differ. This preserves concurrent edits in commit DAG for proper history replay. Committed in 7ebc4bd."}
{"id":"CP-o2h","title":"Evaluate whether NodeRegistry is still needed after HTTP/store split","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T00:52:45.145726221Z","created_by":"jes","updated_at":"2025-12-29T04:12:26.221158382Z","closed_at":"2025-12-29T04:12:26.221158382Z","close_reason":"Evaluated: NodeRegistry is NOT duplicated after HTTP/store split. Store owns it (document state, wiring, fs reconciliation). HTTP is stateless (MQTT gateway only). Architecture is already optimal - no changes needed.","dependencies":[{"issue_id":"CP-o2h","depends_on_id":"CP-8t3","type":"blocks","created_at":"2025-12-29T00:52:52.493729194Z","created_by":"daemon"}]}
{"id":"CP-o7h0","title":"Refactor sync to use MQTT subscriptions instead of SSE","description":"The current sync architecture uses per-document SSE subscriptions, requiring N connections for N node-backed directories. This creates:\n- Startup race conditions (subdirs not discovered until other syncs push)\n- Dynamic SSE task spawning complexity (CP-4w00)\n- Polling/retry workarounds for initial sync\n\nMQTT has hierarchical topic subscriptions built in. Subscribe to docs/workspace/# and get events for the entire subtree. The system already has MQTT for orchestrator communication.\n\nRefactor sync clients to:\n1. Subscribe to MQTT topic wildcards for document changes\n2. Replace SSE connections with MQTT subscriptions\n3. Leverage retained messages to avoid startup races\n\nThis is a cleaner architectural solution than the current workarounds.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-09T06:59:56.442529501Z","created_by":"jes","updated_at":"2026-01-09T06:59:56.442529501Z","dependencies":[{"issue_id":"CP-o7h0","depends_on_id":"CP-s3zg","type":"blocks","created_at":"2026-01-09T07:00:29.670289188Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-g9e8","type":"blocks","created_at":"2026-01-09T07:05:45.141237639Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-1isz","type":"blocks","created_at":"2026-01-09T07:05:45.178783822Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-mg8x","type":"blocks","created_at":"2026-01-09T07:05:45.220137044Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-mxt2","type":"blocks","created_at":"2026-01-09T07:05:45.257705118Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-6ke7","type":"blocks","created_at":"2026-01-09T07:05:45.297933735Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-ef0e","type":"blocks","created_at":"2026-01-09T07:05:45.333543999Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-2cql","type":"blocks","created_at":"2026-01-09T07:05:45.367734864Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-6o2m","type":"blocks","created_at":"2026-01-09T07:05:45.401849064Z","created_by":"jes"},{"issue_id":"CP-o7h0","depends_on_id":"CP-eiyx","type":"blocks","created_at":"2026-01-09T07:05:45.438577195Z","created_by":"jes"}]}
{"id":"CP-occ","title":"Sync should self-terminate and cleanup children when orchestrator dies","description":"When the orchestrator dies (killed or crashes), commonplace-sync sandbox processes should detect this and clean up themselves and their child processes.\n\nCurrent state:\n- PR_SET_PDEATHSIG is set in orchestrator's child spawn code, so sync gets SIGTERM when orchestrator dies\n- But sync may not be properly handling SIGTERM to kill its own children (bartleby, text-to-telegram)\n- Result: orphaned grandchildren when orchestrator dies\n\nProposed fix:\n- Sync should have a SIGTERM handler that kills its spawned child process before exiting\n- Or sync should set PR_SET_PDEATHSIG on its own children so they die when sync dies\n- Could also periodically check if parent PID changed to 1 (reparented to init = parent died)\n\nRelated: CP-a0g (orphaned processes survive restarts)","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T18:51:44.298112292Z","created_by":"jes","updated_at":"2026-01-03T07:21:04.262369886Z","closed_at":"2026-01-03T07:21:04.262369886Z","close_reason":"Implemented: PR_SET_PDEATHSIG on children (line 1091), process groups for cleanup","dependencies":[{"issue_id":"CP-occ","depends_on_id":"CP-a0g","type":"relates-to","created_at":"2026-01-02T18:51:55.364061961Z","created_by":"daemon"},{"issue_id":"CP-occ","depends_on_id":"CP-yw8","type":"relates-to","created_at":"2026-01-02T19:21:00.695841219Z","created_by":"daemon"}]}
{"id":"CP-ofu9","title":"SDK onChange should fire with initial content after get()","description":"When using cp.doc().onChange() and then calling get(), the onChange callback should fire with the initial content. Currently you have to manually call your handler after get() which is awkward and error-prone.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T01:30:20.380563109Z","created_by":"jes","updated_at":"2026-01-07T03:57:27.069303983Z","closed_at":"2026-01-07T03:57:27.06931229Z"}
{"id":"CP-og0","title":"Fork detection: binary file hash mismatch","description":"In CP-rs3 implementation, fork detection for binary files won't work correctly because:\n- Initial sync stores hash of base64-encoded content (via scan_directory_with_contents)\n- New file detection hashes raw bytes before encoding\n\nThis means identical binary files won't be detected as copies. Text files work correctly.\n\nFix: Hash raw file bytes in both cases, before any base64 encoding.","status":"closed","priority":3,"issue_type":"bug","created_at":"2025-12-30T20:07:20.775344004Z","created_by":"jes","updated_at":"2025-12-31T23:04:39.527009741Z","closed_at":"2025-12-31T23:04:39.527009741Z","close_reason":"Fixed hash consistency - both paths now hash raw bytes before base64"}
{"id":"CP-ogpr","title":"Optimize Yjs diff rendering without full history replay","description":"Currently commonplace-log replays all Yjs updates from the beginning to compute diffs. This is O(n) for n commits. Investigate ways to compute diffs more efficiently:\n\n1. Determine minimum context needed to correctly render a delete operation\n2. Consider caching intermediate Yjs states at checkpoints\n3. Look into Yjs snapshot/state-vector capabilities for partial replay\n4. Support lazy diff computation (only compute when needed for display)\n\nThe goal is to avoid replaying the entire history when viewing recent commits.","status":"open","priority":3,"issue_type":"feature","created_at":"2026-01-07T23:34:40.146179338Z","created_by":"jes","updated_at":"2026-01-07T23:34:40.146179338Z"}
{"id":"CP-oi3","title":"JSONL file support","description":"Internally stored as a Yjs array of maps, but sync tool should check it out as JSONL format (one JSON object per line).","notes":"Needs design: How should JSONL ↔ Yjs array/map conversion work? Need to define CRDT structure for array of maps and bidirectional conversion logic.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:46:27.750869028Z","created_by":"jes","updated_at":"2025-12-30T20:49:43.561621338Z","closed_at":"2025-12-30T20:49:43.561621338Z","close_reason":"Merged PR #48 - JSONL file support"}
{"id":"CP-oji","title":"Handle rename events so new paths get sync tasks","description":"notify reports renames as `Modify(Name)` events; the current mapping treats all `is_modify()` as `DirEvent::Modified`. The modified handler only re-pushes schema and never starts new per-file sync tasks or removes old ones, so a rename leaves the new file untracked and the old path's tasks running until restart.\n\nConsider handling rename explicitly (or treating `Modify(Name)` as delete+create).","design":"Implemented by detecting `Modify(Name)` events separately from other modifications in the directory watcher. Rename events are now classified as delete+create based on RenameMode: From→Deleted, To→Created, Both/Any/Other→check path.exists() to determine direction. This ensures sync tasks are properly stopped for old paths and started for new paths.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-26T17:03:59.632881-08:00","updated_at":"2025-12-26T17:49:57.531409-08:00","closed_at":"2025-12-26T17:49:57.531409-08:00","close_reason":"Rename events now handled properly - Modify(Name) events are classified as delete+create based on RenameMode. Merged in PR #5.","labels":["enhancement","sync"]}
{"id":"CP-okn","title":"New orchestrator binary for process management","description":"Create a new orchestrator binary which invokes the document store and (once they exist) other processes like HTTP interface and sandboxed evaluator.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:47.418639497Z","created_by":"jes","updated_at":"2025-12-29T08:45:22.029787664Z","closed_at":"2025-12-29T03:12:03.336139764Z","close_reason":"Orchestrator binary implemented with process supervision, dependency ordering, restart policies with exponential backoff, and graceful shutdown. Merged in PR #16.","dependencies":[{"issue_id":"CP-okn","depends_on_id":"CP-8t3","type":"blocks","created_at":"2025-12-28T21:57:25.7353176Z","created_by":"daemon"}]}
{"id":"CP-oop","title":"Orchestrator should have a global lock so only one can run","description":"Multiple orchestrator instances can run simultaneously, causing duplicate sandbox processes and resource conflicts.\n\nExpected: Only one orchestrator should be able to run at a time for a given server.\nSolution: Implement a global lock (file-based or server-side) that prevents multiple orchestrators from starting.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T19:03:07.375300682Z","created_by":"jes","updated_at":"2026-01-02T19:33:04.471612643Z","closed_at":"2026-01-02T19:33:04.471612643Z","close_reason":"Implemented file-based global lock using fs2. PR #91 merged."}
{"id":"CP-ow96","title":"WebSocket polish: path routing, keep-alive, backpressure (Phase 3)","description":"Polish the WebSocket implementation with production-ready features.\n\nRequires: CP-59h Phase 1 (y-websocket core) - DONE\n\n## Features\n\n1. Path-based WebSocket endpoint\n   - /ws/files/*path - resolve path to doc ID like SSE does\n   - Reuse path resolution from sse.rs\n\n2. Keep-alive ping/pong\n   - Send periodic pings to detect dead connections\n   - Clean up connections that don't respond\n\n3. Backpressure handling\n   - Bounded channel for outgoing messages\n   - Drop slow clients gracefully\n   - Log warnings for lagging connections\n\n4. Graceful shutdown\n   - Clean close messages to clients on server shutdown\n   - Room cleanup on connection drop\n\n## Files to modify\n\n- src/ws/handler.rs - Add path handler, keep-alive\n- src/ws/room.rs - Backpressure handling\n- src/ws/mod.rs - Add /ws/files/*path route","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-04T02:01:47.683938373Z","created_by":"jes","updated_at":"2026-01-04T03:05:04.832447027Z","closed_at":"2026-01-04T03:05:04.832465152Z","dependencies":[{"issue_id":"CP-ow96","depends_on_id":"CP-59h","type":"discovered-from","created_at":"2026-01-04T02:02:24.683120491Z","created_by":"jes"},{"issue_id":"CP-ow96","depends_on_id":"CP-9abt","type":"blocks","created_at":"2026-01-04T02:02:31.577998264Z","created_by":"jes"}]}
{"id":"CP-oxqa","title":"commonplace-log should compute diffs lazily (avoid long prefetch)","description":"Summary: commonplace-log currently computes diffs for every commit before printing output, causing long delays/hangs for large histories. It should stream output and compute diffs lazily.\n\nObserved:\n- commonplace log output.txt hangs for large append-only files.\n- --no-patch or -n is instant, indicating eager diff prefetch.\n\nFiles to modify:\n- src/bin/log.rs (diff computation + output pipeline)\n\nImplementation steps:\n1. Change log output to stream commits as they are fetched instead of precomputing all diffs.\n2. Compute diffs only for commits that will be printed (respect -n/filters early).\n3. Optionally add progress output when diff computation is expensive.\n\nExample:\ncommonplace log output.txt\n→ should start printing immediately, even for large histories.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-04T09:53:09.108066457Z","created_by":"jes","updated_at":"2026-01-04T10:44:08.057512519Z","closed_at":"2026-01-04T10:44:08.057512519Z","close_reason":"Implemented Yjs incremental replay - O(n) instead of O(n²), 992 commits now complete in 0.047s"}
{"id":"CP-pgx","title":"MCP server for firing commands to commonplace paths","description":"An MCP server that exposes commonplace document paths as callable tools. MCP clients can invoke commands on commonplace documents, bridging LLM tool-use with the commonplace reactive document system.","design":"Needs design discussion: High-level feature request without implementation details. Requires specification of API design, data model, and integration points before implementation.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.349217-08:00","updated_at":"2025-12-30T01:43:40.761417202Z","closed_at":"2025-12-30T01:43:40.761417202Z","close_reason":"Implemented commonplace-mcp server. PR #31 created - pending merge.","dependencies":[{"issue_id":"CP-pgx","depends_on_id":"CP-ksf","type":"related","created_at":"2025-12-28T22:50:33.586139-08:00","created_by":"daemon"}]}
{"id":"CP-pk78","title":"Script watch map not refreshed on config edits (P2 from codex)","description":"When the recursive watcher handles edits to an existing __processes.json, the script_watches map is only rebuilt if a processes file was added or removed. Edits that add/change an 'evaluate' entry in an already-watched file are reconciled (the process is started), but the map that triggers restarts on script changes remains stale. In that scenario, subsequent edits to the new script document will never restart the process until the orchestrator itself is restarted or a new __processes.json is added/removed. Consider rebuilding script_watches whenever fetch_and_reconcile changes processes, not just on added/removed files. File: src/orchestrator/discovered_manager.rs:1353-1362","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T07:07:47.641236109Z","created_by":"jes","updated_at":"2026-01-07T01:15:03.217350389Z","closed_at":"2026-01-07T01:15:03.217350389Z","close_reason":"Always rebuild script_watches during periodic re-discovery, not just when files added/removed"}
{"id":"CP-pkzx","title":"Clean up dead subdirs_migrated code from reconciler","description":"After removing inline subdirectory support (CP-e3jr), the subdirs_migrated field in MigrationResult is always 0. Remove this dead code:\n- Remove subdirs_migrated field from MigrationResult struct (reconciler.rs:17)\n- Remove logging code that checks subdirs_migrated \u003e 0 (reconciler.rs:66-71)\n- Update any callers that reference subdirs_migrated","status":"closed","priority":4,"issue_type":"task","created_at":"2026-01-08T18:35:08.616748246Z","created_by":"jes","updated_at":"2026-01-08T19:37:21.739875262Z","closed_at":"2026-01-08T19:37:21.739875262Z","close_reason":"Removed dead subdirs_migrated code"}
{"id":"CP-pr05","title":"Add --force-push flag to overwrite server content without CRDT merge","description":"Add --force-push flag to commonplace-sync:\n\n**Current behavior**: \n- Local edits are sent as CRDT updates based on the last checked-out commit\n- Server merges these with any concurrent server-side edits\n\n**--force-push behavior**:\n- Local file content replaces server HEAD entirely\n- No CRDT merge - local wins unconditionally\n- Uses /docs/{id}/replace endpoint instead of /docs/{id}/edit\n\nUse case: \n- Source-of-truth files where local is authoritative\n- Recovery scenarios where you want to restore from local\n- Combined with --push-only for one-way authoritative sync\n\nImplementation:\n- On local file change, POST full content to /replace instead of computing diff\n- Skip tracking of last-synced CID since we're not doing incremental updates","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T20:04:09.234108668Z","created_by":"jes","updated_at":"2026-01-04T00:26:46.165038252Z","closed_at":"2026-01-04T00:26:46.165038252Z","close_reason":"Implemented --force-push flag for file mode sync"}
{"id":"CP-pta","title":"Rename /nodes API to /docs throughout codebase","design":"Completed implementation. PR #20 created. Waiting for merge.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T08:37:04.362222409Z","created_by":"jes","updated_at":"2025-12-29T09:40:55.11574492Z","closed_at":"2025-12-29T09:40:55.11574492Z","close_reason":"Renamed /nodes API to /docs throughout codebase. Merged all node endpoints into document API. PR #20 merged."}
{"id":"CP-q3m","title":"CLI tool with relative path support in synced directories","description":"The command-line command-issuing tool should work inside a synced directory such that you can use relative paths to send commands to the relevant document.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:48:46.353930244Z","created_by":"jes","updated_at":"2025-12-30T18:24:55.356003983Z","closed_at":"2025-12-30T18:24:55.356003983Z","close_reason":"Added relative path support to commonplace-cmd - PR #45 merged"}
{"id":"CP-q595","title":"P2: Doc handles created after start never subscribe","description":"After cp.start() has been called, later calls to doc.onChange() or doc.onEvent() only push the handle into pendingDocHandles, but no code ever activates those subscriptions unless get() is called manually. Consider activating subscriptions immediately when mqttStarted is true.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-06T06:28:05.025980861Z","created_by":"jes","updated_at":"2026-01-07T01:05:30.243209172Z","closed_at":"2026-01-07T01:05:30.243209172Z","close_reason":"Made activateSubscriptions() idempotent; onChange/onEvent now activate immediately when called after cp.start()"}
{"id":"CP-q7n3","title":"commonplace log shows misleading diffs for merge commits","description":"The commonplace log tool applies Yjs updates in chronological (timestamp) order and computes diffs between consecutive commits. However, when there are merge commits, the 'previous' commit in timestamp order may not be the actual parent, so the diff shown is misleading.\n\nExample from bartleby/output.txt:\n- Commit c8877826 is a merge with parents [99788154, 4cf8e3ba]\n- But the log shows diff against the previous timestamp commit, not against either parent\n- This makes the commit history look like nonsensical edits when it's actually showing the wrong base\n\nThe log tool should either:\n1. Show diffs against the actual parent commit(s), not timestamp-ordered predecessor\n2. For merge commits, show diffs against each parent separately\n3. At minimum, indicate when a commit is a merge and which parents it has\n\nThe underlying Yjs replay is correct (CRDTs are order-independent), but the diff visualization is confusing for merge commits.","notes":"Adding proper DAG topology visualization with ASCII art like git log --graph","status":"in_progress","priority":3,"issue_type":"bug","created_at":"2026-01-07T22:59:52.114403937Z","created_by":"jes","updated_at":"2026-01-07T23:20:26.086197498Z"}
{"id":"CP-qge2","title":"commonplace-beads-bridge binary to sync bd issues to commonplace","description":"New binary that wraps commonplace-sync for .beads/issues.jsonl files. Features:\n- Discovers repo and .beads/issues.jsonl\n- Creates .cbd.json with path mapping\n- Default path: {workspace}/cbd/data/{repo-name}.issues.jsonl\n- Pass-through flags: --push-only, --pull-only, --force-push\n- Configured in commonplace.json for orchestrator management","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T06:43:46.919010395Z","created_by":"jes","updated_at":"2026-01-05T06:51:40.052855937Z","closed_at":"2026-01-05T06:51:40.052855937Z","close_reason":"Implemented commonplace-beads-bridge binary that wraps commonplace-sync for .beads/issues.jsonl files. Auto-discovers repo, creates .cbd.json, supports --push-only/--pull-only/--force-push.","dependencies":[{"issue_id":"CP-qge2","depends_on_id":"CP-6kpq","type":"blocks","created_at":"2026-01-05T06:44:25.329308715Z","created_by":"jes"}]}
{"id":"CP-qmk","title":"Fix P1: Preserve schema deletions when pushing updates (PR #7)","description":"From PR #7 Codex review: When pushing schema updates, deletions are not being preserved. The code always posts an edit built by create_yjs_map_update but this may not handle entry deletions properly. Need to investigate and fix.","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-26T23:24:21.270524-08:00","updated_at":"2025-12-27T00:14:06.786038-08:00","closed_at":"2025-12-27T00:14:06.786038-08:00","close_reason":"Preserve schema deletions implemented. Added state field to HEAD response, client now applies server CRDT state before making changes so deletions create proper tombstones. Merged in PR #9."}
{"id":"CP-qt6z","title":"Implement flock-aware sync spec","description":"Summary: Implement the flock-aware sync protocol described in docs/flock-aware-sync-spec.md so inbound writes never overwrite local edits and inode tracking prevents lost updates/deletions.\\n\\nFiles to modify:\\n- docs/flock-aware-sync-spec.md (reference spec)\\n- src/sync/state.rs\\n- src/sync/watcher.rs\\n- src/sync/file_sync.rs\\n- src/sync/dir_sync.rs\\n- src/sync/sse.rs\\n- tests (add regression coverage for flock gating and pending inbound/outbound)\\n\\nImplementation steps:\\n1. Add per-path state (pending_outbound, pending_inbound, inode) to track uploads and queued server writes.\\n2. Gate inbound writes on pending_outbound ancestry; queue pending_inbound until the server update includes local edits.\\n3. Use flock (LOCK_EX/LOCK_NB) to detect active agents and delay atomic renames until edits are uploaded and merged.\\n4. Integrate inode tracking/shadow links so writes from old inodes are merged instead of lost.\\n5. Add tests that cover: local edit during inbound, deletion staying deleted, and atomic replace with flocked editor.\\n\\nExample:\\nBefore: server update overwrites local edit or resurrects delete.\\nAfter: server update waits/merges so local edits are preserved and deletes stay deleted.\\n","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-07T23:28:25.38938468Z","created_by":"jes","updated_at":"2026-01-08T07:18:17.137624423Z","closed_at":"2026-01-08T07:18:17.137624423Z","close_reason":"Implemented flock-aware sync with ancestry checking, flock coordination, and integration tests. Includes bug fixes for queued inbound writes."}
{"id":"CP-qyj","title":"TypeScript support for sandboxed evaluator","description":"Extend the JS sandbox evaluator to support TypeScript. This could mean:\n- Transpiling TS → JS before evaluation\n- Supporting .ts file extensions in sandbox\n- Type definitions for the sandbox API (dependencies, output documents, events)\n\nThis makes the sandbox more ergonomic for larger/complex reactive transforms.","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.488271-08:00","updated_at":"2025-12-28T23:53:18.488271-08:00","labels":["future-work"],"dependencies":[{"issue_id":"CP-qyj","depends_on_id":"CP-egb","type":"blocks","created_at":"2025-12-28T23:53:18.489746-08:00","created_by":"daemon"}]}
{"id":"CP-r2a","title":"Fix sync race condition: upload_task sends stale content during B-\u003eA sync","description":"When a server edit arrives via SSE, the handle_server_edit function fetches HEAD and writes to the local file. However, the file watcher can trigger upload_task with stale file content before the write completes, causing the old content to be synced back to the server.\n\nRoot cause: Echo detection relies on comparing file content to last_written_content, but there's a window between SSE notification and file write where upload_task can read stale content.\n\nPossible fixes:\n1. Add a flag to pause upload_task during server writes\n2. Use file modification timestamp comparison\n3. Add sequence numbers to track edit origin","design":"## Extended Barrier Pattern - REVISED AFTER CODEX REVIEW\n\n### Codex-Identified Issues:\n\n**CRITICAL: Partial writes can still trigger uploads**\nIf watcher fires during our write, content differs from pending, we upload partial/corrupted content. FIX: Don't immediately upload on mismatch - retry/re-read until content stabilizes or matches pending.\n\n**HIGH: Multiple server edits clobber pending fields**\nIf handle_server_edit runs while barrier is up, it overwrites pending_write_*, causing misclassification when first write's watcher event arrives. FIX: Use generation token (monotonic write_id) so barrier maps to exact write.\n\n**HIGH: Upload with stale parent_cid may fail**\nServer's replace endpoint may reject if parent doesn't match HEAD. FIX: Refresh HEAD before upload, or use CRDT edit endpoint for merges.\n\n**MEDIUM: Window between re-check and barrier set**\nLocal edit can slip in between re-check and write_in_progress=true. FIX: Do both atomically under write lock.\n\n**MEDIUM: Read→drop→write lock pattern is risky**\nState can change between drop(read) and acquire(write). FIX: Re-check under write lock, or use single write lock.\n\n**LOW: Watcher never fires leaves barrier stuck**\nlast_written_cid never updates, next upload uses stale parent. FIX: Timeout/fallback to finalize barrier.\n\n---\n\n### Improved Design: Token-Based Barrier\n\n```rust\nstruct SyncState {\n    last_written_cid: Option\u003cString\u003e,\n    last_written_content: String,\n    // Token-based barrier:\n    current_write_id: u64,  // Monotonic counter\n    pending_write: Option\u003cPendingWrite\u003e,\n}\n\nstruct PendingWrite {\n    write_id: u64,\n    content: String,\n    cid: String,\n    started_at: Instant,\n}\n```\n\n**handle_server_edit:**\n1. Acquire write lock\n2. If pending_write exists and not timed out, queue/skip this edit\n3. Increment current_write_id\n4. Set pending_write = Some(PendingWrite { write_id, content, cid, started_at })\n5. Release lock\n6. Write file\n7. Do NOT clear barrier (upload_task does it)\n\n**upload_task:**\n1. Read file content\n2. Acquire write lock (not read!)\n3. If pending_write exists:\n   a. If content == pending.content AND file stable (re-read matches):\n      - Clear pending, update last_written_*, done (echo)\n   b. If content != pending.content:\n      - Re-read file after short delay (50ms)\n      - If still differs after N retries: user edited, clear pending, upload\n   c. If pending.started_at \u003e 30s ago: timeout, clear pending\n4. Normal echo detection if no pending\n\n**Key improvements:**\n- Retry on mismatch instead of immediate upload (avoids partial writes)\n- Token prevents clobbering from concurrent server edits\n- Single write lock avoids ABA bugs\n- Timeout prevents stuck barrier\n- Refresh HEAD before upload on conflict path","status":"closed","priority":2,"issue_type":"bug","created_at":"2025-12-29T16:02:47.797530633Z","created_by":"jes","updated_at":"2025-12-29T20:50:11.443695514Z","closed_at":"2025-12-29T20:50:11.443695514Z","close_reason":"Token-based write barrier implemented to fix sync race condition. Prevents upload_task from sending stale content during server-to-local sync. 13+ codex review iterations, all P1 issues fixed. Merged in PR #23."}
{"id":"CP-raid","title":"Duplicate deliveries in file-based IO (bartleby-style)","description":"Summary: In bartleby-style file read/write patterns (file-based input/output), messages sometimes get delivered twice; likely caused by duplicate watcher events or missing dedupe on upload.\n\nFiles to modify:\n- src/sync/watcher.rs\n- src/sync/file_sync.rs\n- src/sync/state.rs\n- tests (add a file-based IO dedupe regression test)\n\nImplementation steps:\n1. Reproduce with a file-based input/output pipeline (write to input file, observe output consumer) and capture when duplicates occur.\n2. Inspect watcher event handling (IN_MODIFY vs IN_CLOSE_WRITE) and upload batching/debouncing logic to identify double-send triggers.\n3. Add dedupe safeguards (e.g., ignore duplicate content hashes within a short window, or ensure only close-write triggers upload).\n4. Update state tracking to persist last-sent hash/commit per file to prevent re-sends.\n5. Add a regression test that writes a single update and asserts exactly one delivery.\n\nExample:\nBefore: Writing once to input file results in two downstream deliveries.\nAfter: Each write yields exactly one delivery.\n","notes":"Root cause was CP-nvc5 (missing inode tracking in directory sync mode). Now fixed - inode tracking enabled in run_directory_mode and run_exec_mode.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-06T03:50:29.132906948Z","created_by":"jes","updated_at":"2026-01-07T22:29:47.077064581Z","closed_at":"2026-01-07T22:29:47.077072492Z","dependencies":[{"issue_id":"CP-raid","depends_on_id":"CP-n5mj","type":"blocks","created_at":"2026-01-06T06:37:21.257315139Z","created_by":"jes"},{"issue_id":"CP-raid","depends_on_id":"CP-nvc5","type":"blocks","created_at":"2026-01-07T22:09:24.413670409Z","created_by":"jes"}],"comments":[{"id":22,"issue_id":"CP-raid","author":"jes","text":"Duplicates still occurring on 2026-01-07 per bartleby history.jsonl (entries 37-38, 47-48)","created_at":"2026-01-07T21:31:48Z"}]}
{"id":"CP-rh2f","title":"SDK OutputHandleImpl.set() uses Y.Text for JSON/JSONL but server expects Y.Map/Y.Array","description":"Codex review found: OutputHandleImpl.set() always edits Y.Text 'content' for all output types. But JSON documents use Y.Map and JSONL uses Y.Array on server. This mismatch means JSON/JSONL outputs may not update correctly.\n\nHowever, filter-open IS producing output (13 lines in commonplace-issues.open.jsonl), so either:\n1. File sync is converting the text content to proper format\n2. The server reconciles text updates somehow\n3. Initial write works differently than updates\n\nNeeds investigation to confirm actual behavior and fix if needed.\n\nFile: workspace/sdk/mod.ts:289-316","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-07T03:10:32.447429803Z","created_by":"jes","updated_at":"2026-01-07T03:28:35.311231059Z","closed_at":"2026-01-07T03:28:35.311231059Z","close_reason":"Fixed SDK OutputHandleImpl to use correct Yjs types: Y.Map for JSON objects, Y.Array for JSON arrays and JSONL. The writeYjsContent() function now dynamically selects the type based on content, matching server behavior."}
{"id":"CP-rs3","title":"File copy in sync directory triggers document fork","description":"When a new file appears in a synced directory with content that exactly matches another file already synced by the same process, automatically fork the original document rather than creating an unrelated new document. Detection: pure content hash matching against all currently synced files.","notes":"PR #47 created. Codex review requested. P2 limitation filed as CP-og0 for binary files.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:58:58.555594612Z","created_by":"jes","updated_at":"2025-12-30T20:22:08.593492297Z","closed_at":"2025-12-30T20:22:08.593492297Z","close_reason":"Merged PR #47 - file copy triggers document fork via content hash matching"}
{"id":"CP-s3zg","title":"Audit HTTP API and ensure full MQTT coverage","description":"Before refactoring sync to MQTT (CP-o7h0), audit the HTTP API to ensure all operations are available over MQTT.\n\nCurrent HTTP endpoints to audit:\n- POST /docs - Create document\n- GET /docs/{id} - Get content\n- DELETE /docs/{id} - Delete document\n- GET /docs/{id}/info - Get metadata\n- GET /docs/{id}/head - Get HEAD (cid, content, Yjs state)\n- POST /docs/{id}/commit - Persist Yjs update\n- POST /docs/{id}/edit - Send Yjs update\n- POST /docs/{id}/replace - Replace content with diff\n- POST /docs/{id}/fork - Fork document\n- GET /sse/docs/{id} - SSE subscription (replace with MQTT topic)\n\nFor each, ensure there's an equivalent MQTT topic/message pattern:\n- Request/response patterns (use reply-to topics)\n- Pub/sub for document changes\n- Wildcard subscriptions for tree-based watching\n\nThis audit should inform the MQTT refactor design.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-09T07:00:24.516868018Z","created_by":"jes","updated_at":"2026-01-09T07:05:51.902956541Z","closed_at":"2026-01-09T07:05:51.902956541Z","close_reason":"Audit complete. Created 9 beads for missing MQTT coverage: CP-g9e8 (delete), CP-1isz (get content), CP-mg8x (info), CP-mxt2 (replace), CP-6ke7 (fork), CP-ef0e (ancestry), CP-2cql (fs-root), CP-6o2m (path-based), CP-eiyx (wildcard subscriptions - P1 blocker)"}
{"id":"CP-se0","title":"One-time scheduled events (at-style)","description":"Schedule events to fire at a specific point in the future. Unlike cron (recurring), these are one-shot:\n- Reminders\n- Delayed actions\n- Future-dated triggers\n- Timeout/deadline events\n\nCould share infrastructure with cron scheduling but with single-fire semantics.","design":"OPEN QUESTIONS for implementation:\n1. How to persist scheduled events across restarts?\n2. What happens if target path doesn't exist when event fires?\n3. Should there be a 'list scheduled events' API?\n4. Can events be cancelled before they fire?\n5. What precision - seconds, milliseconds, or just minutes?\n6. Same storage and service questions as CP-eyi","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.644504-08:00","updated_at":"2025-12-30T01:44:47.476156216Z","labels":["future-work"],"dependencies":[{"issue_id":"CP-se0","depends_on_id":"CP-eyi","type":"related","created_at":"2025-12-28T23:53:29.351623-08:00","created_by":"daemon"}]}
{"id":"CP-sgme","title":"SDK should provide JS-native types based on output file extension","description":"Currently the SDK gives scripts plain text strings and expects plain text output. Instead:\n\n1. Input: When reading documents, SDK should parse based on file extension:\n   - .json → parsed JSON object\n   - .jsonl → array of parsed JSON objects (or iterator)\n   - .txt/.md → string (current behavior)\n\n2. Output: When writing via cp.output.set(), SDK should:\n   - Read output extension from __processes.json 'output' field\n   - Automatically serialize JS objects to appropriate format\n   - .json → JSON.stringify\n   - .jsonl → join with newlines after JSON.stringify each item\n   - .txt → string as-is\n\nThis makes evaluate scripts more ergonomic - work with native JS types instead of manual parsing/serializing.","design":"API approach: Make get()/set() return/accept unknown types. Content type detected from file extension (.json→object, .jsonl→array, .txt/.md→string). Breaking change but SDK is new. Add parseContent/serializeContent utilities.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-07T01:45:14.942480482Z","created_by":"jes","updated_at":"2026-01-07T01:52:23.848852673Z","closed_at":"2026-01-07T01:52:23.848852673Z","close_reason":"Implemented typed content based on file extension. SDK now auto-parses .json→object, .jsonl→array and auto-serializes on output. Scripts work with native JS types instead of strings."}
{"id":"CP-sz8","title":"Refactor document.rs: Extract ContentType to dedicated module","description":"document.rs has ContentType enum with MIME conversion, default content generation, and detection logic. Extract to `src/content_type.rs` to be shared between document.rs and sync/ modules (which has partial duplication).","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-30T00:34:51.455397-08:00","updated_at":"2025-12-30T16:42:58.50460762Z","closed_at":"2025-12-30T16:42:58.50460762Z","close_reason":"Closed"}
{"id":"CP-t1e","title":"Subdirectory schema updates create feedback loop","description":"After fixing CP-13l (path resolution), the sync still enters a loop writing .commonplace.json files repeatedly to both workspace/ and workspace/bartleby/.\n\nThe issue is that when subdirectories are migrated to separate documents, SSE events for those subdirectory documents trigger schema writes, which trigger more events.\n\nThe PR #81 fix only skips .commonplace.json in the directory watcher, but SSE events from subdirectory document updates still cause writes.\n\nNeed to add similar skip logic for SSE-triggered schema updates, or deduplicate based on content.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-02T00:41:51.878675146Z","created_by":"jes","updated_at":"2026-01-02T01:03:52.848109258Z","closed_at":"2026-01-02T01:03:52.848109258Z","close_reason":"Fixed by preserving node-backed directory references during directory scanning. When a subdirectory has an existing node_id in .commonplace.json, the scanner now creates a node-backed reference (entries: None, node_id: Some) instead of inline entries, preventing the reconciler from generating new UUIDs on every sync."}
{"id":"CP-tale","title":"Implement inode-branch sync to preserve writes from replaced inodes","description":"Summary: Implement the hardlink shadow strategy from docs/commonplace-hardlink-sync-spec.md so non-atomic writers to old inodes are preserved and merged instead of lost on atomic replace.\n\nFiles to modify:\n- src/sync/sse.rs\n- src/sync/watcher.rs\n- src/sync/file_sync.rs\n- src/sync/state.rs\n- src/sync/state_file.rs\n- src/bin/sync.rs (config/CLI for shadow dir)\n- docs/commonplace-hardlink-sync-spec.md\n\nImplementation steps:\n1. Add inode tracking keyed by (st_dev, st_ino) with commit_id, shadow_path, shadowed_at, last_write; reset it on startup.\n2. On server update for path P: open P, fstat, link /proc/self/fd/{fd} to shadow_dir/{devHex}-{inoHex}, update inode_state, then atomic write temp+rename into P and create inode_state for the new inode.\n3. Watch the shadow directory (not individual files) for IN_MODIFY/IN_CLOSE_WRITE; read shadow path, create a Yjs update against inode_state.commit_id, merge into HEAD, and update commit_id and last_write.\n4. Distinguish atomic vs non-atomic local writes on primary path: same inode = non-atomic diff against inode_state.commit_id; inode change = treat as atomic replace and create inode_state for new inode.\n5. Implement GC: remove shadow links after last_write \u003e IDLE_TIMEOUT and shadowed_at \u003e MIN_SHADOW_LIFETIME; delete inode_state entry; on IN_Q_OVERFLOW, rescan watched paths.\n6. Enforce same-filesystem requirement for shadow_dir; default to /tmp/commonplace-sync/hardlinks; if the synced path is on a different filesystem, require user-configured shadow_dir on that volume.\n\nExample:\nBefore: server update temp+rename replaces inode; a long-lived writer appends to the old inode and those edits disappear.\nAfter: the old inode is hardlinked under shadow_dir and watched; its writes create branch commits that merge into HEAD.\n","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-04T10:52:20.006512646Z","created_by":"jes","updated_at":"2026-01-05T02:55:44.234501626Z","closed_at":"2026-01-05T02:55:44.234501626Z","close_reason":"Implemented inode-branch sync with shadow hardlinks per spec. Core functionality working: atomic writes create shadow hardlinks, shadow directory is watched, writes to old inodes are detected and merged via CRDT. Tested with 4 integration tests. GC can be added as follow-up."}
{"id":"CP-tmo","title":"Orchestrator should watch for fs-root schema changes","description":"When the server's fs-root schema changes (e.g., via /replace), the orchestrator should detect this and update sandboxes accordingly. Currently requires restart.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-01T19:41:28.363627394Z","created_by":"jes","updated_at":"2026-01-03T08:20:21.159846353Z","closed_at":"2026-01-03T08:20:21.159846353Z","close_reason":"Orchestrator now watches all schema documents recursively via /documents/stream SSE endpoint. Changes to any nested directory schema immediately trigger re-discovery."}
{"id":"CP-txg0","title":"Review inotify hardlink shadow code for correctness/perf","description":"Summary: Do a focused code review of the inotify hardlink shadow implementation (inode tracking + shadow dir) to identify correctness bugs, race conditions, or performance issues.\n\nFiles to review:\n- src/sync/sse.rs\n- src/sync/state.rs\n- src/sync/watcher.rs\n- src/bin/sync.rs\n\nReview steps:\n1. Verify inode tracking lifecycle (create, shadow, update, GC) is race-safe under concurrent writes and server updates.\n2. Check inotify watch setup and event handling for shadow dir vs primary path; confirm no missed events or infinite loops.\n3. Validate hardlink creation via /proc/self/fd and fallback paths, including error handling and TOCTOU exposure.\n4. Inspect atomic write path for temp file placement, rename semantics, and inode tracking updates.\n5. Assess performance risks (extra file I/O, hash/diff frequency, watch fanout, GC cadence).\n\nExample focus questions:\n- Can shadow links leak or accumulate under heavy churn?\n- Are old inode writes always merged against the correct commit_id?\n- Does shadow dir creation on every write cause contention?\n","notes":"## Review Completed\n\n### Critical (P2)\n1. **Shadow GC never called** - InodeTracker::gc() exists but is never invoked. Shadow hardlinks and state entries accumulate indefinitely. Fix: add periodic GC task.\n2. **tracker.shadow() return ignored** - sse.rs:817 ignores return value, silent failure if GC races.\n\n### Medium (P3)\n3. **No tracking when commit_id is None** - sse.rs:861-863 skips tracking for empty commits.\n4. **Extra syscalls** - create_dir_all on every write, multiple lock acquisitions.\n\n### Low (P4)\n5. **Unbounded debounce map** - shadow_watcher pending_events could grow.\n\n### Recommendation\nCreate follow-up beads for P2 fixes. P3/P4 can be addressed opportunistically.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T08:47:59.409692272Z","created_by":"jes","updated_at":"2026-01-05T08:57:37.039200038Z","closed_at":"2026-01-05T08:57:37.039200038Z","close_reason":"Review complete. Filed 3 bugs: CP-4r4d (P2 GC never called), CP-5wwk (P2 shadow() return ignored), CP-cr47 (P3 no tracking when commit_id None)"}
{"id":"CP-u37g","title":"commonplace-ps should not truncate CWD paths","description":"Summary: Output from `commonplace ps` truncates long CWD paths with \"...\", which hides the actual sandbox directory and makes it hard to identify processes.\n\nFiles to modify:\n- src/orchestrator/status.rs\n- src/bin/ps.rs (or wherever the CLI output formatting lives)\n\nImplementation steps:\n1. Identify the formatting code that truncates CWD paths in `commonplace ps`.\n2. Provide a full-path display option by default (or add a `--full` flag and make it the default for tty output).\n3. Ensure columns still align; if needed, wrap or allow a wider column for CWD.\n4. Add a test or snapshot that asserts full CWD output for long paths.\n\nExample:\nBefore: `...-8ede39a7-e0b3-48ef-99a0-3cd9a2ae589d`\nAfter: `/tmp/sandbox/.../workspace-8ede39a7-e0b3-48ef-99a0-3cd9a2ae589d`\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-05T02:08:17.480679729Z","created_by":"jes","updated_at":"2026-01-05T03:41:04.198495158Z","closed_at":"2026-01-05T03:41:04.198495158Z","close_reason":"Removed CWD truncation - now shows full sandbox paths"}
{"id":"CP-uf2k","title":"Make --graph and --decorate defaults with opt-out","description":"Change commonplace-log defaults:\n- --graph on by default, --no-graph to disable\n- --decorate on by default, --no-decorate to disable\n- --oneline disables graph mode","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T21:11:12.51658411Z","created_by":"jes","updated_at":"2026-01-03T21:11:34.123331745Z","closed_at":"2026-01-03T21:11:34.123331745Z","close_reason":"Implemented --graph and --decorate as defaults with --no-graph and --no-decorate opt-outs"}
{"id":"CP-uj2","title":"Represent directory trees as Yjs JSON (Y.Map) instead of text JSON","description":"Currently, the fs-root document uses TEXT content type with JSON stored as a text string. This was a workaround because the edit system (diff.rs, replay.rs) uses TEXT-based Yjs updates (Y.Text), but DocumentNode for JSON type uses Y.Map internally.\n\nThe proper solution would be to use native Yjs JSON structure (Y.Map) for directory schemas, which would enable:\n- Proper CRDT merging of concurrent schema changes\n- More efficient updates (only changed entries, not full document replacement)\n- Better conflict resolution for concurrent file additions/deletions","design":"Implemented Y.Map support:\n\n1. replay.rs: Extended get_content_and_state_at_commit to support JSON content type by initializing Y.Map root and using map.to_json() for extraction.\n\n2. sync.rs: Added create_yjs_map_update() and json_value_to_any() helper to convert JSON strings to Y.Map updates. Updated push_schema_to_server to use Y.Map updates for initial schema push.\n\nThis enables proper CRDT merging of concurrent schema changes and more efficient updates (only changed entries, not full document replacement).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-26T17:04:59.967959-08:00","updated_at":"2025-12-26T18:01:42.374357-08:00","closed_at":"2025-12-26T18:01:42.374357-08:00","close_reason":"Added Y.Map support for directory schemas: replay.rs now supports JSON content type, sync.rs uses Y.Map updates for initial schema push. Merged in PR #6.","labels":["architecture","sync","yjs"]}
{"id":"CP-v9r","title":"Sandbox sync uses wrong identifiers for nested node-backed dirs - blocks acceptance","description":"When sandbox sync syncs a directory containing node-backed subdirectories, it constructs wrong document identifiers.\n\nObserved:\n- Sandbox sync tries to connect to: 0e1967af-...:bartleby/output.txt\n- This returns 404 Not Found\n- The actual output.txt has its own node_id: 12504d60-...\n\nExpected:\n- Sandbox sync should resolve the bartleby directory schema first\n- Then find output.txt's actual node_id (12504d60-...)\n- Then sync that document\n\nThe sync is using directory-node-id:relative-path format instead of looking up the actual document node_ids from the subdirectory schema.\n\nThis blocks the acceptance criteria requiring bartleby to sync the full workspace tree.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T06:11:33.596118234Z","created_by":"jes","updated_at":"2026-01-02T06:29:26.741953764Z","closed_at":"2026-01-02T06:29:26.741961394Z"}
{"id":"CP-vhp6","title":"P1: cbd head fetch failure silently truncates local data","description":"In cbd.rs around lines 637-645, when fetching head from server fails, the code falls back to local data but may have already modified/truncated it. The fetch_head_state function should not modify local state until server response is confirmed.\n\nLocation: src/cbd.rs:637-645\nFound by: codex review","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T09:09:49.343784378Z","created_by":"jes","updated_at":"2026-01-05T19:51:02.502970461Z","closed_at":"2026-01-05T19:51:02.502970461Z","close_reason":"Fixed: append_issue now fails on non-404 errors instead of silently truncating to empty content"}
{"id":"CP-vqs","title":"Sandbox sync corrupts file content - blocks acceptance","description":"When syncing new files to sandboxes that are nested subdirectories (like bartleby/ inside workspace), the content gets corrupted.\n\nTest case:\n1. Start server, sync, orchestrator as per acceptance criteria\n2. Create file: echo -n 'note' \u003e workspace/bartleby/test-note.txt\n3. Wait 5 seconds\n4. Check sandbox: cat /tmp/commonplace-sandbox-*/bartleby/test-note.txt\n\nExpected: 'note' (4 bytes: 6e6f7465)\nActual: Binary garbage (3 bytes: 9e8b5e)\n\nServer has correct content. Workspace sync works. Only sandbox sync for node-backed subdirectories corrupts content.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T08:19:40.294061839Z","created_by":"jes","updated_at":"2026-01-02T08:39:25.355282132Z","closed_at":"2026-01-02T08:39:25.355282132Z","close_reason":"Fixed - added looks_like_base64_binary() check to prevent misinterpreting short text as base64 binary","comments":[{"id":18,"issue_id":"CP-vqs","author":"jes","text":"Likely root cause: initial server-\u003elocal write in src/sync/dir_sync.rs:554-587 tries to base64-decode text content to detect binary. For a text file containing \"note\", STANDARD.decode(\"note\") succeeds and yields bytes 9e8b5e (confirmed via python3), which is then treated as binary (is_binary_content) and written, matching the reported 3-byte garbage. This path runs when creating new local files from server (sandbox starts empty). Fix likely requires avoiding base64 decode unless server explicitly marks content as base64/binary, or using metadata to decide.","created_at":"2026-01-02T08:23:38Z"}]}
{"id":"CP-vqs4","title":"Sync should use shared lock (LOCK_SH) when reading files","description":"When sync reads a file to compute diffs or upload content, it should acquire LOCK_SH (shared/read lock) to signal to agents that a read is in progress. This prevents agents from starting writes while sync is mid-read, ensuring consistent content is captured. Complements the flock-aware sync spec where sync uses LOCK_EX for writes.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-08T01:18:01.475757635Z","created_by":"jes","updated_at":"2026-01-08T17:34:13.509925696Z","closed_at":"2026-01-08T17:34:13.509925696Z","close_reason":"Added try_flock_shared() and integrated into file_watcher_task for read coordination with agents","dependencies":[{"issue_id":"CP-vqs4","depends_on_id":"CP-qt6z","type":"blocks","created_at":"2026-01-08T01:18:55.92740908Z","created_by":"jes"}]}
{"id":"CP-vrnb","title":"Add --decorate flag to commonplace-log","description":"Add git-style --decorate flag to commonplace-log that shows ref-like decorations next to commits. For commonplace this would show:\n- (HEAD) marker on the most recent commit\n- Possibly file path on first line\n\nUsage: commonplace log --decorate path/to/file.txt","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T20:59:59.765451441Z","created_by":"jes","updated_at":"2026-01-03T21:01:40.220736743Z","closed_at":"2026-01-03T21:01:40.220736743Z","close_reason":"Added --decorate flag showing cyan (HEAD) marker on newest commit in all output modes (full, oneline, graph)"}
{"id":"CP-vyd6","title":"cbd: add create/update flags for full field set","description":"Summary: Expand cbd create/update to accept the full beads field set plus description from --body-file/stdin.\n\nFiles to modify:\n- src/cbd.rs\n- tests (new CLI parsing tests)\n\nImplementation steps:\n1. Add clap flags for create: --title, --id, --type, --priority, --description, --body-file, --assignee, --labels, --parent, --deps, --due, --defer, --estimate, --acceptance, --design, --notes, --external-ref.\n2. Add matching update flags for the same fields and ensure updates only change fields that are explicitly set.\n3. Parse --labels as comma-separated values and --deps in beads format (type:id or id defaults to blocks), preserving existing dependencies when not supplied.\n4. Support --body-file - to read description from stdin.\n5. Add tests that parse CLI args into Issue updates and verify fields are set/unchanged as expected.\n\nExample:\ncommonplace-bd create \"Fix importer\" --type bug --priority 1 --assignee jes --labels sync,urgent --deps blocks:CP-123 --body-file -\n","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T07:02:37.489749137Z","created_by":"jes","updated_at":"2026-01-05T08:19:58.136660047Z","closed_at":"2026-01-05T08:19:58.136660047Z","close_reason":"Added full field set to create/update: body-file, id, assignee, labels, parent, deps, due, defer, estimate, acceptance, design, notes, external-ref","dependencies":[{"issue_id":"CP-vyd6","depends_on_id":"CP-1evh","type":"blocks","created_at":"2026-01-05T07:02:37.49395258Z","created_by":"jes"},{"issue_id":"CP-vyd6","depends_on_id":"CP-1j5m","type":"discovered-from","created_at":"2026-01-05T07:02:37.497204178Z","created_by":"jes"}]}
{"id":"CP-w2v","title":"Directory JSON as hidden file inside checkout","description":"Synced directory JSON should be a hidden file inside the checked out directory, not outside it. Sync tool should handle this intelligently (avoid syncing the hidden file itself, proper conflict handling, etc.).","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:54:00.14442659Z","created_by":"jes","updated_at":"2025-12-30T18:10:05.226276237Z","closed_at":"2025-12-30T18:10:05.226276237Z","close_reason":"Already implemented - schema stored as .commonplace.json inside checkout, ignored in scanning and watcher"}
{"id":"CP-w2xd","title":"Implement hardlink shadow strategy from commonplace-hardlink-sync-spec.md","description":"Summary: Implement the hardlink shadow sync strategy described in docs/commonplace-hardlink-sync-spec.md so writes to replaced inodes are preserved and merged instead of lost.\n\nFiles to modify:\n- src/sync/sse.rs\n- src/sync/watcher.rs\n- src/sync/file_sync.rs\n- src/sync/state.rs\n- src/sync/state_file.rs\n- src/bin/sync.rs\n- docs/commonplace-hardlink-sync-spec.md\n\nImplementation steps:\n1. Add inode_state keyed by (st_dev, st_ino) with commit_id, shadow_path, shadowed_at, last_write; reset it on startup and ensure the shadow dir is on the same filesystem.\n2. On server update for path P: open P, fstat to get inode, link /proc/self/fd/{fd} to shadow_dir/{devHex}-{inoHex}, update inode_state for the old inode, then atomic write temp+rename into P and create inode_state for the new inode.\n3. Watch the shadow directory for IN_MODIFY/IN_CLOSE_WRITE; read the shadow path, create a Yjs update against inode_state.commit_id, merge into HEAD, and update commit_id and last_write.\n4. On primary path writes, detect same inode vs inode change to separate non-atomic vs atomic writes; diff against the correct commit_id and update inode_state.\n5. Implement GC: remove shadow links after idle timeout and minimum shadow lifetime, delete inode_state entry, and rescan on IN_Q_OVERFLOW.\n6. Add tests for atomic replace with long-lived writer (old inode updates preserved), same-filesystem validation for shadow dir, and GC cleanup behavior.\n\nExample:\nBefore: server update replaces inode; writes to the old fd are lost.\nAfter: old inode is hardlinked in shadow_dir and its writes produce mergeable commits.\n","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-05T02:20:21.390276888Z","created_by":"jes","updated_at":"2026-01-05T04:09:13.636563917Z","closed_at":"2026-01-05T04:09:13.636563917Z","close_reason":"Duplicate of CP-tale - already implemented inode shadow sync"}
{"id":"CP-w5sw","title":"WebSocket integration tests","description":"Add integration tests for WebSocket endpoint.\n\nRequires: CP-59h Phase 1 (y-websocket core) - DONE\n\n## Test cases\n\n1. Single client connect and sync\n   - Connect to /ws/docs/{id}\n   - Verify initial SyncStep1/SyncStep2\n   - Verify document state received\n\n2. Two clients bidirectional sync\n   - Client A sends update\n   - Verify Client B receives update\n   - Client B sends update\n   - Verify Client A receives update\n\n3. Reconnection with state recovery\n   - Client connects, receives state\n   - Client disconnects\n   - Document is modified via HTTP\n   - Client reconnects\n   - Verify client receives missed updates\n\n4. Subprotocol negotiation\n   - Connect with y-websocket protocol\n   - Connect with commonplace protocol\n   - Verify correct protocol selected\n\n## Files to create\n\n- tests/ws_tests.rs\n\n## Dependencies\n\nMay need tokio-tungstenite for test client.","status":"closed","priority":3,"issue_type":"task","created_at":"2026-01-04T02:01:58.469147163Z","created_by":"jes","updated_at":"2026-01-04T02:51:19.951189842Z","closed_at":"2026-01-04T02:51:19.951189842Z","close_reason":"Added 8 integration tests for WebSocket endpoint: connect/sync, bidirectional sync, reconnection, subprotocol negotiation. Fixed bug with empty state vector encoding.","dependencies":[{"issue_id":"CP-w5sw","depends_on_id":"CP-59h","type":"discovered-from","created_at":"2026-01-04T02:02:24.749750465Z","created_by":"jes"}]}
{"id":"CP-w925","title":"Server ContentType::from_mime doesn't recognize text/typescript and other text/* types","description":"ContentType::from_mime() only handles:\n- application/json\n- application/x-ndjson  \n- application/xml, text/xml\n- text/plain\n\nBut sync sends text/typescript for .ts files, text/x-rust for .rs files, etc.\nThese should all map to ContentType::Text.\n\nImpact: .ts files get stored with wrong content type, causing replace endpoint to fail with 'JSON parse error'.\n\nFix: Add catch-all for text/* MIME types to map to ContentType::Text.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T02:10:31.81572127Z","created_by":"jes","updated_at":"2026-01-07T02:22:36.764757592Z","closed_at":"2026-01-07T02:22:36.764757592Z","close_reason":"Added text/* catch-all to ContentType::from_mime(). All text/* MIME types now map to ContentType::Text. Merged in PR #108."}
{"id":"CP-wh1l","title":"Yjs state from Rust yrs not compatible with JS yjs library","description":"When applying Yjs state (from head.state) generated by Rust yrs crate to JavaScript yjs library:\n- Y.applyUpdate() succeeds without error\n- doc.share.entries() shows 'content: AbstractType' instead of 'content: Text'\n- getText('content').toString() returns empty string\n\nWorkaround: SDK now uses head.content directly instead of Yjs state for initial load.\n\nRoot cause: Unknown - may be version mismatch, encoding difference, or yrs/yjs protocol incompatibility.\n\nImpact: Real-time CRDT sync between Rust server and JS clients may not work correctly.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-07T01:56:31.290590813Z","created_by":"jes","updated_at":"2026-01-07T02:05:14.137624977Z","closed_at":"2026-01-07T02:05:14.137624977Z","close_reason":"Misdiagnosed - yrs/yjs ARE compatible. Real issue is SDK uses getText() for all files but JSONL uses Y.Array. See new issue for correct fix."}
{"id":"CP-woul","title":"Remove startup retry loop after MQTT refactor","description":"Once CP-o7h0 (MQTT subscriptions) is complete, remove the polling/retry workarounds in sync:\n\n1. Remove the retry loop in sync_schema() (dir_sync.rs:2089-2118) that polls 3x with 3s delays\n2. Remove the dynamic SSE task spawning added in CP-4w00 (no longer needed with wildcard subscriptions)\n3. Remove individual subdir_sse_task spawning at startup\n4. Simplify directory_sse_task or remove entirely\n\nThese workarounds exist because HTTP SSE requires per-document subscriptions. With MQTT wildcards, a single subscription covers the whole tree.","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-09T07:00:05.525019105Z","created_by":"jes","updated_at":"2026-01-09T07:00:05.525019105Z","dependencies":[{"issue_id":"CP-woul","depends_on_id":"CP-o7h0","type":"blocks","created_at":"2026-01-09T07:00:11.849292661Z","created_by":"jes"}]}
{"id":"CP-xdsc","title":"at_commit replay returns wrong state for some documents","description":"When fetching /docs/{id}/head?at_commit={cid}, the server sometimes returns the same Yjs state for different commits instead of replaying to the correct historical state.\n\nObserved: Commits 130-140 for output.txt all return identical state_hash despite having different commit IDs and timestamps. The content shows '/typing' for all of them.\n\nExpected: Each commit should return the document state AS IT WAS at that commit.\n\nThe changes API correctly lists distinct commits with different timestamps, but the replay mechanism isn't working correctly.\n\nThis breaks commonplace-log diff output since diffs between identical states are empty.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T22:03:35.198195708Z","created_by":"jes","updated_at":"2026-01-03T23:39:55.236438817Z","closed_at":"2026-01-03T23:39:55.236438817Z","close_reason":"Not a bug: at_commit requires documents in memory (via orchestrator/sync). The replay logic is correct - documents must be loaded before historical state can be reconstructed. Added debug logging in 0b6d6b3 for future troubleshooting."}
{"id":"CP-xuw","title":"Make .processes.json dynamically add/remove processes in running conductor","description":"The conductor should watch for changes to .processes.json files and dynamically start/stop processes without requiring a restart.\n\nCurrently .processes.json is only read at startup. We need:\n1. Watch for .processes.json changes via document subscription\n2. Start new processes when added to .processes.json\n3. Stop processes when removed from .processes.json\n4. Handle graceful restarts when command/args change","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-01T10:51:20.920681904Z","created_by":"jes","updated_at":"2026-01-01T11:53:36.875939089Z","closed_at":"2026-01-01T11:53:36.875939089Z","close_reason":"Fixed in PR #77. Added --watch-processes flag to orchestrator for dynamic process management. Processes are started/stopped based on document changes with periodic health checks for automatic restart.","comments":[{"id":14,"issue_id":"CP-xuw","author":"jes","text":"Investigation notes:\n\n**Current Architecture:**\n1. ProcessManager (manager.rs) - Handles core processes from orchestrator config file\n2. DiscoveredProcessManager (discovered_manager.rs) - Has machinery for .processes.json but not wired up\n\n**DiscoveredProcessManager already has:**\n- add_process() / remove_process() methods\n- spawn_process() / check_and_restart()\n- Tracks processes in HashMap with ManagedDiscoveredProcess\n\n**What's needed for dynamic updates:**\n1. Add method to watch .processes.json document via SSE\n2. On document change, parse new ProcessesConfig\n3. Diff current vs new config:\n   - Stop processes that were removed\n   - Start processes that were added  \n   - Restart processes where command/args changed\n4. Wire this into the orchestrator or create dedicated mode\n\n**Implementation approach:**\nAdd watch_processes_document() method to DiscoveredProcessManager that:\n- Subscribes to document SSE stream\n- Parses edits as ProcessesConfig\n- Calls reconcile_processes() to diff and update\n","created_at":"2026-01-01T11:43:13Z"}]}
{"id":"CP-y0v","title":"File creation sync fails - blocks acceptance C5/C6","description":"When creating a new file in workspace/bartleby/, the sync client tries to subscribe to SSE before creating the file on the server. This causes repeated 404 errors and the file never syncs to sandboxes.\n\nSteps to reproduce:\n1. echo 'note' \u003e workspace/bartleby/test-note.txt\n2. Wait 5+ seconds\n3. Check bartleby sandbox - file exists but is empty\n4. Check server - returns 404\n5. Check workspace sync logs - repeated 'SSE error: Invalid status code: 404 Not Found'\n\nExpected: File should be created on server and synced to sandbox\nActual: Sync client loops trying to subscribe to non-existent file","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-03T01:27:19.469011853Z","created_by":"jes","updated_at":"2026-01-03T01:53:38.677730662Z","closed_at":"2026-01-03T01:53:38.677730662Z","close_reason":"Fixed by generating UUIDs locally in scan_directory() instead of relying on server reconciliation"}
{"id":"CP-y43g","title":"Scope orchestrator lock to config and declared fs subtrees","description":"Summary: Replace the global /tmp/commonplace-orchestrator.lock with a lock keyed to the specific commonplace.json config and its declared fs subtrees so multiple orchestrators can run for different scopes.\n\nFiles to modify:\n- src/bin/orchestrator.rs (lockfile creation/validation)\n- src/orchestrator/config.rs (add explicit config field for managed subtrees)\n- docs/DEVELOPMENT.md or README.md (document new lock behavior)\n\nImplementation steps:\n1. Add config field that lists which subtrees of the commonplace filesystem the orchestrator should manage (e.g., [\"/workspace\", \"/teams/foo\"]).\n2. Compute a lockfile path derived from the config path or a hash of the config + subtree list (e.g., /tmp/commonplace-orchestrator-\u003chash\u003e.lock).\n3. On startup, acquire the scoped lock; refuse to start if another orchestrator owns the same scope.\n4. Ensure subtrees do not overlap between running orchestrators; if overlap detected, error with a clear message.\n\nExample:\n- Orchestrator A manages /workspace/team-a → lockfile A\n- Orchestrator B manages /workspace/team-b → lockfile B\n- Starting B when it overlaps A should error.","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-03T19:41:42.285986729Z","created_by":"jes","updated_at":"2026-01-04T00:51:27.414770096Z","closed_at":"2026-01-04T00:51:27.414770096Z","close_reason":"Scoped lock to config file path, multiple orchestrators can now run with different configs"}
{"id":"CP-y9l","title":"tmux ↔ file integration","description":"Bidirectional sync between tmux pane content and commonplace documents:\n- Capture tmux pane content to a document (scrollback, current view)\n- Send content from a document to a tmux pane (sendkeys)\n- Subscribe to pane output as a stream\n- Control tmux sessions/windows/panes via document commands\n\nEnables terminal-as-document patterns and terminal automation.","design":"OPEN QUESTIONS for implementation:\n1. Use tmux command-line or libtmux/tmux control mode?\n2. What's the document schema for pane content?\n3. How often to capture pane content (poll vs events)?\n4. How to identify target pane (session:window.pane)?\n5. Handle scrollback or just visible content?\n6. Security - limit which sessions can be controlled?","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-28T23:53:18.734354-08:00","updated_at":"2026-01-03T20:00:49.121841567Z","closed_at":"2026-01-03T20:00:49.121841567Z","close_reason":"Working","labels":["future-work"],"dependencies":[{"issue_id":"CP-y9l","depends_on_id":"CP-nno","type":"blocks","created_at":"2025-12-28T23:53:18.735182-08:00","created_by":"daemon"}]}
{"id":"CP-ylp","title":"Enforce mandatory file extensions in filesystem sync","description":"Update commonplace filesystem so that file extensions are mandatory. Only .json, .txt, .xml, .xhtml, and .bin files can be synced, and they must correspond to their Yjs implementations.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-28T21:56:43.205364505Z","created_by":"jes","updated_at":"2025-12-28T23:14:28.396705982Z","closed_at":"2025-12-28T23:14:28.396705982Z","close_reason":"Implemented mandatory file extension filtering for filesystem sync. Only .json, .txt, .xml, .xhtml, .bin, .md files are now synced. Added is_allowed_extension() function and filtering in scan_dir_recursive(), scan_files_recursive(), DirEvent::Created handler, and handle_schema_change(). Merged in PR #12."}
{"id":"CP-yq8","title":"Refactor sync.rs: Extract SSE subscription loop","description":"Extract SSE subscription handling from sync.rs into `src/sync/sse_client.rs`. This manages server event subscriptions, reconnection, and incoming edit processing.","status":"closed","priority":1,"issue_type":"chore","created_at":"2025-12-30T00:34:51.027152-08:00","updated_at":"2025-12-30T15:51:57.815913081Z","closed_at":"2025-12-30T15:51:57.815913081Z","close_reason":"Extracted SSE subscription loop to src/sync/sse.rs. Merged in PR #40.","dependencies":[{"issue_id":"CP-yq8","depends_on_id":"CP-jwf","type":"blocks","created_at":"2025-12-30T00:36:37.050903-08:00","created_by":"daemon"}]}
{"id":"CP-yw8","title":"Use PR_SET_PDEATHSIG in BOTH orchestrator and sync binaries","description":"When orchestrator and sync spawn child processes, use:\n\n```rust\nunsafe {\n    libc::prctl(libc::PR_SET_PDEATHSIG, libc::SIGKILL);\n}\n```\n\nThis ensures child processes automatically receive SIGKILL when their parent process dies, preventing orphaned processes.\n\nImplementation:\n- In orchestrator: set before spawning sandbox sync processes\n- In sync --sandbox: set before spawning the --exec command\n- Use pre_exec hook in Command::new() to set this before exec\n\nThis is Linux-specific. For cross-platform support, may need conditional compilation.\n\nRelated: CP-a0g (orphaned processes), CP-occ (sync self-cleanup)","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-02T19:20:42.927092195Z","created_by":"jes","updated_at":"2026-01-02T19:35:53.37633517Z","closed_at":"2026-01-02T19:35:53.37633517Z","close_reason":"Added PR_SET_PDEATHSIG to sync binary. PR #92 merged.","dependencies":[{"issue_id":"CP-yw8","depends_on_id":"CP-a0g","type":"relates-to","created_at":"2026-01-02T19:21:00.665641844Z","created_by":"daemon"},{"issue_id":"CP-yw8","depends_on_id":"CP-occ","type":"relates-to","created_at":"2026-01-02T19:21:00.694166033Z","created_by":"daemon"}],"comments":[{"id":19,"issue_id":"CP-yw8","author":"jes","text":"The full process chain requires PR_SET_PDEATHSIG at EACH level:\n\n1. orchestrator spawns sync → sync gets PDEATHSIG\n2. sync --sandbox spawns exec command → exec process gets PDEATHSIG\n\nWithout both, you get partial cleanup:\n- Only in orchestrator: sync dies but leaves exec orphaned\n- Only in sync: exec dies but sync becomes orphaned\n\nBoth binaries must set this in their pre_exec hooks.","created_at":"2026-01-02T19:21:51Z"}]}
{"id":"CP-yx4l","title":"P2: Schema deletions don't propagate - additive merge skips removals when files are deleted locally","description":"When files are deleted locally, push_schema_to_server now uses additive merge which won't remove keys from server schema. This means local deletions (e.g., from handle_file_deleted) won't propagate to other sync clients. Need to decide: use full replacement for deletion pushes or add explicit delete operation.","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T20:45:05.446587016Z","created_by":"jes","updated_at":"2026-01-06T21:47:16.270985102Z","closed_at":"2026-01-06T21:47:16.270985102Z","close_reason":"Implemented targeted schema deletions with nested path support. Added create_yjs_json_delete_key() for Yjs updates, delete_schema_entry() for HTTP calls, and detection of node-backed subdirectories. Base state now required to fail loud vs silent no-op. Merged in PR #104."}
{"id":"CP-z7t","title":"MCP server using commonplace JSON file for tool/resource definitions","description":"An MCP server that reads a specified commonplace JSON document and exposes its contents as MCP tools, resources, and prompts. The JSON document defines the MCP schema, and the server dynamically serves those definitions to MCP clients.","design":"OPEN QUESTIONS for implementation:\n1. What JSON schema should define tools? MCP-native schema or custom format?\n2. Should this dynamically reload when the document changes?\n3. How to handle tool implementations - call external commands, evaluate JS, or just return content?\n4. Should it support resources and prompts in addition to tools?\n5. How does this relate to CP-pgx (already implemented) - replace or complement it?","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-28T22:49:01.180475-08:00","updated_at":"2025-12-30T01:44:22.367660722Z","labels":["future-work"]}
{"id":"CP-zdy","title":"[blocks acceptance] New files in node-backed subdirs don't propagate to other sync clients","description":"When a new file is created in a sandbox that syncs with a node-backed subdirectory (like text-to-telegram), the file is correctly synced to the server and added to that subdirectory's schema. However, other sync clients (main workspace sync, other sandboxes) don't receive the new file because they are only subscribed to the fs-root SSE, not the subdirectory SSE.\n\nTest case:\n1. Create file in text-to-telegram sandbox: echo 'test' \u003e /tmp/commonplace-sandbox-.../c1-sandbox-test.txt\n2. File appears on server with correct content ✓\n3. File does NOT appear in shared workspace /workspace/text-to-telegram/ ✗\n4. File does NOT appear in bartleby sandbox /text-to-telegram/ ✗\n\nRoot cause: Sync clients only subscribe to fs-root SSE for schema changes. They need to also subscribe to all node-backed subdirectory SSEs to detect new file schema entries.\n\nWorkaround: Restart sync clients to pick up new files from initial schema scan.","status":"closed","priority":1,"issue_type":"bug","created_at":"2026-01-02T09:24:10.775971235Z","created_by":"jes","updated_at":"2026-01-02T09:42:55.095977376Z","closed_at":"2026-01-02T09:42:55.095977376Z","close_reason":"Closed"}
{"id":"CP-zif","title":"Commonplace link tool for shared document references","description":"A symlink/hardlink-like tool (possible names: synclink, commonlink) that works in a checked-out sync directory to create another file pointing to the same document UUID. Implementation likely involves editing the directory JSON to add another entry referencing the same document.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T17:52:42.458856392Z","created_by":"jes","updated_at":"2025-12-30T22:44:51.153396044Z","closed_at":"2025-12-30T22:44:51.153396044Z","close_reason":"Closed"}
{"id":"CP-zjep","title":"File/tmux sync logs 404 on initial commit (reads still succeed)","description":"Summary: Orchestrator logs show 404 errors during initial commit/subscribe for file↔tmux file sync, even though subsequent reads succeed; likely a race where SSE subscribes before the document is created.\n\nFiles to modify:\n- src/sync/sse.rs\n- src/sync/file_sync.rs\n- src/bin/sync.rs\n- src/orchestrator/discovered_manager.rs (log handling)\n\nImplementation steps:\n1. Reproduce by starting orchestrator with tmux/file sync and observe logs for initial 404s (e.g., \"SSE error: Invalid status code: 404 Not Found\").\n2. Trace the creation/subscribe sequence for the file path: ensure the document is created before SSE subscription begins.\n3. If the doc may not exist yet, treat initial 404 as a retryable condition without logging as an error, or gate SSE subscription until creation completes.\n4. Add a test or log assertion that initial sync does not emit 404 errors for newly created files.\n\nExample:\nBefore: Orchestrator log shows 404 errors on startup, but file reads still work.\nAfter: No 404 errors during initial sync; file reads still succeed.\n","status":"closed","priority":2,"issue_type":"bug","created_at":"2026-01-06T03:50:21.407771931Z","created_by":"jes","updated_at":"2026-01-06T17:53:13.369111325Z","closed_at":"2026-01-06T17:53:13.369111325Z","close_reason":"Handle 404 gracefully in SSE subscriptions during initial sync. Log at debug level and retry in 1s instead of treating as error with 5s wait. Used labeled loops to properly skip outer sleep. Applied to all 4 SSE functions. Merged in PR #102."}
{"id":"CP-zjl","title":"Sync tool wrapper mode: run executable in synced directory context","description":"Add a mode to invoke the sync tool that:\n\n1. Starts commonplace-sync to check out a directory tree to a local path\n2. Launches a specified executable in that synced directory context\n3. Keeps sync running while the executable is active\n4. When the child executable exits, the sync tool also exits and cleans up\n\nExample usage:\n```\ncommonplace-sync --exec \"vim .\" --server http://localhost:3000 --prefix notes --local ./workspace\n```\n\nThis enables workflows where a user wants to work on synced files with their preferred editor/tool, and have everything tear down cleanly when they're done.\n\n**Orchestrator compatibility:**\nThe sync tool should respect environment variable conventions of orchestrator-launched processes:\n- Pass through relevant env vars to the child process (e.g., `$EDITOR`, `$SHELL`, `$TERM`)\n- Respect standard orchestrator signals (SIGTERM, SIGINT) for graceful shutdown\n- Propagate child exit codes to the parent\n- Honor env-based configuration (e.g., `COMMONPLACE_SERVER`, `COMMONPLACE_PREFIX`)\n- Support `--` separator for passing args to the child executable","design":"Exec mode implementation approach: Add --exec flag to Args struct. When provided, after initial sync completes, spawn child process in synced directory using tokio::process::Command. Pass through env vars (EDITOR, SHELL, TERM, etc). Handle SIGTERM/SIGINT to gracefully shutdown both sync tasks and child. Propagate child exit code. Support -- separator via clap's trailing_var_arg.","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-30T00:13:55.940464-08:00","updated_at":"2025-12-30T08:40:24.04936003Z","closed_at":"2025-12-30T08:40:24.04936003Z","close_reason":"Implemented exec mode for sync tool. Added --exec flag that syncs directory, launches command, keeps sync running during execution, and propagates exit code on completion. Handles signals gracefully. Pushed directly to main in 1e83d1b."}
{"id":"CP-zkk","title":"Implement CRDT merge for offline changes in sync tool","description":"Follow-up from CP-dgu. When the sync tool detects offline local changes on restart (via state file hash comparison), it should:\n\n1. Fetch historical Yjs state at last_synced_cid using ?at_commit endpoint\n2. Compute diff from historical state to current local content\n3. Create Yjs update from diff\n4. Push update to server (CRDT automatically merges with any server changes)\n5. Pull merged result and update local file\n\nThe infrastructure is ready:\n- State file tracks last_synced_cid and file hashes (CP-dgu, PR #36)\n- ?at_commit endpoint returns Yjs state at any historical commit\n- Offline change detection logs 'Detected offline local changes' on startup\n\nJust needs the merge logic implementation in run_file_mode after detecting changes.","notes":"Reviewed code: offline CRDT merge is already implemented in run_file_mode (lines 322-381). Detects offline changes, pushes via replace endpoint with last_synced_cid as parent for proper CRDT merge.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-30T06:27:49.553275883Z","created_by":"jes","updated_at":"2025-12-30T18:42:48.412284179Z","closed_at":"2025-12-30T18:42:48.412284179Z","close_reason":"Closed","labels":["feature"],"comments":[{"id":3,"issue_id":"CP-zkk","author":"jes","text":"Discovered from CP-dgu during implementation. Design doc: docs/plans/2025-01-02-sync-state-persistence-design.md","created_at":"2025-12-30T06:28:03Z"}]}
{"id":"CP-zpmt","title":"commonplace-ps should show source path for each process","description":"Add a new column to commonplace-ps output showing where each process is defined:\n- For discovered processes: show the document_path (e.g., /beads, /bartleby)\n- For orchestrator-defined processes: show 'commonplace.json'\n\nThis helps users understand which __processes.json or config file is responsible for each running process.\n\nCurrent output:\nNAME                      PID STATE      CWD\nfilter-open            777796 Running    /home/jes/commonplace\n\nProposed output:\nNAME                      PID STATE      SOURCE              CWD\nfilter-open            777796 Running    /beads              /home/jes/commonplace\nserver                 777478 Running    commonplace.json    /home/jes/commonplace","status":"closed","priority":3,"issue_type":"feature","created_at":"2026-01-07T03:13:50.458532903Z","created_by":"jes","updated_at":"2026-01-07T03:46:33.119844942Z","closed_at":"2026-01-07T03:46:33.119844942Z","close_reason":"Added SOURCE column showing where each process is defined (/beads, /tmux, etc. for discovered; commonplace.json for base processes)"}
{"id":"CP-zr8","title":"Orchestrator shutdown should allow sync to terminate exec child or kill child group","description":"Summary: Orchestrator shutdown can SIGKILL sync before it has time to terminate its sandbox exec child, leaving orphaned app processes. Increase the shutdown grace period and/or add a second-stage kill that targets the exec child process group when known.\n\nFiles to modify:\n- src/orchestrator/manager.rs (ProcessManager::shutdown timeout/kill sequence)\n- src/orchestrator/discovered_manager.rs (DiscoveredProcessManager::shutdown timeout/kill sequence)\n- src/bin/sync.rs (optional: emit child PID/PGID for orchestrator to use)\n\nImplementation steps:\n1. Make the shutdown timeout configurable (CLI flag or config entry) or increase the default grace period in both managers.\n2. Add a second-stage kill path that, after the timeout, attempts to kill the exec child process group if its PID/PGID is available.\n3. If needed, have sync write its exec child PID/PGID to a pidfile or log line so the orchestrator can target it.\n4. Update logs to show which PIDs/groups were terminated and which path was taken.\n\nExample:\nBefore: orchestrator shutdown waits 5s, then SIGKILLs sync process group only.\nAfter: orchestrator waits N seconds, then SIGKILLs sync group and exec child group (if known).","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T19:25:28.238493346Z","created_by":"jes","updated_at":"2026-01-02T19:38:29.091230678Z","closed_at":"2026-01-02T19:38:29.091230678Z","close_reason":"Increased shutdown grace period from 5s to 10s, added debug logging. PR #93 merged."}
